{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import batch_norm\n",
    "import csv\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def data_preprop(X_filename, Y_filename):\n",
    "    # reading CSV file\n",
    "    reader = csv.reader(open(X_filename, 'r'), delimiter=',')\n",
    "    data_full = np.array(list(reader))\n",
    "    reader = csv.reader(open(Y_filename, 'r'), delimiter=',')\n",
    "    activity_full = np.array(list(reader))\n",
    "    # feature names\n",
    "    feature_names = data_full[0, 1:]\n",
    "\n",
    "    # names of the proteins\n",
    "    protein_names = data_full[1:, 0]\n",
    "    protein_names1 = activity_full[1:, 0]\n",
    "\n",
    "    # names of receptors\n",
    "    receptor_names = activity_full[0, 1:]\n",
    "\n",
    "    # Object-Feature matrix (proteins description)\n",
    "    X = data_full[1:, 1:].astype('double')\n",
    "\n",
    "    # Activity matrix\n",
    "    Y = activity_full[1:, 1:].astype('int16')\n",
    "\n",
    "    X = X[np.argsort(protein_names), :]\n",
    "    Y = Y[np.argsort(protein_names1), :]\n",
    "    X = X[:, np.argsort(feature_names)]\n",
    "    Y = Y[:, np.argsort(receptor_names)]\n",
    "\n",
    "    return X, Y, receptor_names[np.argsort(receptor_names)], protein_names[np.argsort(protein_names)], feature_names[np.argsort(feature_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "Y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tmp, Y_tmp, receptor_names, protein_names, feature_names = data_preprop('features_2.csv', 'all_endpoints_with_missing_values_012615.csv')\n",
    "X_test.append(X_tmp)\n",
    "Y_test.append(Y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tmp, Y_tmp, _, _, _ = data_preprop('features2.txt', 'test_set_1_012615.csv')\n",
    "X_test.append(X_tmp)\n",
    "Y_test.append(Y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_tmp, Y_tmp, _, _, _ = data_preprop('features3.txt', 'test_set_2_150724_edited.csv')\n",
    "X_test.append(X_tmp)\n",
    "Y_test.append(Y_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = np.concatenate(X_test)\n",
    "Y_test = np.concatenate(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.random.permutation(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test = X_test[ind, :]\n",
    "Y_test = Y_test[ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9437\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = np.var(X_test, axis = 0) != 0\n",
    "X_test = X_test[:, ind]\n",
    "feature_names = feature_names[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8513, 12)\n"
     ]
    }
   ],
   "source": [
    "print Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 165)\n"
     ]
    }
   ],
   "source": [
    "print X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.2, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (None, X.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target = T.matrix()\n",
    "input_X = T.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from dnn_class import DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = DNN(input_X, target, X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l_input = lasagne.layers.InputLayer(shape=input_shape, input_var=input_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HU_enc = 256\n",
    "HU_dec = 256\n",
    "dimZ = 128\n",
    "n_out = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_z, l_ae_out = model.build_ae(l_input=l_input, HU_enc=HU_enc, HU_dec=HU_dec, dimZ=dimZ, n_out=n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ae_train, ae_test, ae_pred = model.build_ae_loss(l_ae_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ae_train_loss_log = []\n",
    "ae_val_loss_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32658.6871835\n",
      "Epoch 1 of 100 took 0.389s\n",
      "  training loss (in-iteration):\t\t30.750186\n",
      "  validation loss:\t\t19.83\n",
      "Epoch 2 of 100 took 0.371s\n",
      "  training loss (in-iteration):\t\t25.223427\n",
      "  validation loss:\t\t12.99\n",
      "Epoch 3 of 100 took 0.369s\n",
      "  training loss (in-iteration):\t\t14.615837\n",
      "  validation loss:\t\t5.75\n",
      "Epoch 4 of 100 took 0.379s\n",
      "  training loss (in-iteration):\t\t6.197986\n",
      "  validation loss:\t\t2.22\n",
      "Epoch 5 of 100 took 0.364s\n",
      "  training loss (in-iteration):\t\t2.631725\n",
      "  validation loss:\t\t1.00\n",
      "Epoch 6 of 100 took 0.369s\n",
      "  training loss (in-iteration):\t\t1.236923\n",
      "  validation loss:\t\t0.57\n",
      "Epoch 7 of 100 took 0.415s\n",
      "  training loss (in-iteration):\t\t0.710986\n",
      "  validation loss:\t\t0.45\n",
      "Epoch 8 of 100 took 0.404s\n",
      "  training loss (in-iteration):\t\t0.539951\n",
      "  validation loss:\t\t0.40\n",
      "Epoch 9 of 100 took 0.391s\n",
      "  training loss (in-iteration):\t\t0.456741\n",
      "  validation loss:\t\t0.38\n",
      "Epoch 10 of 100 took 0.394s\n",
      "  training loss (in-iteration):\t\t0.407043\n",
      "  validation loss:\t\t0.35\n",
      "392.572276688\n",
      "Epoch 11 of 100 took 0.425s\n",
      "  training loss (in-iteration):\t\t0.376300\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 12 of 100 took 0.402s\n",
      "  training loss (in-iteration):\t\t0.356590\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 13 of 100 took 0.393s\n",
      "  training loss (in-iteration):\t\t0.332223\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 14 of 100 took 0.392s\n",
      "  training loss (in-iteration):\t\t0.315526\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 15 of 100 took 0.415s\n",
      "  training loss (in-iteration):\t\t0.312015\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 16 of 100 took 0.436s\n",
      "  training loss (in-iteration):\t\t0.296422\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 17 of 100 took 0.438s\n",
      "  training loss (in-iteration):\t\t0.289194\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 18 of 100 took 0.442s\n",
      "  training loss (in-iteration):\t\t0.269264\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 19 of 100 took 0.390s\n",
      "  training loss (in-iteration):\t\t0.261458\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 20 of 100 took 0.383s\n",
      "  training loss (in-iteration):\t\t0.257345\n",
      "  validation loss:\t\t0.25\n",
      "248.415205818\n",
      "Epoch 21 of 100 took 0.463s\n",
      "  training loss (in-iteration):\t\t0.247757\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 22 of 100 took 0.407s\n",
      "  training loss (in-iteration):\t\t0.238043\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 23 of 100 took 0.396s\n",
      "  training loss (in-iteration):\t\t0.233374\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 24 of 100 took 0.399s\n",
      "  training loss (in-iteration):\t\t0.228446\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 25 of 100 took 0.410s\n",
      "  training loss (in-iteration):\t\t0.223797\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 26 of 100 took 0.366s\n",
      "  training loss (in-iteration):\t\t0.215953\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 27 of 100 took 0.461s\n",
      "  training loss (in-iteration):\t\t0.211115\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 28 of 100 took 0.408s\n",
      "  training loss (in-iteration):\t\t0.207355\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 29 of 100 took 0.379s\n",
      "  training loss (in-iteration):\t\t0.205858\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 30 of 100 took 0.363s\n",
      "  training loss (in-iteration):\t\t0.198397\n",
      "  validation loss:\t\t0.20\n",
      "194.235849786\n",
      "Epoch 31 of 100 took 0.380s\n",
      "  training loss (in-iteration):\t\t0.194125\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 32 of 100 took 0.368s\n",
      "  training loss (in-iteration):\t\t0.198486\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 33 of 100 took 0.362s\n",
      "  training loss (in-iteration):\t\t0.185345\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 34 of 100 took 0.370s\n",
      "  training loss (in-iteration):\t\t0.181439\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 35 of 100 took 0.367s\n",
      "  training loss (in-iteration):\t\t0.179975\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 36 of 100 took 0.387s\n",
      "  training loss (in-iteration):\t\t0.176808\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 37 of 100 took 0.403s\n",
      "  training loss (in-iteration):\t\t0.176614\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 38 of 100 took 0.409s\n",
      "  training loss (in-iteration):\t\t0.170404\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 39 of 100 took 0.394s\n",
      "  training loss (in-iteration):\t\t0.169612\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 40 of 100 took 0.609s\n",
      "  training loss (in-iteration):\t\t0.165439\n",
      "  validation loss:\t\t0.17\n",
      "163.645727319\n",
      "Epoch 41 of 100 took 0.412s\n",
      "  training loss (in-iteration):\t\t0.160885\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 42 of 100 took 0.370s\n",
      "  training loss (in-iteration):\t\t0.158264\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 43 of 100 took 0.370s\n",
      "  training loss (in-iteration):\t\t0.157909\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 44 of 100 took 0.368s\n",
      "  training loss (in-iteration):\t\t0.158323\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 45 of 100 took 0.372s\n",
      "  training loss (in-iteration):\t\t0.151804\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 46 of 100 took 0.370s\n",
      "  training loss (in-iteration):\t\t0.149075\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 47 of 100 took 0.369s\n",
      "  training loss (in-iteration):\t\t0.147203\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 48 of 100 took 0.373s\n",
      "  training loss (in-iteration):\t\t0.145001\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 49 of 100 took 0.372s\n",
      "  training loss (in-iteration):\t\t0.143748\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 50 of 100 took 0.366s\n",
      "  training loss (in-iteration):\t\t0.141157\n",
      "  validation loss:\t\t0.15\n",
      "140.506183514\n",
      "Epoch 51 of 100 took 0.383s\n",
      "  training loss (in-iteration):\t\t0.139224\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 52 of 100 took 0.369s\n",
      "  training loss (in-iteration):\t\t0.138189\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 53 of 100 took 0.365s\n",
      "  training loss (in-iteration):\t\t0.135103\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 54 of 100 took 0.364s\n",
      "  training loss (in-iteration):\t\t0.133406\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 55 of 100 took 0.365s\n",
      "  training loss (in-iteration):\t\t0.131046\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 56 of 100 took 0.386s\n",
      "  training loss (in-iteration):\t\t0.129260\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 57 of 100 took 0.415s\n",
      "  training loss (in-iteration):\t\t0.130217\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 58 of 100 took 0.395s\n",
      "  training loss (in-iteration):\t\t0.126225\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 59 of 100 took 0.469s\n",
      "  training loss (in-iteration):\t\t0.124892\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 60 of 100 took 0.396s\n",
      "  training loss (in-iteration):\t\t0.123674\n",
      "  validation loss:\t\t0.13\n",
      "121.974295063\n",
      "Epoch 61 of 100 took 0.400s\n",
      "  training loss (in-iteration):\t\t0.120921\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 62 of 100 took 0.376s\n",
      "  training loss (in-iteration):\t\t0.119799\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 63 of 100 took 0.394s\n",
      "  training loss (in-iteration):\t\t0.119727\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 64 of 100 took 0.363s\n",
      "  training loss (in-iteration):\t\t0.116387\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 65 of 100 took 0.396s\n",
      "  training loss (in-iteration):\t\t0.116151\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 66 of 100 took 0.428s\n",
      "  training loss (in-iteration):\t\t0.114201\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 67 of 100 took 0.390s\n",
      "  training loss (in-iteration):\t\t0.112875\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 68 of 100 took 0.400s\n",
      "  training loss (in-iteration):\t\t0.112087\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 69 of 100 took 0.407s\n",
      "  training loss (in-iteration):\t\t0.111422\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 70 of 100 took 0.428s\n",
      "  training loss (in-iteration):\t\t0.110972\n",
      "  validation loss:\t\t0.12\n",
      "111.019159278\n",
      "Epoch 71 of 100 took 0.425s\n",
      "  training loss (in-iteration):\t\t0.107320\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 72 of 100 took 0.408s\n",
      "  training loss (in-iteration):\t\t0.105850\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 73 of 100 took 0.422s\n",
      "  training loss (in-iteration):\t\t0.105327\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 74 of 100 took 0.428s\n",
      "  training loss (in-iteration):\t\t0.103808\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 75 of 100 took 0.411s\n",
      "  training loss (in-iteration):\t\t0.102489\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 76 of 100 took 0.394s\n",
      "  training loss (in-iteration):\t\t0.101453\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 77 of 100 took 0.417s\n",
      "  training loss (in-iteration):\t\t0.102150\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 78 of 100 took 0.404s\n",
      "  training loss (in-iteration):\t\t0.099703\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 79 of 100 took 0.371s\n",
      "  training loss (in-iteration):\t\t0.098652\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 80 of 100 took 0.408s\n",
      "  training loss (in-iteration):\t\t0.097732\n",
      "  validation loss:\t\t0.10\n",
      "97.5163694921\n",
      "Epoch 81 of 100 took 0.409s\n",
      "  training loss (in-iteration):\t\t0.097154\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 82 of 100 took 0.380s\n",
      "  training loss (in-iteration):\t\t0.095136\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 83 of 100 took 0.400s\n",
      "  training loss (in-iteration):\t\t0.094367\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 84 of 100 took 0.412s\n",
      "  training loss (in-iteration):\t\t0.094102\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 85 of 100 took 0.446s\n",
      "  training loss (in-iteration):\t\t0.093668\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 86 of 100 took 0.416s\n",
      "  training loss (in-iteration):\t\t0.092163\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 87 of 100 took 0.422s\n",
      "  training loss (in-iteration):\t\t0.092636\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 88 of 100 took 0.403s\n",
      "  training loss (in-iteration):\t\t0.091085\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 89 of 100 took 0.414s\n",
      "  training loss (in-iteration):\t\t0.089226\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 90 of 100 took 0.416s\n",
      "  training loss (in-iteration):\t\t0.089088\n",
      "  validation loss:\t\t0.09\n",
      "87.8568077607\n",
      "Epoch 91 of 100 took 0.561s\n",
      "  training loss (in-iteration):\t\t0.088366\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 92 of 100 took 0.428s\n",
      "  training loss (in-iteration):\t\t0.087924\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 93 of 100 took 0.422s\n",
      "  training loss (in-iteration):\t\t0.086119\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 94 of 100 took 0.430s\n",
      "  training loss (in-iteration):\t\t0.084588\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 95 of 100 took 0.396s\n",
      "  training loss (in-iteration):\t\t0.086001\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 96 of 100 took 0.452s\n",
      "  training loss (in-iteration):\t\t0.084143\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 97 of 100 took 0.432s\n",
      "  training loss (in-iteration):\t\t0.083274\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 98 of 100 took 0.412s\n",
      "  training loss (in-iteration):\t\t0.082591\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 99 of 100 took 0.400s\n",
      "  training loss (in-iteration):\t\t0.081180\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 100 of 100 took 0.425s\n",
      "  training loss (in-iteration):\t\t0.081370\n",
      "  validation loss:\t\t0.09\n"
     ]
    }
   ],
   "source": [
    "ae_train_loss_log, ae_val_loss_log = model.fit_ae(train_fn=ae_train, test_fn=ae_test, train_loss_log=ae_train_loss_log,\n",
    "                                                 val_loss_log=ae_val_loss_log, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b5fafd0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112f135d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ae_train_loss_log, label='Train error')\n",
    "plt.plot(ae_val_loss_log, label='Validation error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.layers.DropoutLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_nn_out = model.build_nn(l_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn_train, nn_test, nn_pred = model.build_nn_loss(l_nn_out, learning_rate=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loss_log = []\n",
    "val_loss_log = []\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17377.4812731\n",
      "Epoch 1 of 1 took 0.249s\n",
      "  training loss (in-iteration):\t\t1.578620\n",
      "  validation loss:\t\t1.90\n",
      "9936.411391\n",
      "Epoch 1 of 1 took 0.243s\n",
      "  training loss (in-iteration):\t\t1.084183\n",
      "  validation loss:\t\t1.98\n",
      "7214.90138965\n",
      "Epoch 1 of 1 took 0.261s\n",
      "  training loss (in-iteration):\t\t1.001228\n",
      "  validation loss:\t\t2.04\n",
      "6485.47492657\n",
      "Epoch 1 of 1 took 0.245s\n",
      "  training loss (in-iteration):\t\t0.924203\n",
      "  validation loss:\t\t2.04\n",
      "6164.68497265\n",
      "Epoch 1 of 1 took 0.278s\n",
      "  training loss (in-iteration):\t\t0.880000\n",
      "  validation loss:\t\t2.06\n",
      "6007.80876835\n",
      "Epoch 1 of 1 took 0.254s\n",
      "  training loss (in-iteration):\t\t0.849437\n",
      "  validation loss:\t\t2.05\n",
      "5895.38682337\n",
      "Epoch 1 of 1 took 0.259s\n",
      "  training loss (in-iteration):\t\t0.903522\n",
      "  validation loss:\t\t2.05\n",
      "5991.04519598\n",
      "Epoch 1 of 1 took 0.262s\n",
      "  training loss (in-iteration):\t\t0.935860\n",
      "  validation loss:\t\t2.04\n",
      "5823.86337298\n",
      "Epoch 1 of 1 took 0.249s\n",
      "  training loss (in-iteration):\t\t0.886553\n",
      "  validation loss:\t\t2.04\n",
      "5756.03704043\n",
      "Epoch 1 of 1 took 0.251s\n",
      "  training loss (in-iteration):\t\t0.898531\n",
      "  validation loss:\t\t2.07\n",
      "5760.35612435\n",
      "Epoch 1 of 1 took 0.308s\n",
      "  training loss (in-iteration):\t\t0.917240\n",
      "  validation loss:\t\t2.07\n",
      "5753.57620463\n",
      "Epoch 1 of 1 took 0.256s\n",
      "  training loss (in-iteration):\t\t0.943850\n",
      "  validation loss:\t\t2.02\n",
      "5630.76158676\n",
      "Epoch 1 of 1 took 0.262s\n",
      "  training loss (in-iteration):\t\t0.871363\n",
      "  validation loss:\t\t2.03\n",
      "5522.37485496\n",
      "Epoch 1 of 1 took 0.253s\n",
      "  training loss (in-iteration):\t\t0.912883\n",
      "  validation loss:\t\t2.03\n",
      "5585.99191247\n",
      "Epoch 1 of 1 took 0.267s\n",
      "  training loss (in-iteration):\t\t0.888212\n",
      "  validation loss:\t\t2.08\n",
      "5567.00484964\n",
      "Epoch 1 of 1 took 0.254s\n",
      "  training loss (in-iteration):\t\t0.885291\n",
      "  validation loss:\t\t2.06\n",
      "5323.38074981\n",
      "Epoch 1 of 1 took 0.257s\n",
      "  training loss (in-iteration):\t\t0.851842\n",
      "  validation loss:\t\t2.05\n",
      "5524.78463003\n",
      "Epoch 1 of 1 took 0.280s\n",
      "  training loss (in-iteration):\t\t0.888650\n",
      "  validation loss:\t\t2.04\n",
      "5313.68942089\n",
      "Epoch 1 of 1 took 0.240s\n",
      "  training loss (in-iteration):\t\t0.870435\n",
      "  validation loss:\t\t2.02\n",
      "5342.54615643\n",
      "Epoch 1 of 1 took 0.265s\n",
      "  training loss (in-iteration):\t\t0.881948\n",
      "  validation loss:\t\t2.05\n",
      "5284.63643851\n",
      "Epoch 1 of 1 took 0.292s\n",
      "  training loss (in-iteration):\t\t0.941568\n",
      "  validation loss:\t\t2.03\n",
      "5418.55928972\n",
      "Epoch 1 of 1 took 0.259s\n",
      "  training loss (in-iteration):\t\t0.936315\n",
      "  validation loss:\t\t2.03\n",
      "5231.87500152\n",
      "Epoch 1 of 1 took 0.248s\n",
      "  training loss (in-iteration):\t\t0.879736\n",
      "  validation loss:\t\t2.04\n",
      "5291.76732122\n",
      "Epoch 1 of 1 took 0.262s\n",
      "  training loss (in-iteration):\t\t0.834855\n",
      "  validation loss:\t\t2.01\n",
      "5077.73346231\n",
      "Epoch 1 of 1 took 0.255s\n",
      "  training loss (in-iteration):\t\t0.841518\n",
      "  validation loss:\t\t1.99\n",
      "5161.17852345\n",
      "Epoch 1 of 1 took 0.252s\n",
      "  training loss (in-iteration):\t\t0.918393\n",
      "  validation loss:\t\t2.05\n",
      "4935.59590164\n",
      "Epoch 1 of 1 took 0.247s\n",
      "  training loss (in-iteration):\t\t0.809594\n",
      "  validation loss:\t\t2.01\n",
      "4958.14120404\n",
      "Epoch 1 of 1 took 0.253s\n",
      "  training loss (in-iteration):\t\t0.815246\n",
      "  validation loss:\t\t1.98\n",
      "5478.83315782\n",
      "Epoch 1 of 1 took 0.246s\n",
      "  training loss (in-iteration):\t\t0.950690\n",
      "  validation loss:\t\t2.03\n",
      "4983.2800858\n",
      "Epoch 1 of 1 took 0.277s\n",
      "  training loss (in-iteration):\t\t0.749553\n",
      "  validation loss:\t\t2.04\n",
      "4720.02220581\n",
      "Epoch 1 of 1 took 0.244s\n",
      "  training loss (in-iteration):\t\t0.729999\n",
      "  validation loss:\t\t2.02\n",
      "4954.45328987\n",
      "Epoch 1 of 1 took 0.249s\n",
      "  training loss (in-iteration):\t\t0.910435\n",
      "  validation loss:\t\t2.02\n",
      "4728.71953143\n",
      "Epoch 1 of 1 took 0.272s\n",
      "  training loss (in-iteration):\t\t0.764954\n",
      "  validation loss:\t\t2.02\n",
      "4564.58911911\n",
      "Epoch 1 of 1 took 0.265s\n",
      "  training loss (in-iteration):\t\t0.712567\n",
      "  validation loss:\t\t2.06\n",
      "4527.82925206\n",
      "Epoch 1 of 1 took 0.290s\n",
      "  training loss (in-iteration):\t\t0.760365\n",
      "  validation loss:\t\t2.05\n",
      "4595.64886319\n",
      "Epoch 1 of 1 took 0.258s\n",
      "  training loss (in-iteration):\t\t0.745740\n",
      "  validation loss:\t\t2.01\n",
      "4817.63919669\n",
      "Epoch 1 of 1 took 0.267s\n",
      "  training loss (in-iteration):\t\t0.836961\n",
      "  validation loss:\t\t2.01\n",
      "4582.45734431\n",
      "Epoch 1 of 1 took 0.258s\n",
      "  training loss (in-iteration):\t\t0.749301\n",
      "  validation loss:\t\t2.01\n",
      "4442.47697812\n",
      "Epoch 1 of 1 took 0.259s\n",
      "  training loss (in-iteration):\t\t0.715395\n",
      "  validation loss:\t\t2.03\n",
      "4495.41113725\n",
      "Epoch 1 of 1 took 0.269s\n",
      "  training loss (in-iteration):\t\t0.736004\n",
      "  validation loss:\t\t2.03\n",
      "4324.52690829\n",
      "Epoch 1 of 1 took 0.284s\n",
      "  training loss (in-iteration):\t\t0.704431\n",
      "  validation loss:\t\t2.06\n",
      "4291.07156563\n",
      "Epoch 1 of 1 took 0.247s\n",
      "  training loss (in-iteration):\t\t0.704822\n",
      "  validation loss:\t\t2.03\n",
      "4226.1999017\n",
      "Epoch 1 of 1 took 0.265s\n",
      "  training loss (in-iteration):\t\t0.756387\n",
      "  validation loss:\t\t2.00\n",
      "4141.90253713\n",
      "Epoch 1 of 1 took 0.256s\n",
      "  training loss (in-iteration):\t\t0.723281\n",
      "  validation loss:\t\t2.03\n",
      "4240.08529703\n",
      "Epoch 1 of 1 took 0.248s\n",
      "  training loss (in-iteration):\t\t0.731180\n",
      "  validation loss:\t\t2.05\n",
      "4392.8205027\n",
      "Epoch 1 of 1 took 0.276s\n",
      "  training loss (in-iteration):\t\t0.802679\n",
      "  validation loss:\t\t2.03\n",
      "4111.71975096\n",
      "Epoch 1 of 1 took 0.239s\n",
      "  training loss (in-iteration):\t\t0.671323\n",
      "  validation loss:\t\t2.02\n",
      "4059.84765238\n",
      "Epoch 1 of 1 took 0.237s\n",
      "  training loss (in-iteration):\t\t0.675201\n",
      "  validation loss:\t\t2.00\n",
      "4312.41029635\n",
      "Epoch 1 of 1 took 0.245s\n",
      "  training loss (in-iteration):\t\t0.803384\n",
      "  validation loss:\t\t1.98\n",
      "4490.89628357\n",
      "Epoch 1 of 1 took 0.304s\n",
      "  training loss (in-iteration):\t\t0.828838\n",
      "  validation loss:\t\t2.04\n",
      "4850.28202392\n",
      "Epoch 1 of 1 took 0.258s\n",
      "  training loss (in-iteration):\t\t0.850000\n",
      "  validation loss:\t\t1.96\n",
      "4169.47768745\n",
      "Epoch 1 of 1 took 0.233s\n",
      "  training loss (in-iteration):\t\t0.708791\n",
      "  validation loss:\t\t1.97\n",
      "4087.05112605\n",
      "Epoch 1 of 1 took 0.281s\n",
      "  training loss (in-iteration):\t\t0.669439\n",
      "  validation loss:\t\t2.01\n",
      "3940.81067136\n",
      "Epoch 1 of 1 took 0.252s\n",
      "  training loss (in-iteration):\t\t0.664642\n",
      "  validation loss:\t\t2.04\n",
      "3929.85901979\n",
      "Epoch 1 of 1 took 0.260s\n",
      "  training loss (in-iteration):\t\t0.648949\n",
      "  validation loss:\t\t2.01\n",
      "3681.06501437\n",
      "Epoch 1 of 1 took 0.262s\n",
      "  training loss (in-iteration):\t\t0.553670\n",
      "  validation loss:\t\t2.07\n",
      "3684.37100874\n",
      "Epoch 1 of 1 took 0.313s\n",
      "  training loss (in-iteration):\t\t0.593607\n",
      "  validation loss:\t\t2.04\n",
      "3919.90971597\n",
      "Epoch 1 of 1 took 0.254s\n",
      "  training loss (in-iteration):\t\t0.694941\n",
      "  validation loss:\t\t2.03\n",
      "3670.91052089\n",
      "Epoch 1 of 1 took 0.259s\n",
      "  training loss (in-iteration):\t\t0.621523\n",
      "  validation loss:\t\t2.07\n",
      "3547.06866447\n",
      "Epoch 1 of 1 took 0.262s\n",
      "  training loss (in-iteration):\t\t0.559125\n",
      "  validation loss:\t\t2.07\n",
      "3557.78664423\n",
      "Epoch 1 of 1 took 0.281s\n",
      "  training loss (in-iteration):\t\t0.616560\n",
      "  validation loss:\t\t2.02\n",
      "3590.92616162\n",
      "Epoch 1 of 1 took 0.261s\n",
      "  training loss (in-iteration):\t\t0.668196\n",
      "  validation loss:\t\t2.09\n",
      "3759.32126402\n",
      "Epoch 1 of 1 took 0.281s\n",
      "  training loss (in-iteration):\t\t0.693812\n",
      "  validation loss:\t\t2.04\n",
      "3860.109326\n",
      "Epoch 1 of 1 took 0.280s\n",
      "  training loss (in-iteration):\t\t0.680985\n",
      "  validation loss:\t\t2.00\n",
      "3983.45484573\n",
      "Epoch 1 of 1 took 0.322s\n",
      "  training loss (in-iteration):\t\t0.766719\n",
      "  validation loss:\t\t2.03\n",
      "3499.4321212\n",
      "Epoch 1 of 1 took 0.252s\n",
      "  training loss (in-iteration):\t\t0.564757\n",
      "  validation loss:\t\t2.09\n",
      "3389.41924361\n",
      "Epoch 1 of 1 took 0.253s\n",
      "  training loss (in-iteration):\t\t0.586213\n",
      "  validation loss:\t\t2.05\n",
      "3752.73243618\n",
      "Epoch 1 of 1 took 0.241s\n",
      "  training loss (in-iteration):\t\t0.685399\n",
      "  validation loss:\t\t2.03\n",
      "3367.77627917\n",
      "Epoch 1 of 1 took 0.242s\n",
      "  training loss (in-iteration):\t\t0.572672\n",
      "  validation loss:\t\t2.03\n",
      "3292.6946846\n",
      "Epoch 1 of 1 took 0.259s\n",
      "  training loss (in-iteration):\t\t0.593171\n",
      "  validation loss:\t\t2.02\n",
      "3376.94791135\n",
      "Epoch 1 of 1 took 0.252s\n",
      "  training loss (in-iteration):\t\t0.660558\n",
      "  validation loss:\t\t2.10\n",
      "3873.36644621\n",
      "Epoch 1 of 1 took 0.260s\n",
      "  training loss (in-iteration):\t\t0.709245\n",
      "  validation loss:\t\t2.02\n",
      "3530.53870999\n",
      "Epoch 1 of 1 took 0.235s\n",
      "  training loss (in-iteration):\t\t0.611963\n",
      "  validation loss:\t\t2.02\n",
      "3404.78778977\n",
      "Epoch 1 of 1 took 0.233s\n",
      "  training loss (in-iteration):\t\t0.556614\n",
      "  validation loss:\t\t2.06\n",
      "3171.19571064\n",
      "Epoch 1 of 1 took 0.247s\n",
      "  training loss (in-iteration):\t\t0.527725\n",
      "  validation loss:\t\t2.02\n",
      "3084.96070801\n",
      "Epoch 1 of 1 took 0.233s\n",
      "  training loss (in-iteration):\t\t0.570889\n",
      "  validation loss:\t\t2.01\n",
      "3608.2228497\n",
      "Epoch 1 of 1 took 0.238s\n",
      "  training loss (in-iteration):\t\t0.655498\n",
      "  validation loss:\t\t2.00\n",
      "3167.05760928\n",
      "Epoch 1 of 1 took 0.242s\n",
      "  training loss (in-iteration):\t\t0.522845\n",
      "  validation loss:\t\t2.05\n",
      "3102.99349032\n",
      "Epoch 1 of 1 took 0.237s\n",
      "  training loss (in-iteration):\t\t0.528970\n",
      "  validation loss:\t\t2.05\n",
      "2987.52091078\n",
      "Epoch 1 of 1 took 0.238s\n",
      "  training loss (in-iteration):\t\t0.531576\n",
      "  validation loss:\t\t2.06\n",
      "3191.58331772\n",
      "Epoch 1 of 1 took 0.244s\n",
      "  training loss (in-iteration):\t\t0.532986\n",
      "  validation loss:\t\t2.05\n",
      "3240.21131344\n",
      "Epoch 1 of 1 took 0.235s\n",
      "  training loss (in-iteration):\t\t0.653076\n",
      "  validation loss:\t\t2.03\n",
      "3391.92035665\n",
      "Epoch 1 of 1 took 0.257s\n",
      "  training loss (in-iteration):\t\t0.562252\n",
      "  validation loss:\t\t2.03\n",
      "3066.36933429\n",
      "Epoch 1 of 1 took 0.253s\n",
      "  training loss (in-iteration):\t\t0.557096\n",
      "  validation loss:\t\t2.07\n",
      "2954.8805028\n",
      "Epoch 1 of 1 took 0.252s\n",
      "  training loss (in-iteration):\t\t0.472936\n",
      "  validation loss:\t\t2.03\n",
      "2839.27992093\n",
      "Epoch 1 of 1 took 0.251s\n",
      "  training loss (in-iteration):\t\t0.550129\n",
      "  validation loss:\t\t2.04\n",
      "2920.30810035\n",
      "Epoch 1 of 1 took 0.292s\n",
      "  training loss (in-iteration):\t\t0.521091\n",
      "  validation loss:\t\t2.07\n",
      "2810.38162954\n",
      "Epoch 1 of 1 took 0.257s\n",
      "  training loss (in-iteration):\t\t0.455675\n",
      "  validation loss:\t\t2.04\n",
      "2778.06273218\n",
      "Epoch 1 of 1 took 0.246s\n",
      "  training loss (in-iteration):\t\t0.516840\n",
      "  validation loss:\t\t2.07\n",
      "2714.63986323\n",
      "Epoch 1 of 1 took 0.251s\n",
      "  training loss (in-iteration):\t\t0.460974\n",
      "  validation loss:\t\t2.06\n",
      "2752.46745223\n",
      "Epoch 1 of 1 took 0.248s\n",
      "  training loss (in-iteration):\t\t0.536670\n",
      "  validation loss:\t\t2.04\n",
      "2818.0188972\n",
      "Epoch 1 of 1 took 0.249s\n",
      "  training loss (in-iteration):\t\t0.537827\n",
      "  validation loss:\t\t2.01\n",
      "3171.0435507\n",
      "Epoch 1 of 1 took 0.278s\n",
      "  training loss (in-iteration):\t\t0.650075\n",
      "  validation loss:\t\t2.07\n",
      "3088.57865942\n",
      "Epoch 1 of 1 took 0.253s\n",
      "  training loss (in-iteration):\t\t0.590285\n",
      "  validation loss:\t\t2.06\n",
      "2881.51142663\n",
      "Epoch 1 of 1 took 0.249s\n",
      "  training loss (in-iteration):\t\t0.505138\n",
      "  validation loss:\t\t2.05\n",
      "2853.84845696\n",
      "Epoch 1 of 1 took 0.247s\n",
      "  training loss (in-iteration):\t\t0.542763\n",
      "  validation loss:\t\t2.02\n",
      "2783.63310068\n",
      "Epoch 1 of 1 took 0.241s\n",
      "  training loss (in-iteration):\t\t0.547673\n",
      "  validation loss:\t\t2.03\n",
      "3163.68300886\n",
      "Epoch 1 of 1 took 0.242s\n",
      "  training loss (in-iteration):\t\t0.593001\n",
      "  validation loss:\t\t2.03\n",
      "3263.69761529\n",
      "Epoch 1 of 1 took 0.238s\n",
      "  training loss (in-iteration):\t\t0.530081\n",
      "  validation loss:\t\t2.06\n",
      "2752.56586716\n",
      "Epoch 1 of 1 took 0.238s\n",
      "  training loss (in-iteration):\t\t0.508276\n",
      "  validation loss:\t\t2.08\n"
     ]
    }
   ],
   "source": [
    "for _ in xrange(100):\n",
    "    train_loss_log, val_loss_log = model.fit_nn(train_fn=nn_train, test_fn=nn_test, \n",
    "                                                train_loss_log=train_loss_log, val_loss_log=val_loss_log, num_epochs=1)\n",
    "    Y_pred = nn_pred(X_test)\n",
    "    for i in range(Y_test.shape[1]):\n",
    "        ind = np.where(Y_test[:, i] != 999)\n",
    "        fpr, tpr, _ = roc_curve(Y_test[ind, i][0], Y_pred[ind, i][0])\n",
    "        scores.append(roc_auc_score(Y_test[ind, i][0], Y_pred[ind, i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11b7036d0>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFxHxYwpxERE/phAXEfFjCnERET/2/x1ATL95Bc0qAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b703110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss_log)\n",
    "plt.plot(val_loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    }
   ],
   "source": [
    "print len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = np.reshape(np.array(scores), (300, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1129b4990>,\n",
       " <matplotlib.lines.Line2D at 0x1129b4b90>,\n",
       " <matplotlib.lines.Line2D at 0x1129b4cd0>,\n",
       " <matplotlib.lines.Line2D at 0x1129b4e10>,\n",
       " <matplotlib.lines.Line2D at 0x1129b4f50>,\n",
       " <matplotlib.lines.Line2D at 0x1129ba0d0>,\n",
       " <matplotlib.lines.Line2D at 0x1129ba210>,\n",
       " <matplotlib.lines.Line2D at 0x1129ba350>,\n",
       " <matplotlib.lines.Line2D at 0x1129ba490>,\n",
       " <matplotlib.lines.Line2D at 0x1129ba5d0>,\n",
       " <matplotlib.lines.Line2D at 0x1129ba710>,\n",
       " <matplotlib.lines.Line2D at 0x1129ba850>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzsnXd4VFX6xz93ZlImZTLplRQSAgQIITRBFFRAqVbW7roq\n9r7W/enad9F1reta17KuYgXEAhaU3kMIkEZ675mSybTMzP39cSeTSQECBBv38zx5ktx2zpR7vuct\n572CKIrIyMjIyJycKH7pDsjIyMjI/HLIIiAjIyNzEiOLgIyMjMxJjCwCMjIyMicxsgjIyMjInMTI\nIiAjIyNzEjMoERAE4RxBEIoEQTgoCML9A+zXCoKwQhCEPEEQtguCkOG1r9K9PVcQhJ1D2XkZGRkZ\nmeNDONI6AUEQFMBB4CygHtgFXCKKYpHXMc8AHaIoPiEIwkjgFVEUZ7v3lQMTRVHUnaDXICMjIyNz\njAzGEpgClIiiWCWKYhfwEXBun2MygB8BRFEsBpIFQYh07xMG2Y6MjIyMzM/MYAbneKDG6/9a9zZv\n8oALAARBmAIkAgnufSLwvSAIuwRBWHp83ZWRkZGRGUpUQ3SdZcCLgiDsAfYDuYDTve9UURQb3JbB\n94IgFIqiuHmI2pWRkZGROQ4GIwJ1SDP7bhLc2zyIotgBXNP9vyAIFUC5e1+D+3eLIAgrkdxL/URA\nEAS5iJGMjIzMUSKKonA85w/GHbQLSBMEIUkQBF/gEmC19wGCIIQIguDj/nspsEEURZMgCAGCIAS5\ntwcCc4EDh2pIFEX5Zwh+HnnkkV+8D7+nH/n9lN/PX+vPUHBES0AURacgCLcC3yGJxn9EUSwUBOEG\nabf4BjAaeE8QBBeQD1zrPj0aWOme5auAD0RR/G5Iei4jIyMjc9wMKiYgiuJaYGSfba97/b297373\n9gog6zj7KCMjIyNzgpBTN3+HzJo165fuwu8K+f0cWuT389fFEReL/VwIgiD+WvoiIyMj81tAEATE\nnyEwLCMjIyPzO0UWARkZGZmTGFkEZGRkZE5iZBGQkZGROYmRRUBGRkbmJEYWARkZGZmTGFkEZGRk\nZE5iZBGQkZGROYmRRUBGRkbmJEYWARkZGZmTGFkEZGRkZE5iZBGQkZGROYmRRUBGRkbmJEYWARmZ\n3xgb9Xpa7fZfuhsyvxPkUtIyQ0aN1cowf/9e2+ptNuL8/H6hHv18HDCZ+E9jI51OJ/U2G/V2Ox1O\nJxdHRvLk8OGe4z5sakLncHBLfPwxtWN0OEjavp0/xcTwXFraUHVf5jeKXEpa5hfjoNnM8zU1rNPp\nANhtNJK4fTtPVlZ6nn1aZrGQumMH+q6uE9KHY500mJ1Oz9/LqqowOhyDOq/OZuO9xsYB9/29uhpd\nVxcTg4NZGhfH6+npfD5mDB80N7OqpcXT38crK1nT1nbINowOB09WVh5y/yt1dUwMCuLdxsZD9rvG\namWFu81uulyuw77OCouFKwoKuLKwkE+bmw95nMzvD1kEZAAo6uzE4XIN6tjdRiPT9uxhs8HAbSUl\niKLI/5qauDEuji/b2ni8qgqAzQYDVpeLLw4z6B0LZRYLM3NzCd60iQ+amo7q3FUtLczIzQWgwWbj\nwYoK3ve6hsnhYNqePdRarb3Oa7DZOGPvXm48eBBdH1ETRZEfdDoeTU7mhrg4zo2IYLJGQ2ZQEMtH\nj+aGgwcpNZtZp9PR5nBQZDb369NNBw8iiiJPVFXxcGUlbe42Op1OXq2rY/H+/bzT0MALtbW8NGIE\ns0NDebexkfzOTvZ2dPS63ictLVxRWEi9zQbAV62tjNu1i0sLCjzHOL0E9Nv2dqbu2cOogAAmBgVx\nf3n5Ub2nMr9tZBH4lWN3ubi/rIyOw8zidF1dWLxmt8fCOfv28a7XLFcURa4vLqa4z4AF8FxtLQ8l\nJfHZmDEIwI96PR+3tHB3QgKvpqfzoXtQ3WwwME2j4ZMBZpaiKGJ0OBBFEYPDwbft7czKzSVj506P\ndXEoVre2EufnxyPJyXzf3n5Ur/P9piZyTSZqrFZ+1OsZ5ufHa/X1HqviyaoqthuNbDQYep23JD+f\nq6KjmR8Wxhetrb32HejsJFipJFmt7tfeKSEhPJmSwll5eTxeVcWjycnU2mxYvT6v9Xo9b9bXc2dp\nKe80NJAREECeyeRp98u2Ns6LiOCDpiYWhIeTERjInQkJPFBezrQ9e7i5pKRXm3kmE1E+PjxeWckb\n9fXcUlLCbQkJFLo/S6cokrBtm0fMXqyt5bnUVB5KTub2hARau7rkmMNJhCwCv3KeqKrixdpallVX\ne7aZHA7+kJ/PNoOBOpuN7Jwcbjp48JjbcLhc1Nps/L262mMNbDUaeauhgUf7uCZqrFa+bW/n2thY\nBEHgxrg4lhYXM8zPjxEBAWQFBWFwOCizWNhiMLBs+HA2Gwy0e82e7S4XFxcUELVlCz4bNhC/dSsP\nVVRwbWwsfx8+nGuKivhjYSEthxiI9nd2MkurZUF4eL/B+nAYHQ5+0OmYFxbG2vZ2ftDpuG/YMOwu\nF9uMRorNZt5qaODuhAS2GY2e85yiyO6ODu4eNowlkZF84na1tNrtHitgdmjoIdtdGhfHfYmJFJnN\nXB0TQ4paTYnF4tlfbLHwQloaHzQ1cX9iImeGhrLXZKLL5WKjXs/yjAyuiY3lh6ws3h41CoBpGg3f\njBtH9SmnsL+zE4PXJCHPZOL1kSP5rKWFxysrWTd+PEtjY6mz2bC7XFRZrTTa7R6h2d/ZyakhIQAo\nBIGJwcHs6mNdHCtdLhf73O3I/DqRReBXzG6jkTfq69k8YQKv1ddT5XZR3FpSgs7h4NwDB5i+Zw9X\nRUfzrU7Hno4O7C4X37e389/GRqr7uDQORb3dToyvLwl+fnzknrU/V1PDUykprNPpKOrsZIfRyL9q\na7m3rIyrYmLQqFQAXBUTQ5PdzmVRUYA0iMwLD+d/TU3U2mxM12iYExrKSvfs2SWKLMnPx+ZyYTjt\nNMynn07Haaexa+JEroyJ4dyICPInTybcx4es3bt7DW7d7O/sJDMwkNEBAXQ4nf1cN950ebm4VrW2\nMkur5dKoKL5pb2edTsecsDBuiIvjsoICpuTk8GRKChdERrLNS1zqbDbCfXwIUCpZGB7OFoOBD5ua\nGLZ9O09WVR1RBABuiY+ndto0ApVKRgUE9HIJFZvNzA0Lo2jKFP48bBgTgoLYazKRazIxXK0mxP1e\neyMIArNCQ9H6+DBNo2G9Xg9IAnvQYuH0kBA+yMjgh/HjSQsIwFehIMHPjwqr1dP2XpMJXVcXBoeD\nJK+A/pQhFIE7S0uZnJNDYWfnkFzvaHG4XJgGGfM5Wen/7ZIZcqxOJ9cWF/NcWhrRvr6DPu9v1dU8\nnpLCJI2G2+LjWbh/P+MCA8k1mdg9cSJ1NhtbDQaujo0l3s+P64qLMTudaFUqIn19eaa6ml0TJ6JW\nKg/bTrXVSpK/P39NTuaKwkIa7HY26PW8N2oULmDe/v3YXC4WhYfjp1Bwz7BhnnNDVCpWjR3LVI3G\ns21eWBhLi4s5RaNBpVBwWXQ0L9TWcm1sLD/odFRYreRMnIiPYuA5SJBKxXNpadTbbLzd0MBdXu05\nRZGCzk7GBgYiCAKnhYSwyWBgkUpFpdXK2KAgz7Fv1NfzXE0NeydNwl+pZHlzM1dFR3NWaChLi4uJ\n8PEhXa0mLjaWCB8fFoSHE+7jg9XppNBsxux0EqBUSgFut6snSKViTmgoNx88yPLRo7mztJRGu53/\njh59xM/T1/16RwcEeFwzVnc2UYq/v+f9yAoK4vnaWrYYDJ4Z+uGYHRrKDzod50ZEUGQ2k+zvj1qp\n5OywsF7HpanVlFosFJvNhCiV7DWZyHa/lwqhJ8FkcnAw7x1lrCXPZCLO15dIr+/32w0NrNPpeCQ5\nmesPHmRDVlavdn4OnqutZU9HBx+NGfOztvtbYlAiIAjCOcALSJbDf0RRfLrPfi3wNpAKWIBrRFEs\nGMy5JwNftLXxZVsbFVYrP44fj79SiSiK5Hd29hq0vBFFkc0GAy+60wD/LymJ7OBgyi0WHk9OJlCp\nJD0ggPSAAACuiYlhu9HI+RERLIqIQBRFLiss5OaSEhL9/NhuNDI7NJRLoqIY5u/PDqOR7UYjdyQk\nUGWzkejvz1mhoXyckcETVVXcNWwYQSoVt8fH4yMI3BAXN+CMFGBOn8FmTmgonU4nM9wD2KLwcG4p\nKaGgs5P/NDRwQ1zcIQXAm7uGDeOSggJui4/nX3V1zAkLw0cQiPL1Jdjdl9NCQthoMPB5Swvr9XpK\npk4l1MeHZrudhyoqSFOr+UdNDalqNQWdnSyOiCBQqSQzKIiMgAAEQSBYpeKqmBhPu/5KJWMDA8np\n6OA0rZZSLxEAeDo1lS6Xi1GBgaSp1fy3qYlwH58jvp5uRgUEsNYdyyi1WEj2EgCAMYGBlFksrNPp\nuMRtYR2OOaGhXFZYCEiD8fjAwAGPG+EWgSKzmQsiI9nT0cE+k4lxfY6frNFwqzvgL3gN2q/W1dHh\ndHLvsGG9tm/Q6zn/wAFcoshMrZbX09PZ2dHBg+XlbMjKYkRAAF+1tfF+UxN/9HqfB0PfPnSzzWDA\n5nIx6zAWmCiKvNXQgJx4fniOKAKCICiAfwFnAfXALkEQvhBFscjrsL8AuaIoXiAIwkjgFWD2IM/9\nXeAURV6vr2d+WFi/AOF7jY28MmIEX7a1MTsvj6tiYviouZmf9HoKJ09mlPsmNDocrG1vZ0lkJCUW\nC/4KhSfv3kehYHFExCHbVykUHn8xSO6C19LTOWffPgIUCq5zz8Kzdu/mFI2GXR0d2Fwubo+PlywB\ndy7/6Vot32u1nusEq1Tcl5h4VO9FqI8PiyIimOu+QX0UCq6NieFvVVV8297Oa+npg7rOVI2GWF9f\nTt+7V8qCMZlYGB5OptegdbpWy4Pl5YwODGRBeDhPVVXxTGoq95SVcWV0NHckJDBh926UgsC68eMJ\ndFtF9ycmEnMYq+wUjYZtRiOnabWSJeDlLvEWhLFBQTxzCCE/FKMCAnihthaQ4gEj3ULejZ9CwQi1\nmjXt7bw8YsQRrzc+KIjWri5qrVZJBA7RnzS1mhKzmSKzmQcSE/mouZkck4lJwcG9jkv088MF1Nps\nxPr6olIocLhcPFFVhValIs9kYopGgwBkBwVxRWEhH4wezUytlqerq8nOycEhinw9bpznu31rfDyf\nt7QclQgUdHZybXEx27KzPdtcosiy6mpeqK3FVxAomTrVY+keNJsps1iYFx4OSHEtAcmd1+FweCYO\nMr0ZTExgClAiimKVKIpdwEfAuX2OyQB+BBBFsRhIFgQhcpDn/uZpsNk4a+9ellVXc5N7BvVWfT0X\nHThAmcXCNqORCyIjeX/0aG6Kj2edTsei8HDuSkjwmN3vNzaSumMH1xUXs8VgYIvB4JlJHyshKhXb\nsrN5JT2dJVFRvD5yJCVTp7IoPJy9kyYRpFRSbbNRZbWS2GeR1/GycuxYTvHq/9K4OD5sbmZheDih\nRzFr/mtSErG+vuyZNIlVra1sMxp7zVzHBwYyRaPho4wMnh4+nHcbG5mck0OJxcIjyckk+vvzano6\nn2RkMM5rcLwwMvKwrpZpbhEAKLNaSRsg8+dYGRUQQLHZjEsUKTab+4kASC6haF9fkgfxuSgEgfMi\nIri3vJw9JhOZhxCBEQEBHktgQlAQyf7+rGpt7WcJCILA5OBg5u3bR9CmTWw1GPhWpyPJ359dEycy\nzM+PcouFfPcgfU1MDPPCwwlQKnksJYWPMzJYm5nJZC8X4YyQEDYbDEdc27G3o8OTHfbPmhq2G400\nuFNdbS4XlxcW8lVbG3smTmSyRsNr9fWec99saODGgwc96a9vNzRwXWwsYwID2TfEMYnHKisHlZm2\nz2SizCsJ4NfIYKQxHqjx+r8WaXD3Jg+4ANgiCMIUIBFIGOS5v2lqrVbOyMvj0qgo1iYmMiEnh0cr\nK/l3fT2nhYQwOSeH890uCIDLo6O5PDoakFaZnrNvH0tjY7mrtJQfs7JY297OO+5UzcH4g4+WMB8f\nbnSvVh0XGMg+k4lqm42F7tnTiSLJ3587ExI8AeTBck54OOe4+zZTq+W1+nre8bJ4VAoFGydM8Pz/\nano6DlHk4qgoj//5D0fZJkgWxi0lJThcrl4xgaFAo1KhVamosdkoNps53cvy6mZicDA2l2tAV8hA\nvJSWxrkHDvCTXs9/vd4fb9LUanZ3dNAlisT4+pIVFERhc3M/EQB4KCmJWpsNs8vF9cXFpKjVXBMT\nQ6BSybLU1MP25bQBXk+ivz9+CgWlFgsj3KK3qqUFhyhykdfn81JdHZ+2tPDNuHGsaG1lYlAQuSYT\nsX5+/LGwECewbvx41EoljycnMycvj+tiYwlWqdhiMKBzOPiuvZ3s4GBWtLZSOHkyJRYLeSbTkN1P\nO4xGHqus5OqYmH6u0L68Xl+PzeXirUN8Jt20dXWhEoRDulxPJEPV4jLgRUEQ9gD7gVzgqBPXH330\nUc/fs2bNYtasWUPUvaFBFEXuKi1FrVTy9+HDsblcnJGXxw2xsdzjdpm8mJbG2fv2sXLMGBZHRPBo\nZSVLIiMHvN7YoCBi/fyYm5fHnQkJZAYFEenjQ8auXWhVKm5PSDihryczKIj9nZ2ewPCJ5njLHPwp\nJobVbW0DDlrdLDmGAX8g4vz8SPT3Z7vROOQiAJKgvV5fz0GLhaWxsf323xAXd1SuE7VSyRdjx/J+\nUxPxhyjTkeLvj87hYHJwMIIgkBUUxCaDYUDLbJp7wBRFkc9aWlin0/HBIILfh+PUkBC2GAyMCAig\ny+XijtJSonx9e4nAer2eP0ZHc1ZeHktjYwlWKtnT0cGZWi1ft7dTO22ax/0zLiiIaSEhfNTczJXR\n0eSZTDyVksLr9fU4RJGb4+KI8fNjvDvbqpvNej17TSZuHeT95RRF3qiv56W6Os6PiGBNezsPut1p\nA3FtUREvjxhBgFJJp9PJmvZ2nKKI8jCC/lBFBQaHgw8zMg7bl/Xr17N+/fpB9XuwDEYE6pBm9t0k\nuLd5EEWxA7im+39BECqAciDgSOd64y0CvzZEUeTWkhLWtLcT7BaBPR0dBCuVHgEAmBsWRunUqZ5B\n4/GUlMNe908xMTxfW+vJuIn18+NUjYZNBgNjDzPYDQXjAgP5uq3NExjuy4cffsjChQvReJn1vyQL\nwsO5KjqaEUM8IB+yvbAw3mtqQiEIhB2FC2swvJCWRtbu3bR1dXmC+974KRT4DSJ47o1aqeT6uLhD\n7vdVKEjy92eUu70ztNojphELgsDr6els1Os9acHHSrdL6OrYWD5sbibZ358Cs5kq9ySkymrF5HTy\n0ogRRPr68qeYGLYZjXzc3Mw2o5ExAQH9ZsqXRUXxZkMDowMCGB0QwLWxsTxcWUm6Ws2K5GRAcq11\nl/tosdu5uKAAs8vF7NBQT8zicNxRUsJek4kX09JY0dLCSLWaJ1JSeLOhoV+9rEabjbcbG3k4KYlk\ntZpOl4vmri62G42HtUR2u4P0zXY7Ue5Y1f8aG1nR2srpISHcFB+Pn0JB8tSpXD5liseaeuyxx47q\nMxiIwXzLdgFpgiAkCYLgC1wCrPY+QBCEEEEQfNx/LwU2iKJoGsy5v1ZEUcTqdOJy+xc/b2lhg17P\njuxsSiwWOp1OthmNTBtggDyaWeONcXHkTJyIv1ca563x8ZwXEXHYmcNQkOmeCSqg380liiK33XYb\nK1euPKF9OBp8FAreGz0a1VEOjsfKAvd6h9QTYCVF+fry9siRxPr6EjnEAnM40tRqjwhM1mj41yCC\n9HF+flzidmEeD90iYHe5WFZdzV+Tk1kcHu6pc7RBr2emVotCEDzxnOygIPa44wRnDpAJtCA8nB1G\nI1+0tXFqSAjBKhVvpKfzcUaGJyU3MzCQ/M5OLE4nVxcVcWV0NA8nJfHnsjLPdSxOJytaWni0ooLS\nPqvkv9XpeH3kSOaGhfHayJF8NGYMCkHg9JAQNrjXZ3TTvb7C5F4R3ul0kh0UxBetrYii2KtcRzdd\nLhf5nZ2cGxHhcQVXW63cWVrK2WFhfNTczKt10tz56qKiXv0eCo54N4mi6ARuBb4D8oGPRFEsFATh\nBkEQrncfNho4IAhCIXA2cMfhzh3SVzDEiKLIi7W1BGzahGbzZqbv2UOjzcY9ZWX8yz1DGedOH9xu\nNHLKcc6SFYLQb4Z1Tng47x2n6T0YRgUE0GS3D+gKqq2tpb29na+++uq42vgtV4adotEQqFAMuSuo\nm3PCwymdOnXQfv+h4Db3BOOXYGxgIA12O0nbt5MZGMiZWi0XRkbyuVsE1uv1zOoTT0hVq9E5HHze\n2spZA4hAgFLJvLAwXq6t9cy0L42OJs3LugpWqYjz8/NkiT2RksKt8fGUWiw8XV1Ne1cXc/LyeKG2\nlo0GA280NHjObbHbabHbGT2AtTZLq/Us0utmhzuZoNO9SLHT6eTy6Gg+aW7mnH37iNiypZ9w5Hd2\nkuzvzz3DhvF6fT2lZjO3u0t93BAXx2vp6TxdU8Mat9W+Qa8fdNHDwTCoKZUoimtFURwpiuIIURSX\nube9LoriG+6/t7v3jxZF8SJRFA2HO/fXir6ri4vy83m/sZH8yZOxnX46UzQaRu3cyaTgYE9O8lSN\nhp3uPPuBLIHfCn4KBaMCAkgcwIecm5tLdnY233//PfZjrCOj0+lITEzEeZx1jX4plILAOWFhQ5oZ\n1Jefy6rpZlFExKBcICcCpSDw/ujR/DB+PB+PGYMgCJwVGkq+2czq1tYBRUDhjl1UWCxMP8S99oeo\nKGyieFh3y1XR0dwUH88XY8fio1Dgq1CwJjOTb9raGLZtG9nBwazPymLZ8OF85VXwcJvRyFSNZsBF\nbjO1Wtbp9Xzc3Mxq94r4nR0dKOltCcwICSFVrWZOaCgfZWSwJD+fv5SXk+O2GnJMJiYGBzM5OJjT\nQkKYu28fzV1d3O92EWcFBzNNo2FJfj6PJCVxulbbq4/Hi5w466bYbGb+vn3MDw/nw4wMjz/2xbQ0\n0tVqzvWaPU0JDubV+nrMTucJmyWeSL777jvOPPNMVCoV44KCCBvA17t3717mzp3LTz/9xKZNmzjr\nrLOOup3a2lpqa2vZv38/WVlZRzx+8+bNbN26lfvuu++o2zpRPJuaiupnXuX6e6bvWhc/hYL3Ro3i\n0cpKrC4XGQPMuLODg1EKwiFXvs8LC+MviYmHDIgDPOyOD3gzXK3mp6wsdroHekEQmBQcTFtXFxUW\nCylq9SFdviAt6ovx9eWDpiY2GwwcnDKFXR0dTAoOprNbBFwugpRK1nl9/zdPmMDbDQ0s2LeP90eP\nJqejg4lBQQiCcEgPwGPJyRgdDq6IjkYQBD5raeGyIXDRgVw7yMMrdXVcEhXFyyNG9ArICYLArQkJ\nvYI/UzQatrpdQT+nKX+0iKLI2LFjqavrHYu/9tprKXCXFb44MpJ5A6S55ebmMmHCBBYuXHjMLqGm\n7mqimzcP6viNGzeyZs2aY2rrRBHj50fEUZT6kDl6FkdEkDNxIsVTpgx4P10VHc2Dh1mwqFYqecrr\nwT1Hg0IQOCUkxNOuQhCYHx7O1+6Z9jaDgemHsDAUgsC27GxWjxvHeRER3FVWhlalIkWt7mUJBPYR\nr/SAAJalpvLiiBE8VFEhiUCfBXt9GRcUxA9ZWagUChaHh7NOpxuymkgnpQh0OBz9asJv1OtZNMhc\n+RFqNVqV6rjjASeakpIS8vPzPQN+N0ajEZ17Qc55kZEsHMBHvHfvXrKyspg3bx5r1649bDtLly5l\nzpw5vPHGG722NzU14efnN2gRKCsro9qrWqrMyUN3+Y6BmBAcfMR8/KFkYXg4X7W10eVykWMy9aqL\ndSjuHTaMD5qamBIcTKBC4bEETE4ngYdw+S2JjMTicrG7o4MJR7HqPNTHhxvj4mgconLfJ6UIPFxR\nwZl5edjdwRt9VxdlVivZR1DjbgRB4KLISOb+jF/MY2HDhg0AlJaWera5XC46Ojo8IjAQOp2O1tZW\n0tLSGDNmDOXl5TgOM+vYtGkTCxcu5M477+wVCG5qamLu3Lls2rRpUAHi0tJSampqcA3y4TYyMieC\nOaGh7OjoYMH+/ST5+Q1qAdfowEAujIzkdK2WIKXysJZANwpB4KmUFCYEBRF0lOm3T6em9gp+Hw8n\nnQiIosjqtjYE4BF3rfwtRiNTgoM9KWWD4c2RI5nyK7cENmzYwIgRI3qJgMlkQhTFw4pAXl4emZmZ\nKBQK/P39iY6OPuwMvbW1lcsuuww/P79e121sbGTatGmIokiV+2ljNDTACy8MeJ2ysjJcLpfHjSQj\n80ugUanYP2kSV0ZH88wRVkd7s3z0aG6OiyPQvUjM4XLhEEX8DzOuLIqIYLtXbaRfgpNOBIrMZhyi\nyNrMTN5rbGSjXs9GvX7Apfu/ZURRZMOGDVxzzTWUlpSAe3Wj0Z3C1t6n7kmXl3ts7969jB8/3vN/\namoqZe7c5PXr12P1WmDkdDrR6/WEhYWRkJBArbswGkiWQExMDKeeeqrkEvruO8jOhv/7P+jzEByL\nxUJrayuZmZmyS0jmFyfB358rY2KYfxTlVFQKBYIgeCyBTpeLAKXyiHHDnztDrC8nnQh81dbGwvBw\nonx9eXPkSK4qLGRtezunnYA6Pb8kFRUVOJ1O5s2eTemGDTBzJtAjAro+jyTMzs7moHtgrqysJNVr\nBpSWluaxJq688kq2bdvm2dfe3o5Wq0WpVBIfH99PBKKjo5kxYwabP/wQrrgCli+XfvcJNpeXl5Oc\nnExKSoosAjK/aQKVSjpdLskV9AsP8IPh19/DY+DB8nJ2ez0e0JtuEQBpteG88HAKzOZffZD3aNmw\nYQMzZ84kbdkyyk0mXFVVYDJhdFddbN+0yXOsxWIhPz+fiqIiWLGChoYGYr3q2XRbAi0tLdTW1vZy\n17S0tBDpro3UyxJwuWgsKCD6vvuY8fnnbP7uO1i1CseMGbzp4wNfftmrv2VlZaSmppKYmHj0IuAl\nSgaD4ZjXNcjIDAUeS+Aw8YBfE787EWi02Xi5tpb5+/fzTkMDL9fW8kRlJf+sqeHB8nJyTSbO8HL9\nPJuayifqBIoAAAAgAElEQVQZGQT8Bj6swSKKIu+88w4LTjuNwB9+IDQ6mroRIyAvD0NuLuC2BNwr\nF4uKihBFkfpVq+DCC2koLOwlAmlpaZSVlZHrPrfZq3BWa2srERER0NBAwjffULdrF9TXw4wZNDU2\nEn3//Yy/7Taq/f1pHzWKrVu3cv0rr1C0cyd4xQ9KS0tJS0vrLQL79h35xa5ZA9OnS7EG4Prrr+f5\n558/rvfvaLDZbKxatepna0/m1093TEAWgV+I7pn+Z2PG8GFzMwVmMzaXizqbjUCFglVjx/ZadBKo\nVHL+Iap8/iIMQe3xFStWYDAYuFSjgVmzJHfOsGGwdy/GAwcI9PFBFx4O774L4EkhrV+/Hq6/XhIB\nL8soNTWV0qIicn/6CaVS2c8SiIiIgFWriFepqH3/fZg0Cdf8+bSKIlEXX4xqyRKmTpvG1q1bWbNm\nDf7+/qxKTASv1NOysjJSIyJItFolEVi7FsaPh8MEiX/69lsqb74ZNBqoqJCexrZ5M5999tkxvW92\nu12KjVxzjUdUjsT+/fu58sorf7OromWGHu+YgCwCvwBftrWxOCJCekLW+PG8mp7Ok8OH81xaGg8l\nJw9YhOpXwzffQHg4uJegD8jHH4M79XMgrFYr9957Ly+88ALK77+Hs8+WRCAkBHJzMRYXkxQZSXto\nKLz2GogiBQUFRIaHU19fDy+9RAMQ+9ZbnmumpqZSXlpKzocfMn369B4RKCigdds2yR20ciUJV15J\nbXY2vP8+bTfcgEajwde90GrGjBls3ryZb775hgceeIBVDgf88Y8QFwf//S+lJSWkLV9O4uOPU11U\nBH/+M0RHw5YtPS/O6YQHH/QEuR++7jo+Vqth3jyoqKC6uhqHw0GF+2/a22Hr1kG//Q899BBPPfKI\nJI7/+9+gzmlqasJkMvVbiyFz8tK9TkCOCfwCdNidrGvTU78yDPfDiIYMp7OT7dvT2L49hZqa54b2\n4gA7d0qDYkwMuN0uFBaCu7iWh7fegmuvBW+/94MPwooV7svsJCIigjNmzZKycbpFQBAgNxdDRQXJ\nqanSYrnOTigspKCggLPi46mPjaXDbsfl44Nm5UrPAKrRaAgEfqit5ZxzzukRgWXLaHn9dWlF7fbt\nJCxeTK3BAGedRWNjI9Fey9pnzJjB559/Tm1tLffddx/Fra3UHzwoBYjvv5+yLVtI1WhIfPFFSQRi\nYuD228F7odmXX8Lrr8Npp9F1443k1NWRl54Ow4dDeTlbt27l1MhIFo8YIVU/vfFGuOqqQX8ENTU1\nfPHZZxAUBO+9B4NY29D9XuzYsWPQ7RwzbW093w2ZXy1yTOBnospq9Tx2rpsb39ThLAzmqQd9yM8f\n2va6ulpxuSwkJj6AwbDpyCccAVEU+de//tWziOqee+D55+G88yAnR9p2661w5529T8zPh5AQeOUV\n6f/cXHj6afjhBwD0ej0xMTGwfz8EBsLw4ZIIdHRAQQHG9naSx4yRUkTPPx9WrqSgoIDZjY3Uq9We\noLDw8suS2NhsYLWS5nJhdbk4PT1dGvicTlizhtbQUCJXrIBZs0hIT/cEhrvTQ7uZOnUqFRUVnH32\n2ajVaubPn89Lr73GqupqHl6wgDqLheQPPyTyuuvoUKkwP/cczJjRWwRefll63TffzL79+xH8/dlX\nWgopKVBRwbZt25hmNHLhnj18/vTTGHJzsbS3g3fZDFGEPqvFu2lqamJvSQl1CxeC2Qx79/Y7psNd\n9Mv7HK1W+/OIwGuvwZQp8M47gz/HYICLL4Y+/ZY5ccgxgSFk924pm3AgHigv594+dbU3drVxeUo4\nWVmemOeQ4XB0oFJpCQwch93eeFTniqKTvXvP7LVqtr29ndtuu01K2WxokAbtJUukPPo9e6SZ/s6d\n8O23UFwsndTWBiYTvP8+/O1v0mBw553kzZlD9e7dAOjb2tC2tcHDD8PZZwMwfPhwyqurITkZY3g4\nicnJGAwGXOeei/Wzz6iuqOD0pCTqOzp6MoMuugji4+GzzyAnh1StlvFhYcRVVUmB4W3bID6e1kmT\niGhthfPOQ6vV0tXVRUdHhyc9tJugoCCys7OZP38+IJWa2L59O2+//Tau6Gh+3LIFv+HDUSgUDEtO\npsbfHyZPlkSvs1P6XVAAF14Id9zBjssv54ILLqCsrAxbQgJUVLB161amt7Qwe8UKChsbSairY5zd\nTsd330md+OormDRJcjMNUA+pubmZMVot3wgCXHmlJMp79kiCAOz9+mtOHzu21zlNTU3Mmzfv5xGB\nzZvhiSfg0Ufhxx8Hd87998Pq1Z74j8yJR44JDCHvvjuwS1cURTbq9XzR1uYpouQSReqT2vhjejih\nob0STwBoaVmJ3X7sK1GdThNKZRC+vjHYbAMHDa0O64DlEbq6dOj1PyGKPS6c7rz7lpYWWLkSFiwA\nPz+YOFEaeHbtgvR0yRJ46inppPx8GDMGMjLgk0+k+IDVyt2dnXx04ACIIvotW9Dm50sD6F/+AkBc\nXByNjY2QlYVBqyUsLIzAwEA6srI4WFFBistF4jPP0NTURF1dnSQCggBLl3o+hJHp6UwaO5bo/ftp\nampCXL0aFi2ipbOTyGefhcsuQxAEEhISqKur6+cOAli9ejWXXnopID0+dP369axevZqnnnqKadOm\neY5LTEyksrIS1GopOLxtGzzyCNxwA7hjDDt27GDmzJmkpqZS4HDQWVpKYUEBE6Oi8FuwgGarlQ6z\nmdMzMrjn2WehqkpyDf31r/DFF7TfcAOWm24Cr1TipqYmrgkM5OvaWrjuOmhshD/9SbI0br2VA5dc\nQl1Njcfq6j5nzpw5lJeXe2IDR132wuWSLKvD4XRK78O118Jll/WOlRyKjRvh668lV+GLLx65DZkh\nQV4nMEQ4ndIktL6+v2u2zJ1Bc3pICCvdQdRvKzvApGJGSsCAInDw4I3k5s7EZjvk0y2P0J8OlMpg\nfH1jsNsbBxzs574/l2/Lvu23vdNQDoDF3OPf7xaB1tZW6YVedJG0Iz1dyoj54gtpgddtt0k3cn29\nJALdM9EzzoC1a2n75hs2bN+ODqChAX1BAdrsbHjoIWkmD0RFRdHa2orzppswJiQQEhJCaGgo7UYj\nBRMmMCYqCr9ZswgJCWHfvn096aHnnisJ0qefcvcNN/C3ZcsI3LYNpVJJxxdfwKJFUoro9OngrrLa\nvVagryUAEBMTg3IQM6NZs2bx+eefA9A2cSLvXXAB35aV4fByje3YsYOpU6eSmZnJvuZmtjY2Mi4+\nHn/3SmfBLRYvPPMM35aUcMW8edybmsqywkJu+vBD4traeH7XLklU6+txOBzo9Xoub2vjp717sUVF\nSTGVvDwpEB8YSPGll9ImCLiuv95jHTQ3N5OQkEBmZiZ/vusuxo0bx65du474Gnvxn//AWWcdfpDe\nv1+Kk0RGQlbWkWMDVVVw+eXw6qtwzjkQFjag9XPCcTql79BJhBwTGCI2bpQSR/z8+rt2NhgMzNRq\nuTI6mv+5A3Pvl7WR1dlCa+sqQkN7n2O3t+JyWYmJ+SMHDlx4TP3ptgSUygAUCj8cjt6dqtRXcvGr\nm0i587F+vmTDtm8AaDvQM3vziEBZmXSTuF03KJV0jcug6/VXYdYsyf8/f75kLRw40CMCbr7++mtE\nUZSyfQ4cQF9RgbZPTXKVSkVYWBgt6ekYlUo0Gg2hoaHodDryJ08mwx08jYuLIycnp0cE/P0lf/Ku\nXQSccQbBU6dCSwvRTidNZjNMmtSTIuqme9Vw35jA0XD99dfz6aef0tbWxvUHDvB2YCC3mUz8+7//\nBaQCd3V1dYwZM0YSgYICXvTx4erQUMjM7HUtzYwZ/ODryxmVlUTOno1erycuLo5nn32WnQkJ0ut7\n/HFaW1sJDQ4mOjmZpKQkDhw40HORUaPg6acp1utxuVzox4+XZta4V0WHhjK1tpYvly9n3Lhxh699\nJIr9ZzX79kmz/H/849Dnbd4Mp50m/Z2VNWC8wkNLizTw33MPLFwoWXV33CEF1bs5liJ9tbVSxtXR\nsG4dnHkmDOGTsH7tdNcg0zkcsggcD598It2fcXHSJNib7meRLo6IYGdHB6tbW/nJ1srCiDXodD+g\n1fa2BMzmQgIDM4iLuwmz+diebilZAlK5V1/fWOz23i6h1dve5Yp9UBcTIH3pa2o8+xx7pZRO0/4e\n31ZpaSm+vr60btokHe/1cJrylFCUHaaem/6iiyRrodsd5MWqVas455xz0AUEwK5d6FtaCOkjFCDN\nwhsbGzEYDGg0GsLCwmhvbyevqIjMyZMBSQT27NnTa6EY114rDYKJiaBQwMsvE52URNPbb4NCQWtr\nq2fFMEiWwHfffceOHTuOWQSio6M577zzuOyyy9hXW8u3FRUse/ppz3MNtm7dyqRJk1AqlYwfP57P\nP/+cXKeTqw8e7CcCqFSknXoq1y5cyH1//zvLli3j4YcfZsGCBezevVvKrPrsM5p37SI6MBAmTGD0\n6NEUFRX161dxcTGCINC6aJFkneEWgSef5KGYGPaEhjIxO7vXYrp+PPEEuF1iHsrL4Z//lH42bhz4\nvM2bpUA5QFqalCY7UOArJ0dyBV5yiTTwdzN/vnQNu12yYuLiegb07dul9GSdTnKZnXfewH146KHe\nQjIYNm+WgtNeq7pPBoKUSprtdlkEjhVRlCa+S5YMLAIb9XpmhoQQoFSycswY7ikrQ6ewM127Bput\npp87yGwuZP36DMrKQnC5bDidvR8k7c0DPzzAnob+5qvTaUKlkkpNd7uEAClYC+iWv0NhVjyfnDcC\nrr4aXnrJc66qTJpVukp6ZpclJSVkZ2fTUlQEEyciiqLHxVSRoqUwVgXdaxrmzpXM/5ycXpaA2Wxm\n3bp1XHnllbSrVPDuuxg0GrRRUf363y0CRqPR4w7S6XTk5eV5isXFxcXR3t7eWwQmTpRcEd1FsC6/\nnOjRo2nu6KCzsxNRFAnwKmmbnZ1NcXEx11xzDbNnzz7k+3wk7rjjDr777jteeeUV/P39mTNnDtu2\nbcNkMvH+++9zkdt9lpmZSVVVFX/OysLfYOgvAiDNsJ/rndabnJyMxWKhwW6Hu++m6brriGpogDPO\nGFAEXC4XJSUlZGRk0JqSAnl5ONrb0et0RJSVEb5xIzE+PkTijvMMRHu7ZEFs3+4REQDKyiT33vLl\nkuD/9FPPvj/8QbII163rEQGlUnqdfVdU63QwZ44kJo880ntfaCiMHCm1/d13ksvRnUzAQw9JmWiR\nkdKAfajUuoICyc10NGzeLH2Hvvnm6M77jROoUNDU1SXHBI6VkhLJDTR8uCQC3os3Ky0WrC4XI90D\nz6zQUPZNmkTqi8PxU5UPKAKdnQUUFGRQUiK4B/CBzXWX6OLfu/7NzV/fjEvsbS53u4MA/PzclkBj\nI8TGUrPqv0za0kD17LNpMDZIM7C335ZuqPp6RJcUfPSpKfdcr7S0lFNOOYXW6mrIzGTp0qX8+9//\nBmDjlGj+cJ4Dm8OdAqtWS+4iPz8ps8XNli1bGD9+PGlpabS7XFBaij4oCO0AFVFjY2NpaGjAaDR6\nLIHy8nLa29sZ7n4qU1xcnOfYXvSpdR4VFUVTU5PHCvCukrhkyRJycnK477778PHxGfB9HgxZWVkU\nFhYyd+5cAIKDgznllFP46KOPWLt2LZdddpmnz3fffTfXn3225L5KS+t/scxMSEjotUkQBCZNmiRZ\nA3ffTfNVVxG9aBEsXcqoUaP6iUBNTQ2hoaGkpKTQ2tEBU6fSsno1YSoVyptuktpevJiohgaaDxyA\nCy7o7/Z58UVplv3mm9KgazZLPvPKSin4PHu2FOxfsqTn3AMHpO0XXCDdED1vUP+4wOefS1blhYdw\nec6eLQW1V62CiAgp+cDplLLQdu6U3EjLl0tun+72v/xSOkYUJRE4mrpOdrvUxhNP9Ba9kwDZEjhO\nNm+GU08Fl8tBamqJxxLo6NjDfxvrOS8iotfAI9qVBOmK8PdP9YiAt6VsNhdQVDSa2to+s3jA6XKy\nvXY7AKXtpcQqQ3C5nHy4/8NefeoODGOz4Uu4lCF04ABERLDuiqVcWN7FVf/8gKKtRdhj/SWf7GOP\nwRdf0JYuDcqBzVK7umuvxWY2s8myiZbGRsjMpKioiGeeeYauri6qHK0UREG1weuGu+QSKX3U63Xn\n5eWRnZ1NWFgYOnd5Z72Pz4Ai4O0O6rYENmzYwLhx41C4Zyt9ReBQFlN0dDRNTU394gGDwe60c+NX\nNw7q2FGjRvX6f8GCBdxzzz0sXryYULeVJAgC//znPwkaPVpylR3Fwzk8IuDvT1NsLFFJSZ52Cwt7\nuw0PHjzIyJEjiYyMlGb6c+bQ9NlnRHd1SX5LgEWLiMzPp+XLL2HdOizr12MymaR97e3SGoe//EWa\nraemSqUx6uuloG23NTVrljR4GgzS/7W1kmC8/nqvz94TF3j7bbj7bmnbRx/1dzV5M3u2lHL81Vfw\nwAPSwH/ggDTTioiQrIWAAOmntVUa/C+8UBKbmhpJtI7GEsjNlV7n3LnS6/Rykf7eCVQqaZJF4NjZ\nskUSAYNhM5MmXe0Rgb37z+eV6v1cHWbtdfzBgzB1ai5hYWfjcHQQEmLpZQmYTIWUlmYMKAJfHfyK\nme/OpNPeSU59DqvetvD1F4H889tHPcfoLDocDndM4Omn8f1qi3SNggKM887iw2Eurs0cy+V/upy2\n2ia2b0/B9fhDUn7/LbfQkuDHF19AtdUO+/dT9u67DPf342BTDi1ddnAXTfPz8+OTTz6hoaMBH4UP\nVYaeG25bdDRvnX9+r9e9b98+MjMzJf++Xg+LFqFz2tHr/40o9s40iYmJoa6uDrPZTFBQEKGhoWza\ntKnXcwPi4uJQqVSEu6us5uRMwWTK6/f5dItA33jAYGjpbOE/uf85qnO6WbBgAQaDgeuuu67/zvnz\nexbQDRKPCCBl+XRnM6Wnp1NaWtrraWrFxcWMHDmSiIgIKaNrzhyavv6a6IgIqdQHwOmnE9XWRnNw\nMDzwAM/ffz+PPvqotO/ee6UBurtE98yZkp+8rKxnG0gDfWKiNGAajVIAd6Ay51lZ0oz+r3+VUkDf\ne09yF7rXYQzI9OlStlNiojS479wp5WB7pecCktVUUyMJUFeXdExBgbTGorp6UCupAdi0SXJhKZWS\nJfsre370iSRIqaSlq0sWgWOlWwS6ulrw87N43EGbnGNJ9BWg7MJeKZo6HaSm5hIcPBE/v3g0mlqP\nCDgcRhwOHc3NiW4RiO7lDnpnr7T6cn3lenIackhsthLqF8onT5dLJRo2bGD1pdnUN+yTRGD5cnz3\n1UvuoIICvlAexDplGhHnXcCYkWMwN3XgclkwR3dJJnBDAzl2F2+9BfNzXNy1YAElo0aRajYzWQm1\nPgqcLheNjY384x//4KmnniL/m3zSOtOo1FcCcNddd3HhRRfx92ef5UV3Vgr0iIBGo6GzsxPzpx+h\nNxowmd6mouKhXu9pbGwsJSUlBAYGolAoCAsLw2QyeURAr99MTEwUMTExKBQKurraMZvzsVhK6Ut0\ndDTNzc3HZAnorDocLgd259GXex4xYgRffvklp3UHzL0JCYGpU4/qepMnT2b37t2IokhTUxNR7lhK\nQEAAMTEx0loFN8XFxaSnp/eIQFYWTcHBRHtnYvn4EPnKK7RERMAVV1CWl0d1RQWsXw/ffy8t8Otm\n2jTJP+8lAo899piUNTZsmDTY1tZKA/JADyUZNw5Gj5Zm9q+9JhW9W7SoV4JBP9RqaVA+91xISpJm\n+p9+KomDN8OGSW2Xu92X3SIwbZqUHDBQQLqlRVrU141eL8Ueuj+r6dN7VsKfBAQqlbjg9xMTEATh\nHEEQigRBOCgIwv0D7NcIgrBaEIS9giDsFwThaq99lYIg5AmCkCsIws4jtdXSIsUAxo2Drq42fHzs\nHktgpXM2tydlAi7a2vZhtYoUFFyKybSV+PhcgoIm4Oc3jICAGvR6EbP5IGZzIYIwClFU9LMEmjub\nWV+5niuH38va0rXsr9qJ2mRH+eln3L5IiXPlCvjznxlZ2Ixf0QGUdTowm/GtMtLQmkfej8v52qeS\nMcFjCAkJYdSIUSj00g27oeRdbl9zO0RHc2C3npln+vLKdWrW1dTwpMXCsEAFVy2CehzU1NUQERHB\n4sWLufjii2kvaqfl0xaq9FW0tLTw9ttvU1BQwI8//sizzz7L2m/Xcuqbp3Lw4EEyMjJQKBSEhISQ\n+nQqekMHAWHjaG7+iLa2nmBcTEwMxcXFhLhnld3ulEx3ILWgYAmpqWb+5y6c1tEhzZBbjQVcvuLy\nXp9RdHQ0FRUVLF++nCS3C2WwtFukjBRz16GD84dj4cKFR3xS02CJj49HoVBQUVHRyxIA+sUF+lkC\nCgXNd9xBdJ9HA0bNnk1zaysMG0ZVYCD1P/4ozbpfeQW8n2E9ZYrkLikq8vj6ly9fLpXrTkzsLQID\noVZLg/OYMZLr8f774ZZbjvyi33wT7rpLEpbJk6Ug9EAiUFMjCdSMGT0ikJEhiUdfl5DDIfUjMhK0\nWul1DhsmlRw56yzpmJEje1a+92XZMqmEyc03H7Kkx2+NILcF8LuwBARBUAD/As4GxgCXCoIwqs9h\ntwD5oihmAWcA/xQEods56wJmiaI4QRTFKUdqb+tWOOUUyYLs6mpFpbJ5RKCQdM4JiyQi4gJWrFjB\ne+/9hF6/EbX6PLTacgIDx+DvPwwfnxri4rawc+dIior+RFfXaOLi6CcC7+35kKC6xax4YglrStfQ\nXLwHMT4OQakkd0w4TR+9Bbt386crgvAztqH87Gu4+GKUUaMwtBcyusnFf/9vN9ZOqzQIp6YitksD\nVEP7VnbWSZqXn2NhyrRIWqOdrBozhkaDAf9sNVotdLjgy51fkpiYiCAI3PPgPSgvUGKsN3Kw4SDb\nt29n6tSpaLVakpKSePzxx/nHS/9g696tRMRGeDJztKFaDM0GfP1U5LTVEBd3IzpdT2mBmJgYqqur\n0Wg0PLr+UZ7c+SQA48aNw+HowG5vxGYrZqbnCWQ7USgCqG7bzccHPu4JUruvlZubS2Qk3Hbb6YC0\nittoPPIiKZ1FMtE67Z1HOPLEIwgCc+bMYe3atf0Wt/XNECovLyc1NbVHBIAmq5XoPmmw3TEDURSp\nDAigXhCkLJxFi3o3rtFIweCVKyE11fMc5qampsGJQF/+9rfBWUIpKVLbIIlASIhkUXjTLQLl5ZI/\n32qVLJnRo3v6VlHRE4vYtEkSB5NJOqeuToppbNggxRrg0CIgipIIXHSRJDr395tjnjjef//QmVDH\nSeDvSQSAKUCJKIpVoih2AR8B5/Y5RgS6pznBQJsoit0OVWGQ7QDSd+3UU6HUbMbe1YZCYaOhAYxd\nDrpQEe6rJjLyfEJDVxIS8hLJyX+ltvYN6urOR6Hwxc9vGE5nDZmZm4mMvJ7IyD9gMCwhK6u3CDhd\nTv794yukd/4JY2kmnfZORlkCUSYlAxCmDqPd0o4oipQLetrjA1F+uwkuvpiDmgBC/cHXxw/f2ARP\nsDUpKQlru1NKprCXU6Yrw2w2U1rkYvr0DPbFO4j79mtycnJIv1BBcDDYHfDBxg9IcN/sDaYG4rRx\njBw7koLcAqkompfP9rzzzmPLhi1QA5EpPf54/2B/Yrpi0IYE0GzpxN9/OFZrTzZSbGwsoiii0Wh4\nI+cNLj3lUoRIgcCgQCwW6VGTnZ09KawdHbsIC5uH0VyKU3RS3NZzA6elpfHttw9zzTXfo9NJloPF\nUkpu7gxcrt5F/fqurD5eS+B4EUVXL3fgvHnzWLNmTS93EPS3BHQ6HWFhYURGRvaIQJ9zAPz8/FCr\n1eh0OmpaWqg3mxGTkwfuzLRpHndQU1MTVqtVWmNwLCJwLJx1liROfV0W3TGBblfV9OlSfzIypL5V\nVUnxiOeflyyEVaukrCeFQgpyazT9rxkfLxWx6/vEv4oKqWrr5ZdLmUmrVklZTkOF0djj1urLq6/C\n448PXVteDKUlYLPVDVihYKgYzOAcD3iH9Wvd27z5F5AhCEI9kAd4rVJBBL4XBGGXIAhLD9dQfr6U\nIXf5NU7G7d7NH5sn0uT0Q62GwuZOImhFoVCi0UxDFVhOcNj3REVdTm3teRQXfwCAn98wbLYaxo/f\nglI5m5SUR6mvX0xSsguVCmy2aOz2Rj7O/5jHs2t56W4D4WECZw87nZn+kdKXHAhVh6Kz6DB3mbE7\n7ejDFKiWXEXX+HG86ypCoXThzBwFguARAX9/fwJDfGhoi0SjaKfd0s6aH9aQmgYxUSPRBgTREOAi\nOTkZVYIRH6uAVhtEfUk9W41baTQ10tDRQFxwHNOmT6P6QLVHBPKb81m6eilarZbA1EDUO9V0hfjy\nhz9I750yQEmwOZgQjR9mJziUUVgsPQX2goODUavVhISEoLfquX3x7cTcGUO1oRqLpQSVKpzOTmlW\nJM3qdxAZeRFOewNqlZr85p4Zk81WR0DAy6Snv4bVWgmA1VqOKNp7BZK7utrZsaN3yqbO6rYEujrd\n59Xicv18q0n1+g0cOHCB5/+5c+eyYcMGmpubew3oI0eO9IiAKIqezzgiIsKzDmCg0hggWQP79+9H\nq9V6BKF/PzbjnO52JaWmUuV2sXgsge7A7IkUgdNOk2bDffGOCXSLQGSkNKtPSpIE4aefpDUrr7zS\nIwKHQ6GAESP6WwO5uVLWG0gC8vrr0hqHoRr0li2TgvIDUVoqxe28nos9VHTHAoYiJpCXdzZ6/aGf\nIXK8DFXU4mwgVxTFOGAC8IogCEHufaeKopgNzAduEQRhxqEucs45jzJlyqM8+vJfSC4sJNFVwiOO\nW4iNhfymTiKkCjm4XAp+LIlnQ2UqKlUQBkNPAoUkAtWkj9xKo3EkAC1tTj6LHE/4uBxaW6V1Ak9v\nfJhhwVbgc6Kj4eJoM5PG26UbAMkS0Fl1tJmlxWCiYEN511/4suQr2sak4qsD+wTJH949QABExQdS\nVGkTKWQAACAASURBVBOA1sdJVtQoPl39MZMngyYgiVD/QOo76tGb64hSd6FNWERYmIYR9hHEJ8Tz\nnz3/ob6jntjgWOaeMZeOkg52797NlClT2Fa7jbdy32JF4Qo6R3RiabLQoTHz3XfuSgT+IiqDiqAg\nH/x8wmi2Kt0Ds3QzCYJATEwMQcFBOFwO1Co1Y4eNpbClELP5IBER59LZeQBRFLHZpJsiJORU/AUj\n5446l4KWnoem2O11qNVphIbOwWqtAMBikX4bjT3VNC2WMqzWclyuHj9vtyXQae/EYiln9+5M2tp+\nvpo2NlsdNltP6m14eDj/z9x5R8dVXmv/d6Z3aTRqoy5ZsiW5F2zAYDAY00NJCJBASCAJSS6kkAYp\nFwKhJIQk3PRACBBIqKaY3txwb7JlWbJ6G5Xpvc+c749XGknI3Bhu1vrYa2lhDTNnRmfOeZ/3efbe\nz54/f35uBz8Zdrs91/kbjUZRq9VoNJoZctDo6OhxQaC4uJi9e/dSXV1NWVmZGNbzgejouA7fUllc\nuIWF9Pf3o9VqP74c9J+M6TmBujqRc5iUs6qqxO592zZhLvjII8LUr7n53x/3eJLQwYOwdOnU7+vW\niQt6esPc9PD5RPPZiUzgy2QEyE1L8OciEBCJ7Ouvh4n+nP9kTDKBjzu2dvrOP5Vy4fe/C8DmzZu5\n4447cj//iTgREHAAVdN+r5h4bHp8CdgAIMtyD9AHNE78PjrxXxfwAkJeOm7k5d3Bxo13YP/qV/ns\n+vVckHmeIaqwl2Xp8sYolERVwtAQ/PFQKX9rF3rjTBCoIBDYTjyt5sK3TsMT9XAg+AYu6QhS44uM\njpYQSzhYmGdkZKQBv/8V6urG0cnvotAHppiAzors/QMjQz/DoDagklIolWb2j+yneeWFaAJKjp79\nPrt21c4AAXu5mbZeD96UkRVFRRw4sJfaeaBSmbFqtYyERjjm2MBw3IhWV4HVquPgwYOcveRstgxs\nYTQ8it1kZ83qNch9MqVlpRw7toRhXxvL7cv54ktfZMVZK1Cr1XitYwQCgp0nNAmS7iQmkwK9poih\nsA9J0pBKTXWv2u12tAYt19VoyGRCNBc1c9R1lFisi7y81UiSgmRyjFBoDxbLSs67RI9RmeGSuRfS\n5ppiAsmkE7W6mDffLCced5PNJojH+9Dp6maAQDwudrfBoCc3G2cyJxBNeGlr+zSSpJllwTEZ0Q8o\nRtlsgpaWtTNA5aNGKjVOIjE6o4T2/PPPp6SkhEwmmpOz8vPzczv4QCCQ673Iy8sjEong9Xrp7e2l\n+TiLX3FxMfv27ftQEEilvMTjvUSt4Vw39sDAAEuXLhXAU14u6uoHBv7/gEB5uQChdFrs/hctEiZ3\nIJjA22+D3S4W44suEo1sJ5KsPx4IHDgwEwQkSZgm/u53ojz27bcFY5lc8Lq7xWuOx2AmY3IB3bxZ\n9I0cr7ehp0c0Ft58s0iWf0Tv+WBw3ywzyuy+XcjHRH+JUalEr1Cg+BhFDH7/Vg4ePH3iT5FJp334\nfAIUzzzzzP8vILAXqJckqVqSJA1wFfDyB54zAKwDkCSpBJgL9EqSZJhkBJIkGYH1wBE+JObOFazx\nbZ+Pc6xW8jL9xDBgqh2iPxyjSBJ6Ync3YB4jrO4HpkDgxY4X2TTUSiYToj2owqiw8venb8UZeoA1\n5usJlLzK8LCRZDbLxaWNdHaej9GwgGsuupxE4iSiRl8OBBoNfiyJt4lFO2kuakajyKBQGOnydtFg\nm0ul52zKbV9BodATCHhyIFBVaaZ/MExSWUZTnp6RwTGspWoUCgNmtQABl+cd/FSjVhditWrw+Xys\nW7KOXcO7GPAPMNeUxuf7b3TFOhoWVZFIDBGNtPDNVd9kSekSLll8CUfajpDIj4A2wKFDEFaGCYwF\nMJsVWPRC5tHr5xCLTemhpaWlKNUuPl8Zwe/fQlNhE0ddR4lGO9Hr52I0LiASOYLb/TIGwxq2dh4l\nmNTQbC2aAQKplBONppitW5WEQhXE44PE430UF19FKDQFAomEuPmeftqVY+STclAq9DoaTRllZV8h\nlZrttZNKifVvus9ZILAdv3/zx3aCBSbyAZkZeYErrriC9evX099/O0NDYki91WrF7/cjyzJ+vz/3\n/U6W177yyissW7YM3YR76vQoKiqaxQQikQh33nkn2WyWUEiUSkajx3LMs7+/n5UrVwomoNGIxbej\n40NBYGxsjHXr1p3wbGO/fxsdHcfprzhe6PWicayubvbiXlUldPa1a8Xvjz124rr6iTABELMctm4V\nYHTLLaLyaLK8tL9fnJMHHvhwE7xzzxXH+NOfxHS6aHT2UJ3ubgECDQ0CxH784xP7GxALc0fHdQwP\nPzjjscOtFzL8m9Xg8WBSKj9WPkCWZfr6fpwrzc5mo4BEONxCOh3+yMc7kfi3ICCLLdNNwFtAG/CU\nLMvtkiTdKEnSVyee9nPgVEmSDgNvAz+QZdkLlADvS5J0ENgFbJRl+a0Pe6/8fHAmk/TGYqyyWNAQ\no1QaQzO/k3ZncgYISJYRkvoh0tk0gQBoTTH+67X/4suv3gKSjpaoj0c6b+QbNz7MTbt28K15vyWi\n7uf94c1kAlnKQ9sJhZZTlFlNYf0OHD3fR5YypCospNNhlms30ZM9k3TKSaWlAq0CIunMBAg0UHzr\nm5Su+glW6zqCwVBukaiuMuMdB72+iRIpTiwQx2zToVQaMamVjIZHicU60OqbUasLyc8XN9mCuQuo\ns9bxater2DVxfL73qF1ZS/1ScVxlqofa/FrevOZNvnPKd5jbMJcimqConZYWGS9exobHMBplrIYK\nBgIDE8nhqbxASUkJSvYxGDcSDO4STMAtmIDBIEDA630Nj+cVxsZuQC45hCdcgN2gYsA/QDwtmvQm\nmcDAAIyP1xKP9xGP92GzXUAyOU4qJSS0yXzByIgr1yzqjXnJ1+UjJ7qxWs9BrS4hmZwNAj6f+JnO\nBrxeYdOdSHz8ztPJxX86kDQ1NfGHP/yBeHyAaFSAnUajQaPREIlEZjA9EIv8888/z5o1a2YdP50O\nUFxcTG9vLzU1NZSVleFwONixYwe33347f/rTnwiF9mEyLSMWm1oQZ4AAiMVWrZ5qRPtA3HPPPbz7\n7rvHNbo7XsTjAwQCH0FXrqyc2cQ2GXa72F1PgoDBIOxMTiQmQSASEYNuxsZEGWlV1cznGY2CAbz/\nvmBK//VfU8ndgQFRSWSxCEuLD8bIiLCq0GjEe3z+81BTM5sNTIIAiLzBhg2iee4EIhTaSzzeh883\nNVfC43yRYJkX7xoDfO5zGBWKj5UP8PneJpkcJ50WRSmplA+12obZvIxg8ARmSHyMOKFPKcvyG7Is\nz5NluUGW5fsmHvuLLMt/nfj3qCzL58qyvGji518Tj/fJsrxkojx04eRrPyysVnjX5+OM/HyiCR8a\nKUuJPI5lyTD9oSQ2WSBhW1cIhTKLFC3BEXQQCMCm0J9ZVb6K6xZ/kWPBFAXtp7H2hd/x/G2XclaP\nlsoiEwv063kh80WKxhWkrSNks8spGm+kcAso30lhGIKoLUYwuJOUooSuRDlkPBTrLaRlidHwON3e\nbhoKGnKfWa9fTSaTye0I51SbCDqhtHAt8fEBNFaQVSYUCgN6pYK/HfwbzlAPFdZm1GobeXmgVqsp\nLi7mjOoz6PJ2ka/OEI/3ct33r6H6pDgKhYEChZNaa62QphSi+taaaca+6Ch72lwoDUpSqRQmU4ZC\nU/VxmcBnP1vB2nNs7Ag15EBg2NeGLKdRq4swGOYzPPw77PYb2L/fSvXKFkZGKkgnRqmz1tHp6QSE\nRqnRFNPfDwMDNcTj/cRifej19ZjNKwgGxc0Ujw+gUOjweNy5CY++uI8KSwVSegCjcQEaTfFxmcBk\nLnX6Bs7rfQOdrmaGpv9RI5kcQ5K0x2UTyeSo2J1PxKTJ3nQ5CKCwsJA333wzV047PQ4cWI3ZLJCr\nurqa8vJyRkZG2LNnDxdffDF33HEHnZ1bKCn5PNFoZ+51AwMDLFy4kEwmw/Dw62Jh/JBGsf7+fp58\n8knOOuss9p9gA1YmEyQW6yWTif/7J8OHg4BSKQwSzzrrxI4zPebOFcZgn/mMWJw/8xnBAo4nmSxb\nNvX+E+NDkWWxmNfUiPnRTz01+3UvvCAkqr/9TejGxcXH722YBgKe7A7k3/5GDOs5Tv7mgzE6+ghV\nVT8kFuuZsKlP0tPxLeb9q4JgZZBszzFMDsfHYgIDA/dQU3MnkqQhkwmTTvtQqQrIzz9rRsn3fzI+\nUe1sxoIMDw4P8ymbjdbRHcSzKkqlcfrTfqwNaQpHOmF0lKNDo9g0ZcjeWnq8ffgjUZ4a/CV3nHkH\nd5x5Bw+PLeXMrpPorDufa25/HnXCQEm0jzX2Czi1fwCDB6S4AoOhEW1PgHn3GGg+8E/0I0r+/sxT\ndHS8TlbTxFgsiVIOYEwpSWSVHBw7iF6lJ0+Xx+23386xY8eARRiN5DTm2koDYRcsqPgc48NjWEsA\nhQWl0kiR3sxzVzzH4qI6zqn/NGp1IWZzioqKChQKBWfUiEXFqIwhy2mWFJUSjHSQbz2fGkOCMnPZ\njPNljjdT1HyUlqEuyotFwZbBkKbUUsdAYAC9vm5GhZDVuglLwyWEpSpRAqrPp9qoQqWtZWPnRlS6\neiRJSUXFt3nj8D78Ra8T9TfR3z/E/OL5uQqh6UxgeLiGvT3Pk8lGUauLsVhW5fIC8fgARuNiwmFX\nzpPMG/NSYSlHk3FgNM5HrS7+UCYAovQcIJEYIZEYorDwMuLx/xsTMJkWk0zOBoFEQoDAZFJuMi8w\nXQ4CAQLpdHpG6S5AJhMjGm3HbBbINV0O2rNnD9deey3f/va3+fGPN2O1XkQ2GyOVEpJTf38/ZWV5\nWK0y27dfNgUCx4n77ruPr3/965x33nkcOMGBLZlMCMgSi3X+2+cCoknsg3YSk/HQQ6KS56OG2Sxe\np9EIWWeyg/nfhckkfsbHxeuqq6ea7T4Y0wc0TSbta2qgvx9ZzjIwcJ/I+0yAQCYTpbX1IhKXnCqm\nya1bJ3yTPiQymSgu1zOUlt5Afv4Z+P3vMTLyJ3R+PSWmS9Dr5xC6YA7Gnp4ZIHCiJZ6RyBGs1rNR\nq22kUh7SaR9qtRWrdS0+37sndIyPGp8oEHh5QTtz9Hqut9vpcO4mI5mwSx6GEimyBWnKoiMMvd1B\nj3OEMosdVaiWjvE+nOa3aLQtYFHJIowaI3u/spfFnlG68k9CUijYIq2lsHUTlzVfzM2bmtDWnYSx\nR6KsTAl9fYyuu5ZlQy9iiFh58MEN3HvvU2gMS3HGgmSyEn/56gbe36pi68BWGmwNxONxfvWrX7F/\n/35iMRVms5pwWNyMhVYZi9FE0BUl4JtLUxUoVVaUSgPIcc6oOQOFHEGtLkCtLsRiSVA1QYfXVAt5\nQS0HAQVzzFqyKQcpzSIMKgXp1EyLYn1oPt78t3FqdlFRVAOAwZCkPG8ug4FBdLo5uV6BdDpIMLgL\nV7YKvaYYjaaMSKSNZYUltHq9XPLUJTzStptly3bzRNvrvFV0IT9Y+ktKTSsZHh5kQdEC9o2ILuJU\nykk2W0w4DEplLaHQJvxpHZIkYbGcQjAo5ibE4wPodCtQq8XnDgZFYrjeYkMmi0ZTOoMJyHKWbFbY\nSfh8GX7+80sIhQS4er1vYbWuQ6er/Uhy0AfvvVRqHLN52SwmIMsyyaRIGE9KRpN5gQ/KQYWFhaxY\nsQKTyUQgHuDebfcCEI12AFmMRiGHTYKAw+HITUL7zne+SCyW5qGHXiUcruG55x6ire23KBRR2trq\nsdvyqH08Sba6IpcvmIwjR0QJ/Y4dO7j88stZtmzZCTOBdDo48RlPcJ7G978vungRNtojIyP4fO8R\njx+fhQUCO2b5VR03Xn5Z7OBtNiH5nGhys7ZWSEIDAwIEmprETn86VRwfF8AwOaBpMibkoETCQV/f\nbfT2/jgHApOFE8HgTmGqt369MOybHrt35xiCz/cuJtNSdLoKrNZ1OJ3PMDBwN/UvlsGaNeTnr8W/\nQsXKvXu5c6I/JJtNsXfv/Bks83ghbO6DqNU21OoC0mnPBBOwYrGcQjzeQyLx75nKR41PFAi4DFF+\nVewgEj5En6cFtdpGheTFJatxpmVKYh6euKuPkdAItYVlGBK1dDr7CRa+yzl158w4VpljL22Gk0gm\n4b3smeh3b2KFcoxTR0ZRLrkY0xEF1RYf9PWRPutcHOpa9OkyRkcDbNs2hmvMji/m43CHhog3wIG9\nCBAoaGDz5s1Eo1EcDkdugfD7NwOQzYY5ddUSdu3ahdtdwrxq0GoKUSgMZDKiNj6d9uZAYMmSFLfe\neisAhYZCdly/AzIecaHJHuw6maM+H85Ufi6hOBkW57kssawjvfb7WLVCojIY4pTlNeCKuBh3V+aY\ngM/3NhbLanyJOPm6fCyWkwkGd7LSmmC/28sbn3+DX+/+LR3BFD94+4eon9jK98+9hrq6SkKhIa5e\neDX/OPwP0TeRdOJyFVNVBVpDKRWGFF2BMI6gA4vlVILB3YImy2kOj2Sx1x+lrDrC0HAWf9xPnUlJ\nIF1Ia6s0gwk4nc9w7JhIXgYCY6xe/TLhcF/u81ut63MlwCcS27fPLF+X5SyplBuTaeksEBA7ZQmT\naXFOq/8wOaiysjI3K+GY5xj3bb8PWZaJRFpRqwvR6x3k5eWhUHRjMPTS2tqae10sdoh7713Fz3/+\nc666qoNvf/tu7r77Hmpr53DaaSFWFDaz/E2Z9OcvmTVpbOtW+NvfMnR1dTFv3jyWLVtGS0vLhyeH\nf/5z0bWLkIOUyjwikfaJ87uLdDpwQufxvfc2sn59E4cOnYPTeRwJBjhy5DICgeMMBP9gLFuW8zdK\npTwkP7CxmYyurm8RDk+bl1BXJyShSRBQqUSfwqFpBodvvCEW8Q8m66urob+feLwXg2E+zvF/4av2\nQHk5yaR4/9xnv/de0eE9aX2dTguX2AmwikSOYDaLvgardR1u9/MU2S7H+GLLBAicib/ChXnfPs6b\nyOf4fG8RjbYzNjZV0STLMocOncuRI5/G4xHGesnkGBpNCZKkQKWykUp5SaUECCgUGgoKLsDt/mBN\nzv89PlEgUIEe18iDjI8/zkigA6O+nEpViJCmAg1ZjIk49ngfuqJRFmYsrPQr6Hb1kqp4l/PmnT11\noGgUi7ObVhbi8UCLdS3SO++gu+JiflPxa1zBHyL9o4nqbC/09mJaWMsbqouIZirR6bJ84QuFPPbg\n83hjXt7blKWusZzDB9K0u9ppKGjg1VdfxW63MzIyMrFAFBIOC2qaTgc56aSl7N69m9FRidJSMOrK\nUCqNZLNRMpkYspxFodCjVtvIz/dz3nnn5T76KZWnkEiMkJ9/BrFYF+V6Ja/2HyCmqCIU2sdtt01J\noeGgmpvmPsDF47uYl70BAIMhgVZtRZuy89DTWdJpL/7oGPt7/oDNdhH+uD8HAr29P6bOks8t5+7g\n3PpzuWTeJZzx6BlcXf4TllTMQ62GxsYqVKpB5trmsrpqNY+2PEoq5WRkpIjqashaxQJks8znl9t/\niUZTiEZj5/q/rGcwnOCNwa2oql8jtOYmugdDGNQGClUhepxW7rsP1OoCMpkg2WxqwrCua+IrFIt0\nLCYkqHD4ABbLSeh0VScsBx07Ri4XAWLRUSotE3mFmQ1CyeQoWq0dg2Ee1778XdxRdw4EPigH3Xrr\nrbnyPHfUTTARxBf3EYkcoajoCoqLB/jDH/7A8PBv8XhuIh6Ps3LlSiRJIhw+SFPTarZv3862bbfw\nxz8uYcMGN3PmLECp1DFXp0OZgUw2DKWlbNy4kZdeeolkUnhoHT06QnFxMUajEavVSnFxMV1dXcc/\nAXv2CJM6IJ0OYbGs5KWX3uLBB+9mx4617NxZRW/vbf/2PB49+hiDgzGqqn5yXODIZlOkUk4CgW3/\n9ljTY2joAYaGjj9S0+PZyMDAXVMP1NWJ0tBsdmrY0rJlM+cX9/bOtsCAnBwUi/VgNi+nTvN1HFdq\nQaEglXKhVObl2Ct6vWhY+8Y3hP33yy8LGevZZyEUItL9NoYN4j0NhiZKS2+gJvpZkXsoLSUvbw1B\nVSfZIwdzNHR8/Ens9i/jdD6JLGfh6FGi3/8s0b5N5G/oo+vQlwAhR2o0QvKdLgepVOLvLSy8FLf7\nxY90jk8kPlEgkKdREokcwhfYTSjuoNBYS6UyREZTRFEqjJSGy5f1sWzNCJc+c5gXt/+CB297mlJG\nWF62ZOpABw8Sq52PK6jF44Fgcb2oYPjsZxk+50scPKikO1OPPdIDfX1Yl9Xy0+RPGTv3eoqL4frr\nz2Owe5DRLaPs3JLg/Isqha+VD+oL6nnllVf40pe+NA0ECsR8AcSO6+STV7Fr1y76+4epa1jE8op1\nOSYgNL4CJElCoTAA8gzfflnOkEq5yMs7Xew6lCle7NqBWjefUGgvR46IEmcQTNhshtU1K4m5RL26\nxaJHkhTo4tUMhxwUFJzP7oPnkQxvxWa7MAcCVutadLoaVix5g3lFwkTujjPv4MblN1I99k0mJk5S\nUjKH4uIeZDnL9075Hr/Z+QCplIvBQQECKaubVEbByupL+HvL30mkE3R2ncIi+2FUwbNYEf0t9epG\nktbDdA37sOqtmCUPHWMmIhGm7XrcE81lYoGfXKRTqaNkMjHi8X4MhqZcR/iJxPDwlC0/iHyARlOC\nVls+iwmIG9COXj+XNwdaOOI8Ql5eXo4JTAcBpVKJamJuwWhQMJVeXy+RSCsFBeehUiW44or1+Hzv\nUFS0loICHStXivaYaLQDg6GZxsZGSkqWYLNt4Ve/uoRLLxXSS+2Ejpxxi893991386Mf/YjGxkZ2\n7MgyNKSaMWfhf5WEwmGxe0ZclxbLKp544jCPPfZXrr0WFi9uY3T04RkJ6sl46qmn2LFjB5lMjL6+\ntwmFUkQihlmztcV5FV5cHxUEotFjuZ349BANi0J+ykkotbWwaRNybTWByQX7gyAwNHT8PMqEHBSL\n9aLX16EfzJIoEd9fKuXCal1HJHI0x9Q5+2yRV7jySvj1r9l41TJcJy+CP/2J6ND7GP+5HcbHkSSJ\nxsaH0by6Hc4/HwC1Oh+1pph4pRb6+0mnw3g8r1Fbew8KhVEwjgcewFPWj63gIsqKv0giMz4hQ46g\n0dgnjmPLyUFqtQCBgoLzCAZ3nDCDO9H4ZIGAOk0q5SYUOsDy4jp02lIsShlNNoot5kVhyMPi7sM+\nb4TyPjc/Oe0xtlSk+PLOcpSKaZn4vXtJLVnB0JBwJbUVSqLO+O67Wb5cbJA6EnVYu3aDVou6MI9s\nnpX28Qx2u57i4jU8t+E5wq+GUWolFjaFaZxfAD2gdCuRZZn169fPYAKTDU/pdJAVK07m8OHD9Pb2\ncuF5r1JSdBlKpZFMJjoD2SVJIpUq5N57pxJRyaQTlcqK0dhMILCDrNJGIpvGmn8agcAOxsaykxMt\nsVr3IMvrqauLMjCgw2DQk5cnLJwU4SrGYgM0Nz/DYFTBaCyLTleTAwGDYR4rVuxDo5mySqiwVPCb\n837Dgf0KVqwQj+XnWwgGCwiFBji18lSKdHpkSUd/v5bqakhaOvFE8inOW0xTURO/fX4Hr+wsYbkt\nQ+vhejo6iigwxwlpOugdc2PVWdHLY7QOG3JJ38m8gKi2GGXbwBb8qQ7CYQvQRiRyBL1+LgqFBrW6\ncIJRzTSgCwRym95cDDtkfNEpzTiVEiCg0ZTPSgwnkwIEopKdVDbDwcHnSCY35nICxxvUA9A5LLyT\nfvfEDsbHj2A0LsRonI/L9SwKhYHGxscoKsqwZIlIUgoQaOTw+GGUmloArr/+bq677joAyiaknYxH\nXE8Oh4PXXnsNnU7HwICHbBZqa6dAYPny5ScIAiHM5hX09UW46y4DGo0Jvz9LeflNDA7OLtp7/vnn\n2bRpE07nP4nFhEne8HDsuAuQYFHVBAI7keUMbvfLJ2RzEIt1k0rNTsKm034UCh0VFd+kp+eHjI//\ni1idAVpa8J1m4uDB00XV29KlM5PDQ0Oz8iiA2KUHg8TDx9Dp5qB59l2SRWLpS6Vc6HSVGI0Lc865\nAPziF6JpaXCQh6pcbFk/D/m2HxKtkDEsvWxmZdLzz8+Y5qbRlJJaMQcOHsTjeYm8vNVoNEWUlFzD\n+Pjj0NODe2mUwgU3ovjqTaiDEglXR46NAqhUBaRSHlIpb269UKnM5OWdnpOP/lPxiQIBi9qDybSM\nYFpiqVWLWm1DkjQUEsbkHySbVwB9fYwFRsjvcRCxn8Xflyr5QqdnZgZw716s55xEaamwNrHZEM03\nksTy5UI6HDPNQfneO2KHgSgk6OgYpKFhJTbbhSyavwjd1ToWXSZhLxpm7rxKOAQ/++bP+MIXvkB5\neXkuJ2C1luR2Q5lMiLy8UubNmzcxvKUChUKFQqFDlpMkky5UKlFZIfJchXR2TgeBUbTaMnS6WmQ5\ng14vyuSqbctRqwtQKo/k5oOvWPE3stkj2O1fordX5nOf+xSlpRNU2TmfYXkfCoWKv/Yr+doBGX/c\njz/up+tI/v/q2LtvHzkQkCQYGWnG5WpHkiROKWsiIRvo7xcbLJ+yg+c3f4a8vNNYX7eef+19C/Xc\nGEoJYqkyHhv7IzqNB5PSxlHfAQr0VlRpB11edc5+XqUq5oornMRivSgUWr7x6tfYFN/IoUNno1S2\nEQ4fwmQScw+Cu4NotZWzJKG3395Ge/uqGeBwOLAF7/pLCIcPkUg4SCbHUatLUKnykOVsLlk6ed41\nGjv+jADRg/1PoNU6c0wgrozPqvDYvXsfDl8rSkmiP/AEsuxHp6vGaJzP8PCDWK3rUKlMPPTQ5SxZ\nkkaWZaLRDvT6uVz0z4s44PFQV/dLjMb5uWMWT0yIk72jZDIZxsfHsdvtrFmzBqczCugpLJySPE47\n7TQ2b9583O/R1d9PdMIlM50OEgrpSCQk8vODFBeX43a7KS+/Gbf7pVx3N4ideE/PVg4dup/eQ1N0\n8QAAIABJREFU3ltJJgXoDA2FyWRmg0AiMYLJtBCt1k4wuIfOzhs/VLbo7b2NZHIcWZaJxbpJpz2z\nnpNMjqDV2ikvvxml0sj4+OMc1f1CzH1Y6UejKWV09CGRE+jqEi6n4gMeHwQUCqiqIhY8ht6rRbOt\njaQ6xL8O/xNnsAu1uoi8vFMYH3+C7u7vEQ4fETmH556DN99kLO5mT5OF+E++jFpfiuqqL8GE5To9\nPaLfYZodt0ZTQnJBGRw8iN+/BZtNDPopLb0Oj2cjYyWHiSiGyM8/ExQKdCED8c6tx5GDvDM2jQCF\nhZfhcj133HP7ceMTBQIm5RgafRNtgRSGzDHUahsKWcWyfBuVUT8H40NkvR6MXf3ItgIMJTbabSej\nzehEgwgIzfD995FOXsV99wmQnt5vs3gxOJ0QLqoTg7onQKC4GHp6Bmlu/lQOjQsXFqJuTmMx+6mu\nXIApaeJ73/0eP/vZz3I5Ab8/QH5+MbKcJJ0Oks0mUCgMnHzyycyZVmc9Kf8kk44cvbv2WiaAbupG\nSCRG0GjKUCjU6HQ12MzzseltzCmYQ17eGZSXb8XjgWw2yYoVz1Nfvwm1upeqqie5//6bsVjEjjVz\n5DKGzRsIJ8McdR2lNr8WR8jBwLifn92anztdHwyfT1zT8+ZNPebxNOH3C++gxoJSQmllLj83FGvn\npQ1fRaksYv2c9RxLvUWXqo2sIo/8ejWRBX9Dxk2NsZne9PuUGQwEk0oyukyOCchyMRpNN5lMjJS6\nkWOebvYnWunrPxuN5hjh8EFMpsVkE1kOnnIQTXZ2hVAotA+7vZX9+2/ILdZjQRdy4VHa2j7H4OD9\nOTlIkiQeG9Txxz1i+HwkGWHzwC60WjuuhIQEjCeNGI0pvF4Xfr+fW9+/lTd73sy9Xzab5dChm9h1\naDm6YCPmqn2Mj89HOuVU8hyFxGKdWK0ieVxXdzqRyAGSyRHRde4fZSg4hCcWoKpqprlZfihEQgLZ\n58LpdGK1WtFks/xk716iER1gQaudAoHGxgT9/cdwTEt+pFIewuFDyOEwmtFRyGTIZIJ0dzuZMyeP\nkpKrcx5IanUB5eU30d39ndx5Gxz8BePjftLpVTQ3P0UopKOuro7BQf+HMgGNpoy8vNPp7PwqmUxs\nltwWjUaJRCI4HL/H799MMjlCNhs9LhOYvAfU6gKam59k4cJXSSsTeE9V4KkYpLn5KUZHHyGrkUTv\nweHDIMskwoNEiz6kD2LOHGLRbvSPvYXy89ejUOi5c/P3Gfa3oVYXYbWei9+/Fb//XbzeN8RrzGZo\nasIVdTEWcxK5+VMYzQuEXORwCMfLDRtE9cG0clC1uoRkfQH8+c8kXnkU7ZuCrWi1dprr/8GxG3wU\nFKxHoRBNdrpsMfHhfR8qB00HgaKiy/H53p6xgfm/xicKBLTZYbpCMll1A9lsFPXLm1HsO8S5Fpl1\n7l6sthpcBTpW7B9FWrSY/Hyo2fQ+myq+LMysQBhbWSzQ3MyZZ4pqsenDr/R64XWVrJxYoCcGepSU\nwODgQK5cE4SJXCAlvlwpW05oPMR1112HJEkYjUY0Gh2/+U0fJlM+Gk0psVgXSqUJSZJYt24dKya3\n0xOhVBpIJIZRqQoIh4WcWVtbiFI5nQmMoNWK3YDB0IDBUM/gdwYp0BegUKxh4cIteDzg9b7D4OA8\niormYbdfSX39AbxeUQEiy+DvbkSRyOf3e37PwuKFzCmYQ9f4MF1DfmpK8zl6lOPGpJXL9D6XQKCZ\nSES8oNZsxZVICVubygzdvi6KpHkMD8Ncw8nEDT0cCeyksvJHFDdZQJEhktWxpKgep+598lVZrtkT\nwVwYzoFANlvM/Pk7SWWq2ePNclp5MzqlzJgqSzJZjMfzMv39q3EeE+Wj6lTdrAqhVKqLJ564A6/3\nWK6CxR0OgGmcWO8wgb6NORAAGIopebNHdHy+0PECP939BhqNnZHwOI35NsZT+VithXi9Y3h9Xryy\nl0dbHs2939GjjyFJYJ9jZa7hdJwpK462Bti9G5ND3Nz5+aKr1mRaTii0PycFvd4t6LwrOlsPN3q9\ndKmVyF43DoeD8vJy6O+n4sABbHIScBIKNYs5xJddxsjIb1i1ysCrE9UsmUyc1taLaGk5C20qRQZg\nZIR0OkRn5wiLF59BVdX3KSwsxOOZLGX9EbFYF4cP/w+Dg79gePhB3G7weOJYrWfjdrtZtWoVfX3O\nD8kJCBY1mceqrb1rVuL9zvvv5La7biGTCRMM7iEa7cJgaMp1lx/veJMhSQqqqr5P+21gzswlP38N\nRuNCXK4XxK6utZW0e5DDP0/QOXL8eQTpB+8hSxL1/Q/D176GrCwgnhghnXKjVhdhs53HqlXHsNu/\nMquXwhlxMh4ZJxo9isEwX9wct90Ga9YI+4oJKejZtmfZObRT2NU3FMIjj5BcXI52w1YAsnIWf0+K\n+X+xU1n9g9zxdfoaEt72GXKQWm0jEB0iHB/NbRrF4wXk56/BPfqfYwOfKBBQpfrZ6/ZSXii6EdWP\nv4wUjHGVysXa7i3UVSylzRTlwvYMqiXLsFpFxdjuxi/CM8+IXx59VHQ0TnQhPv741OyLyVi+HNRz\nqsSXOU0OGhsbnAECVp2VjCQSgj6fmQ+GVltGMNiOx5Mn9OToMVQqMbDj8ssv53e/+13uuceOgVJp\nJJEYRq0uYHwcSkuZqKZxMzLyF0Kh/bldEEB5+U3YbBdjUIvBMeHwGSxevBWPR2Z09F9s23YVKhXo\n9fXU13cxOhpEpbIQCAgDRW3vp7n3/XtZXbmaCksFj7/gQGXy8/lPfzgITJeCJiMWayaVEi8oM+oZ\nDodxuSBtGsRmsLGo0cT27bBvj5rC8Jk0FDTQUPsDAgqxYISzVlZUVpA09pFK+4lms6hN/hwIpNPF\nNDfvpNMf4ZnuVublmViTr2MwfzeBwHwSiWHuuGMZrz4uQECTrJ4lB6lUXVRVLWTz5u/idD5FPA7R\nrOg4q360msKXXAQC7+dAwJeS2DVyCFmW2dS3ieFIGJSFOIIO1s+7hr7AMAUFpaw81sXpjmHqy+rZ\nNfAah9uuweN5A6fzR2zd+mcwePivS1fiShs59g9h+qV366mu/ikbNxby3HNgMi0mGu0gHD6UA4EV\nZStwRT4AArKMZmyMlqyM7PPicDgoKysTZm7AXHYiSQMMDxfmPP0D7k2sWpXglVdembjOvoxWW43d\nfj26TJoutRr6+kgmwxw+PMbixaejVhezx7cHx5jYrSsUWubMeZiTT/423d1vUl39CslkkrExIXG6\nXC5OPvlk+vtHj8sEEgmxcbHZLqS+/nfYbBfPAoF3o+/yRvANJElLKLSXWKwLs3nlBHtOH/d406Ok\n5BoklZFi+xcBKC29Frd7AyxYgNx6mPbOL2F0mgmFdpPJzHYYjZWC3tqM1C2cUb1JqDDqIeNHo5ma\ny6HXN+Qq1ECwxPOLo1Qr24lE2gjLBfzg7R8I47mDB0U/xZlnAvBy58ts6t8k5KCsBy6+mIQ+gqY3\nCO3tbB3Yynf++Ck03losFlEo0OHu4OqRY8QTgzPkIJWqgNFAJ97IwAwmAFBcfDXOjd8+frPcx4hP\nFAgok30MRBUYTaLSR33Tj1CYC8gebSEbD6HLK0Xf0MxJw1lYtIj8fNHcl7FXwLe+BTfeKLzNr7km\nd8ziYvEzPa65Bi66TC26MidAoLQUvN7BWUwgIwktyes1zThGKgXBYDkqVTu9vXloNKVEo8dQKi2z\n/q5oKMuext1IsnGCCVgZG5sEARtlZfvp6vomg4P3zdgF2WwXYjROuVQ6ndXIso6LLvoufv8btLSI\nYQJ6fT12ezcuVwCVKg+3W/gwZVo/Q8FQAadWnEq5uZzWAQcZtZ+lTR8NBDKZJiSpHVmW0UsJvAmZ\nqiYnXb52mgqb+PrX4de/FnX5awqu5qoFVwHQ5RE3UzBrYkm5uNGcIbEwp1WBad3AxVRUdNMeHsef\nsRAJHeS8ijA92jdxu5vQaOx0dGgYOSJAYGBMxYP7X53xGS2WLi64oIF//ONC/P5NDA9H0JUIEy7Z\nESfPU04wuB19dxxuuAF/UiKYiHLMc4z3+t9DJcFILMNwaJiFxQtRSAq01mIWub18IRhidf1qvjyv\nHodnG93dN/PWWz/k6aeX0OlwsbxsOSPhcRZGHGR1epQjLo4du5MbbxT+ZcmkHr2+HpfrWbLqGvY4\n9nDl/CtnMYH//i8PKYWOUZWC6IgTh8NBcbGBaLtgLI1SOzpdiP5+KZfwtZuu5KSTsmzevJlAYBCP\n5xUaG/9OTflPUMnQkkgQbz/Ke+9dwIYNV9Hc3MxwcJi+RB/7uqcSoSMjRuJxUCpvx+NVUVZWlvMx\ncrlcnHLKKfT0hAiHkxPXRAyfbzMwtXNXqwuoqLiJ7dvL2bOngScPP0EsJRZkf8qPO+HBZruQUOjA\nBCuah0qVTzrtxeUSG+tnn53NBEAA1U9+0c3B4W9NfN8nEwrthYULiY7tIpw4QuOWVRiNi9nT8/As\ngI3He9Dp6nLMvy8Y4MK6k1HKIdTqKRAwGObOqJZyRpycapO4omQIj+cV2vxR7t9xPy92vCjWj+9+\nF9Rqdg7tZOfQTrYPbp8YXDVONpsknfajOe9qePppBvwDLA6beDndRiAuwHRLywBHvFHiKvcsOcgc\n9qJLhAUI+Hy53awt73wC1SGSdcf3lfqo8YkCAYvaiCsWwqopo2KDAu1lN6KwFiPv2YGcZ0Sh0rNw\n1afEkxctypUL5+UBP/iByLSefvpUu/iHxNq1WazW7fxo+XK8E3XFJSUx4vHgjMEiVp0VhVREJqPE\n4zEzvSdn40bIzy8jnQ7R1iaYwOHDnWQys0HA3Z+mkhgECnNy0CQT0OsLWbPmMcrKvo7X+zaRyOFZ\nu6DJGBsDp3M9tbV7UD34Gsq00Ln0+jlYLP34/T6USgtut7BF0fTO4+G/Psyq9CrKzOUMR3rJkmLp\nAsNHAgGj0UYmoyOZHCGVcpGIlbPyojb2OPYwv2g+F10kClEeegi+euqV3HqaaH7r9nVToC8glNFT\nZRYgemzUh0HSEU2HSaUEmHo8ZdxwQwve4TW44nEuqLBSoJFISVEGxxrJZk9nZAQ8XWIB2rInzWs9\nU39AKpXAYhllxYoa7HYrmczJOBxvotaEIaVDOTqMarLRcn8/mbfewZNIsLxAwd8P/IFoKsoSq5L+\nUABH0EG5pZw51jnE9PnYYglOzsqcZqjjFFuWF0aMZDKd/PrX3+Lmm8EVcTPWVU6BvoCV2o24V11E\nvGeYa66Bl14SExwfeYQJT6Vd7PPEWFW+ipr8mlkgsOPpITrjlch5eYQGPTgcDrTaPfgOPUJcpWae\nYpiqKh0jI5A6JgCu1PgZSkoaWLiwnnfe+Scm02KUSj3KuExEgjG9GvfeXRw5sgafr4Tm5mZana1g\ngCP9U4a+LS0tALy25zWufexampubicViRKNRvF4vixYtwu2+hX/964vIcpZgcAcdHdcCMyVMgBdf\nVPPoo3fxw3d+kJtDEc6GCRHDYlmFVluOx/Myen0DanUhqZSH1tYgq1b9mLvugkOHZjMBWYY9e4rZ\nskWauOYbSKV8JJvKCCjbyQ/VoSirwmpdx+tHfs5Zj5+FOzols4ryUCEB7xvZx/vOECtL69FKcdTq\nQvbvhwcfFPNI0mlvrsDAGXFSYdRwf6cCtaaE7nCKs2rP4ubXbyaYELr8e33vcdnTlxFPx9k6uJXf\n7nmUZHJsAsxKkK66Gp56ikH/AOupR9kwl9/u+i0Ag243UWWYSGGCdMqH5tPXw8svoz4ygI4ESnVK\ngEBnJ/zP/0A0iqpnhDkbislq/zPL9ycKBPLUFnxxH8WhDPUb7Ch1eUhFZWQP7SNrs6BQaDHNWyA6\nAuvrmazay8tD9AG8/LLQ6P6X8Hq9rF+/nq985Sv8a98+dhwWXYl6/SBqdSWKac5/Vr0Vo9JGKFQC\nmGZYjv/jH3DSSeJCHRjIY2TEzvh4Z042ikSmBhZ5BwTdzXqKJ+QgwQRKSsBoLMTvL6K29i5stosI\nBnflKOEHY3QU+vv/zC9+9B6J5yNU60QSTKnUk80Wksm05ZhASQl8WjOKMq3EFDKhiZeTtR0lX59P\nTY0k+iem5ZZ8PvjnP0V/zKS54mQUFEA4LPICyaSTscFa7EsP8tf9f+X6pdejUMDVVwtWNh1A3MOd\nbP9rFn9ajVIOo43W4CPIBfUnEU/HMZnEedq+s4re3sW0HFzDitIF2NU+up1WUsECdh86C1n+K7YL\n/oeIv1+c7z4Vvkws15vx2sFX2Lv3Qm65RYXugp/ydMscYrF7iCQVSO4mSgIxPO1dpLLQ9rIHaXiI\neDTE+XWn8fs9D7G2+gwq9Vl6/KMMB4epsFRQX1BPUKWlNJXlgASnH3SgSPTwz5YQ3/iGhEol8b3v\nZ5D0fm75ej7hWJAFgSO0NV9BomuIxkYx92T1alFtqNWKxoudYwOcU3cOR3YXMRqYAoHxcShJDFJx\nShXOVDHxsQAOh4OCghgl8dM4WriMFeajXHnlabjd0POOuG4V0Wr0+nqqqiz09h7EZBI9H0QihAGp\ntoBoWxttbSeTyZRjt1dyxHmEhbUL6RvtyyWDDx06RF5eHvuO7ONIzxGKSosoKSnhly/9EqPRiFar\nRaNvpL1jIZlMiGTSSSIxPOHpNHPn7nRCS8upOMNuhoPiJohKUdL6LOl0BWbzScRi3RgMkyDgxuE4\nwvnn38dPfxrKMQGn08nll4spcGNjwlH2978X+VhJUmA2LydkHCbQkCCvXQ2VlZjzzqRK4+KcunM4\n74nzyGTFzi0W60GvFyzgz/v+zDtO0EsR1IoMKlU+t9+Z4Gd3pZBlBTrdnJyVsyvixKpK0RbOo27+\nVnr8o1y76FpWV67msZbHAAEqn1v4OcxaMyeVncSrvTuJxh0T0m652AlkMqj27qfcFadh5XlsHRR5\nAmfYDco03iJQBxVI0Th87WuoLvsCKROQBaVSNyF5ZKClBQ4fpiy4Bp3uPzNr4hMFAiaPE1/Mh80V\nyZV6KUrKyWYTZAtMSJJGDLhYtw5UqhwITM7NprFR+IN/SHg8Hk455RQWL15Ma2srF198ca7bUpIG\nyWZnWtoW6AswKgoIh0tRq825+nwQC3xjo1isly7N449/tFNV1UkoJD7Mk08Kpgjgd0yCgI1kchyV\nqiAnB5WWXsott2wCzNjtonPww5jA6CiUlipZbBK7lBJ1Mvf/VKp6zOYDZDL57NwJxdYsF6RHUNXq\nSblS+AcrBAjo8gmHxama7kJ8zjnw97/Dww/PHg9rtYLX28zY2N/xeA4SdTfxz4H7WVC8gIUlCwFy\nQ2Ocf9kA99xDJBmhpsdDY4+fYFwilXLz6aYr8GYTXDrvQpKZ5BQI7MlHpwvTF4izpGQFshxj97ar\nIGZl2BPi2LE8tAtepcAo8gARXxBvCpzujSQzSS5//bPsP7aCxx6DSMEO3tpvI77bBwYPVa55JJUK\nKgMSj42dTGz/OApkmkIFLLTcRjSToCJdQI05j05PJ46Qg7/+qpwi1RxcqQwaLuZV1blUvrWZcdcZ\nRHpOYWBAFBuoLT7y9XmMjmWoHFIQ0EscUi1HOTqEoWkrd94J774rFMddu85CodCxw9HCGTVn8Odf\nFzHgnjLOa22FlfYh8hdVEddVkHbHcDgcWK0hlA4327SX0Kxuo7k5TTQK4UNiF+/pD6HXN2A2pxkf\n78FoFKW02WCQkAxygwZpYJj+/rlISh8Oh4JWZytK5zlkwhk63OIiaGlp4eKLL6anpwdCkNAnyC/M\n52fP/gylSVQJpNY9RLuplXQ6kPNXCgZ3kk57UKunGLTTCXOa2knJKfY6RBlaQpkAMzideiwWAYg6\n3RzU6gK2bpUZcraiUGSxlr6LVivyYlu3buWNN0SlzjPPiOvSahXXaiAAZvNJhML7CCyWyNvQCZWV\nDMYNlOsl7j1TsNHv3P0+n/3sCLFYNzqdYAJdni6CqRTbhw8SSkk4HAo2bZaJKcfZu1cUZExKQu5w\nL1lU5BvsjEfGGQgMUJNfw9m1Z7N/VPRntDpbWVC8AF/MhyfmodDcQCbtJJFwiHtZkuDrX2fVC3ux\njfiZu/J89jj2kMqkcE2wFb9PhcqVEX/otm1It3yPRAqkiYpn98CE59PevaIaatGi464RHyc+USBg\n7OvGH/eT5wzmPMYVWjNytV3IQQqtaAuf8BGfIQedQNx3332sXbuWBx54AKVSSX19Pd3dAvHDYQEC\nkWk9SKdXnc5yy/ls2nQPgcCqGSDg9UJNjViszz47D6XSjk4Xxu8XINDVJXZ3AKGRCRBwFwAyKpU1\nJwepVHpcrvlEo6KapKrqtlzy8oMxOirs3OephJhepJwCAbO5nsLCdnbtauSeeyD5tothlYFWKQ9f\nX4qho+VklBHy1DYaGoQp46Qk1NsrqoKWLYMrroB0OE1gNM3+/WKRLiiAjo7PolDo6Oy8luricxkL\nj/HdUwTKRaMyu54IcetpLsbeOAQvvkiPr4e1fvEFpb0pkkkX3z7nCqoMCpaXn4UctxCOZAmF4Ghr\nAZ+69PekzcMUZZcAKtr2XAEpA96Ym6NHIaP1UKhMkLZpUcthsshsb3mPzvEBsmQZDpuIRsEf6uW/\nN2/k0jt6qaCfBcFq+vIVKItL0B9bQWWkh4jZSsWQhad+tw4ClZgPJvnyIwrCu7YRT6b53a/yefy3\nc3jx2RgRGknJn0d7pI8dL50L799GNJ5i5UphGTEvnc97sYU8/pqB3VUKWr3l6HwjvGdfy6HeEXbt\nEs7GW7Y0UFb3MD2+HiqUy1jTuQP84gI5NHaIZw++yXzzIFRWoilpQBlM4nAMYbNlYdDBS+ELKfCF\nyDO9i0oFRaF+4joNgWEBAiZTFJdrCJNpEfF0nIPt24goQJ6XwuIOolAeRba0096ZoHX8CC1blqJL\nGHm9+/UJH5tDfOYzn8E56KROVce4Ypy4Ns7czFyCyiAD3mHStZsJSnGSyQCplBOFwojbvRG1upAn\nn/wX8Yl6fZcL1l8pZn7vaB2jrQ1S6hTooG84gtm8Eo2mnLu23c8h1yA33HASRweHyMjw1tjNmM2i\nT2Dv23u5L3YfsViMl14SGxd32E+m9nUeeAAslpNwu18krQfDXieZ8jIOjbcxmK6lre0yvrn0Uv7x\nmJfXXssQjXZgNArptz/Qj91YwH1v6fjF3U9y/6+TzDtzP4qmF3n1VdDpGlj1xNeJp+MEo90kpHxK\njCWMhcfo9/dTk1/DUvtSDoweIBqF1vFWFhQtwBvz4oq4KDZXk5UlotEOtNqJcezXX8/ylnEMjnEs\nTUuos9ZxYPQAvrgAga6glgGrVewu5swh+e2bCSVBGYJLLpXZeyCAWw/h7ZsECCxceGKL3gnEJwsE\nAl5CER/GMU8OBCRJQ7apgWxhXq6udjJmyEH/JhwOB4888gi333577rHpINDR0U5BwdwZ40hPrz6d\nVaYrGR09F6MxbxYINDSIL/i7383jgQdEV6XHI0Cgu3vKkTYyNgkC4gOr1QU5OQjEXI7uXw7j2x6i\nru4eJOn4PuRjYwIEajJhkiolBSTJZOCXv4SBgTNQKLL09JSwaBGsxs02fSmulIYX/p6iY38RKkkN\nw6fgP/M6WntctLYKij3BuNm4Ufz757X9/HdlP9ddJ4Y7PfEEtLaeQWPjI/zxj7dz7Tmnc9NJN7F+\nznoANq9r5yfJNs7d04673Q0tLdz9mzYW9Zlp47+RPUmi0Q6O/qyH2sHl3PGdZaCKEU2H+dbTvyZh\n7uSYfYg1Xh3zfjmPbLaSnq4lqCwuwrg4ehR8CQ/mmMSY2oBZGUcVruSG736JPz8zsWPLpKifm+F7\nGwcoUwfYJp3K/MgYSzJWBvOypGuqWfTo/+PuPcPkqq+s39+pnFNXVXdX5yR1tzoqS0iIIHKyyWAw\nDMYeg8F+x9kYbGwwDmNMMAzBNsGAbeIQTRLKWS21UudcnbtyzufcD0cIPJ55h7nv+9zHz90fq8+/\nOjzVe/332muvfQpV4hSh9W2UTqv5cEuK7+lGqRs8n7pBE/f/doCr91kw6AXEQB21piHiGCkXy4hX\niky+V4eyYOJnDwS4+moZBMp8GUyaMB+VXs79a/KMTGkJ63SUxKHxmj9QVib3It99V0Fv3MKqslUc\nP6Lhx9kHWD0eJS/meaX3FT7wPU2N0guVldhr29CmCrI6qNgNMzMcjC8mprFhiTwBQEnax5y7kuGx\no7w8OMKOHbczOioPqr3R/wbff+d24mXwqHkBez6FqebPUDXMO/v6GQwMQGg5UtjJB09NMjsr02qn\nrDuF1EKKUqmUc7oOsyw4iTvhpqashi//5S5Muim0+nHGx9NMTmZ55ZUnCATeQqPx8M1vfpM9e/YA\nciWgqt4KwIF9Ks49v4CoFtFlBDb3bENvXMaStvd5rOsxdvcp8Pv15AoBgrkGltqy5CSJaNTI8PZh\nmmhift7P/v1y47isdYiFlV/lkUdFkslVxOPdJIJmBKBLOc/B6cMcHroHk+l6ajIPEJlqJ5HwEA6L\naLUViJLIbGyWL7RcRlA/QUQR5+EHNDjWv0Sy5mXefCuPqKpkPBZgOjpNOu1lcPBUCoPnMOabZS4+\nR5m5jBZ3C4OjaYqLJfoGc1TbqhEEAV/SR5m5jCxG4vFDJ6ldyWrlpVaFnOT1etZXrmendyfhrJwk\nRnJKegufbEqbj8+TFNVoorBzp8RfD9bxfj0U9u+Vy8b/v1YCplSCxoQO5dT0J3SQQot43kbE5gaZ\nDvr08yZZ5fkxCOTzeXL/ySisJEn88Ic/5Oabb6a09BPusqGh4SQddOjQIaqqlp5cYPRxJJNyknY6\nOQkChYLs27NokQeVSoXFoqeoSH7f+Xm5JzA8/AlFkvLLIFDwy19TqezMz0oUPd6LmBcxGODA/T62\nPPj38rtcTp5Qz0Qz6CYGKC0FTyrOkNmOOZflggvgvvvgww9XAXDsmAODAeqzUYwrLbRu3MV9AAAg\nAElEQVSdqiYxlWXPbgXFxlJix05DaHodZ2M/L70kW8Y3N8t/y23bZA77NF2AG9bEOH5crmgAdu+W\nlYqDg7Cizcpvz/8tgiBw+DCEu+Lk76un4MijDSUhlyO8ayfFgxX4OB2d18gHH2jQP2+mYtdVVFcp\nUaokita8zQeF76Fe8Qw2h4WGhB7NoJa+vrMwGtNYnEnyygjd3ZBX+7GltByLqzBkNRSml+GuO8zh\ncVnhElWEuPKmKdZOSjx5rosDwlJaIykaVTGmtHbmbcW0ektYMC1hodrBokKEM255k1PWqMj0jqC8\n9HIeXKXm1Jga02Xf5Gs32dDNz5FWaKkQVUQdbtrMfizNezn/siCXXw4D/gEKvnnsrUv4+fjP2V+S\nZ3QqzqRRzeLua0hoH+fC9hGmp2VG4PXu7Wyo2sChgxI1Si91Ph2BZICh4BCBlJeymf2ESpvZNFKJ\nVYRsNkspLtIGB00dWib1zZhnN2GTgigpELHVcHj6TX70yl6Ghs5gePgWlEojk0EfDVIl2Zmb+F5u\nGUGNHttZT2Bd9yLbdh2kRF0K+UqujjbxrT8cYfuOY7S3txMihEKpYHJwkrNnMqzPQlegj/baZWwb\n3MemZ9V8efogXV1JXnynlN92zdHV1YJSWUIgEKCrq4tCQe4v9aVk+sK56gNC6SBkBOxKLU/ve5qf\n7/w5H3r7aHQ20ntcpq8UUh6X62qK1T6CGRW9vQliozHUqNn8RgqtVpZ2lzZ5weZl4yVzPPZYGQgu\ndi/I1iC/PTTL766/k+fuuJw33vgq4dAShIIN2MdHh5p5rectfvTzABqlBnO+Be3YWSy5/l949oND\nzBs3Y6o7xugoeP3y5W4mNkMhN8O/v3gbh5/6Et849xLc6lrUSjU6lQ7j7l+SF/OYx75AVsziNDgx\naUw49A7iBQ2x2KGTlUAoHeLf1utQ3ChTvusq17HDu4NI3o9FKmc2n2c4HiZXkPPXXHyOlEKPIqAh\nGFCwfbyTo4ttaOcDEArx5aM/Y8D/v7em/qzxDwUCxkyajohBHv/+mA5SaJGkLJKU/btKQBDkauBj\nELjnnnv49re//TfPxONxrr76ao4fP37SsvnjqKqqYnp6mkwmQ3d3Ny0tnfwqM8grC59wtR+DQFHR\nJyAQich9iMrKMh5++GEEQTjhwaPA77eQycjT5MGgPMCcDeQJokYKmE6ct5MdSCB+sMDgjgypFNjS\naWJDJ+R0YXnc4e23YcMGubfwr+ve4L6pLzKQ+AhrNMG+vJ3UVBaHQ25SDw7KlUhfnwVLJo2yIKIo\n15PSqFnXmiORgFJFC3OHW8gIUS6+fppgUHYb/slPZJBzueDWz6VQJXIkjsaRRAmXS5Z/qlQyXfRx\n5fDww/IiprPPBrc+x5v6b3LMcJQKA/TSxLWu/Ziz1QAouxz8232P4U4Zubg4yy9+AVq1msiK76NO\nVSBWbMeus1Md9GDwZ9m86XY8HoEioxUs00QTWZDSOBI2BtV+PD4nN81mqO0IMhrqo1gLMfU0WxVf\no9JXyf6Uhh6hkZZgjlopxKRQwu4pueyaMTYyXaShOu3HtWIb7e2gmxomWVrPHKVUJpQEq//AyjNn\ncMeD5BQGjIgc8Z2FJzuGu2mQfn8/09FpHu96nFZlKc7aaqpKLagKVmb0HzJmTdM4sYr7tub4Qt91\n7DrhL7ZpeBunVp1K394IhkKcWp+GyaCPwcAQp04Ooy4p4sGDRXSffhV2oKTEjjFoZkpRxdKlMKtd\ng2LnGlY4B4m5NOT0pQQTXUjmWb7+9fNY7HOSrlrEL37jJzSRAhpomFzEQraWq9R2VO5hvrvvWe7Y\nqQEMXMU8ZUovjzyRo6Ojg+MLx9GZr2Fy4iHag7BcYSN9cYBBp5cbh6OsmslRTIT33guyqU9Ed8av\nefLJ35JMFiFJEl1dXQQCYDIXmE1n0CgEQukgtUsWIKXDrtWjkTQ8cuARfrLtJ/zzsn8mNXUuwpoH\nKBSULGu4GpXajT+X47XXDtNSIgPEo/c6P2ZJsFbK9hZlS4+yY4fAH7c3M6Y4j9gZp/D2NqD5ZV5+\nPcnvfw99fVei0+4B9jM+cD7/+qcufvZDF/p8GQuTxVQobEwmBXSeYUaCI5yz6AwWrZhk50FZejkd\nm0Yo+IhHi7ni+++DaQ5XSl6C098PieMbqb3u1zBwCcFUELvOjsvgwqQxEc4JZDITJ0FgMjJJvq4a\nfvYzQAaBnd6dxEU/xcomdgQzvD5SzFBQvnXNxedIF0zMzZZgd2QYjdVQWfs5jpYoiDZUsWliM7X2\n2v8+qX6G+IcCAU22wJKwWr5yfpoOEjMn7Bj+fpfpxo2fGAcODQ3x1FNPEf2U7OVXv/oVmUyGnTt3\nYrf/7dCFRqOhvLycrVu3YjQaaV7iYr91nluHhnj5BBB8GgQ+pneCQbkfoVQqueWWW078nEo0Gjdq\ntYV9+2SQMJvlW1E+nMeLASloQKk086UvqaiMybf+2y5NEfaLuIUM0ozMqb7+upycH3hANjMcH4el\noXk00nnc/bM/4zMl6Y/pUEazPPooBIre4chCP7x/NjMTWkqjfpRtFuwOgaigQRnLUVkJY0/cT14p\n35qsZdNoNHDRRfLvo63bT17ME3wviPMSJyqbitSoDEpOp7zu9s03ZfXPTTfJPYTTToNjxyQUyQxe\nvMw4ZzArNITXXcjGXccJ6zvRWSPUJUp54e5XSWoT2CblD65RbSSjmeU7jb8ja+lHpxWo9dUhitC/\nvY7Fi+0Um4rBNkZDW4DnXjWiknLkSvZx5qTAHccPEaVARMhjTVeQNYzRlPYxpLiZZaMtKK7fT9OC\nSHHSx0LwQoZyYZTECYt1jNhEygM5/Ek/FRVQkRth+3QdCXMNzlCBvDLKdGqYyqiagsJIXBDpHj0T\ns3+cylYvv9z5S771wbcYCAzQriwDp5OzzwZtqBNt2ytMWkV+ekWSs44nqR88yIEdaTaeMslV2w+z\nsmwl/kPy8FdDBA4N+Oj3DfC14z647Vb++PYocXMMnQQetxHNrJ7jsUoWL4asuJT03otpNXQTtFqJ\nmJKY4gYKhmnqYileKtyA4J2gxDSNfnIZkmBmrms9AZWdUqaIMUtVOsFl26ZoWPYzVnOYMvU0+3ev\nZMmSpRwY6yMb/lfqKUYjKqiKFSBaypT6CD/eNs3rVR3YpRR79xoZD6pIq+cQdAUeffQatFoLBw4c\n4Pfv7SEqzpGPN1BhUBHPximtm0GRtoFKgUqp4pcbf8l0dIZLFl2Gb3QVwml3M0cYg76Wgb6vcvdX\nRnj44U6y0/JuibNXDhOPyyCgLJpAnXORtHfR1QXP7hmkMP41TJt2QNSDwT3PuadbUang6aevJJP+\niLKyQSYH13Hog0YM9jD5uJWJQSvLSpR4k3kOzhzEprOxrHQZ6uJhhqflXtt4sAeNFCEeLaKq1Eja\ndhhjZBkA//RPh2lft4Ve1z3EvXWMzYVw6B24jW40Kg0L6fyJHCPTQd6IlwpLBaOhUQ4cgMhkOSaN\niQTzFGurEQQVhenVHF+QG/6z8Vne+0uWZ3aX4SwKsUq3DV/yKo5UqnnPMM1dp96FWqn+7Mn1fxP/\nUCCgKMCiADIIfJoOOgECn6aD7r33Xh588EH+8hf5Bgvg9XopKirimY8tJIDu7m5uuOGGkzuA/2M0\nNDTw8ssv09nZiak+jSKt4v22Nr4yOHjC8OvvK4Fg8D/frqccXY5RcPD00/IH1umUKSEpmmNWbYCg\nDoWiiB07oE0RRWFU8KObU6yoyoAAhogMAkM70/xg+RwffSTPh/ifm8W6UE0BJ9/csYER2wJBNFSZ\ns9jt8PzwA7jMu+EXP2C96iBm6+MYV1iw2yEgqsksyLSRlLRTtVqeMgzmp0kk5D3fo3N+Bteeyrbx\nbQTeDaA9Q4u2TUu8W25Ay+ogubppaJDXwz7zDHzlK1BkLJBT5Hjk84+QKE9QSJlZe99FeBbSJLKL\nKFs5h9Nfg+gtZ0/bFhgpQipIOPQOahPXUC2dTkHIkMstYEubGdJaObM+SV0dlFs84OxnzUY/nbNW\nVIogjw6/RMBgwhMJkkuNkdSNMjhTgtI1zkXpCjLqSpwKibfKX6bRJ2GPzBJInIsn9EWK+YhCoobD\nhig1IZnTFwRYrBzmt+/WU1dxNa6wLCns9fVSF9ciSUYmjDEkZTl1ijHsrjTHFo7x3vB7JLIJPBnN\nSRAQhs7nN1s3kEyfStG7L6CsreNwicSazIe4tnyf+z7K89KzKswhL1JdHfXRHLsGeqnx5Vk2C++X\nn0pCO4qkgIRKQ7lZYqHLRtJZJRuuKZzkFuxcKD7LYK6T+biAaaKdAhlaXlfyC/Vq5nTVKCJzmIiQ\nLziI9rWjqZ7DETfgMXkoKQQQ1UaeXriTf1c1YcxmUYr7+f2fV/Or7Q/jbPmANdpfccS1EVsghHJs\nA1dsPYtel4233FbMuRyTU+twVMs03F0PDTM21oogHGdmPsmdrz2IzpQmO3kalYYCoiSicw0hJN14\nszGSYpKG+I04n1rge9/S4Z3WIGqjzEhxlEodR458nro1b2Er3cAZnSOISDS6hwgG5f5UVu+lMHA2\nz23ZR74gIh3OM7B9DkEQcBU6qavWEc1EuOlLIv39bkymnSxe3MPgwCKEgUtIn3cDiaTE4DErZ7Rm\nCGZybBnfQkNRA02uJlKWY4zPyQONY/59mBQJIiEzNeUmpKJeBL/cXO7pMVFiPQ7qFG2r/Xy0O4hd\nb8dtdLN7227GfLLC5ONKwBvxohAUrHtqHb/7vcjLL0OLu4WMIoRD58SoMSDOtbBv/DjDw3DPF89n\nfEjAHyjDavBxNm/R1d/OkRvO5eGzrWT2X/83uzL+T+IfCgRyBhONU2lZYH3C8OdjOug/VgJbt27l\nrRMqoY/D6/Vy77338sgjj1DIFghtDnHsyDHa/jdNlPr6el577TWWLl1K0hNHP2Kgw2RCKwjMZLOf\nGQQkCfxf/waRF5bzwgvys06nXD3kwnlGcgakkIbZ2U6MRmhVRHBd7sIjpWh1pSnUmbHn0mRSEoUd\nfmr2yXJIMScydPsQzaZ7KFU/ijmmJ9A0TBANVjFLXsyzd2ovV4TsRBbZuTKRoXmujEDrFHY7zOcU\nEM7R0gJ7tpm4/VYNCkHBTHwal0tu4r3lfRZJyHFg9ACR7RGOvnszk+N/PgkCWi0olj7Dc71Pfjxw\neVJfnlxIEtVFWVS0CKk8TzpXjLh6FfOacpRGAecqEWusAf9BEX/zUVRFEqmRFB6zh9bCjaSSCgRJ\nQXi8n3RVCnuHkdn9Sex2qLJVIdgmaV7sxR53EFhs4ImVCSKOYg6XiLh8m8E+iufAU4iGWTTH+5By\npViTVuZVKYIGAdvQAbLuchbbbLj5CHXaSX8qhCELyd4ksT0BbLkAH/RXcMl51+KIycMgPb4eqpOg\nkEyM6dUUUhbqlGPMxmdpdbfSXtKOhIQjIYHTybp1kDtyAbVzNRhTG+DYMZSfv479rRVcV/Qki179\nd0Stht/cOsyaMi+HjOspjac4PLOTy/db+FOtiy/f6WfJOrkpldAauO4CM+EjYFvq5mehRkyBDCnc\nrB3vYtf0ejz7bsURrKPU7CE9beFQ4RhTaScNpSOU2YaQJCMVQhJT4yTmqJFmdyMl4gIvbvgip0zC\ni1YdCYMBl/ILaM74LQUhi+vif+NU837+GlzNjFZPtXeA1uMljBS+iavWTVFWAYYYaucR1Ao1OUua\nb31rLwZDAtHaSenIFZzRWcfcnJoqo3xTzWh3QLKSWlcjbbk2/tftOdwuJU8+CQr3MQRJIKiWK+9E\nop2kWktwvhdlWsSrn2B2MEpVldz/W8hM8NDXz8HZ2EfdkhDqdCejo/KCDVNmMd8++2rOe+E8LGte\nYvlyP+Xl3dTU9JBOa2huyyA2vImkjjHWZ2XlMiWVZheHZg/R4GigydmET7ebqWAQk1qHN9SLVZkn\nEtbSUGYHZz/JuUqyWVDHXBQJMwgIfO4SBdv2yZWA0+DkTy//iff+kEQQ5MofYDI6SUEsMBuf5Xhk\nD6EQNDgaECQlWo2AWqGmztzCvtHj9PXBzGAx3qEU0UglZvUMl+VeZ8/BYvKWekqqN/Lju9QYDJ8x\nsf438Q8FAmmzmYaRsFwFnPD++ZgO+nRPQJIkuru72bt3L5lMBpCbwnNzc1x11VWo1Wr2/GYPR887\nyk+mf0LRwifj1ZIk8WEwSPeJ3aT19fWEQiE6OzvxmWL8+p44kd1Rmo1GehOJkyDgcMitCvh7EBBF\n+MENKYwhFZe4QhQKsr/X1JScZInmmVUYUMZV9B5bzbKaDEYpT9EFRaRH0rjyKXIeI0mlmuG9GTQT\ncRTTSQ7uE5nbn0TrUWNK9nO8opVta2/jtZUvEUWFMpHnyPQRiMGa8RKetDUS0eZYNLuIN0x/omCc\n5KmKBjSpLOHFfhbVGMmrgjz5xyeJj8dlv6R5kQ/Dj/P4B8uJvTWJsc2I7dgBsok9BLpk1Hvx+Ivk\nN/yQrYq7KJTtJDmQ5ECLrP8eGx8jbUqjUWqwFudJChUsZIJsrWrHusqMrtGKKm9A06XFvtyKsc1E\n/Egcg9qAypAgHIghSRL24RyqRSqWnKenAhkE6ux1oInhO7CVCXMRunIDz3cmcBZcmDuvoHM2hqDM\nowotwSiWYjoehJwGS8xCta2aoVINimyGWcrIjefQaSeYco9h6DdyTPEj7n7oR/R+oZcDvMDlylmW\nnWZGkkTaVE30+HoojeRQFwzsj6+mCAX2zBxD870sdi7m1MpTkZAwR/IkMy70eljpVqEW1biSsjX0\n+MTpeOLf55zhtxmwZeGM0/jptf2srZjknf56AgYzifkdrBsT2Noc53NfnMRZL4NAWGmhWDuNGNnF\nU9YfYvRnEUxWfNYgw2dVMrZiFwBFGQcOdRluVYCELkjTOiu2wgJuQUKggDmnQGETMId1tJrq0JLl\nO3ETd5wBeypUzEsqXGVRdmWeoKrYwqRmkNNcBjrrVzFuPJ1Fs320pY/xQXgNi9tqsWdA7+olgrxf\not/fj8/nw2jzIumasIkmKipA1AbxGOtQKwSiil0U4vWcX38R39t7B6XREA8+KCf1ss5e6pUO4iaZ\n619YAKV/CmVNNdnpPEPWYUaORPnYkHciMsHn289gIT2FqqQP0k1EozJdtDCrprHOxN6pvWydfYvb\nbnuHigo9xcVB7PZBbv+SnZ9v/DkaS4QldVba25+g0b2cglSgwdFArb0Wv24v89EALe4WpmNzqDI2\nTCYosxeDs5+g18WxYyJfpRfPYRuvXPkKX7+phEl/iOi8HZvahmASiEwq+WCTAeFEHvNGvESzUers\ndQyrX5UrG0sZiCpQyQzAiqpW+kPHGR8HMa8mFXMQxYOhMExFwcfNNwtsOjDB9sOTfP/7n0jk/0/j\nHwoEEgYdklLxN57g/xkdNDU1hUajobm5mX379gEwMyOv3VOr1ZxzzjnM/HkG4TaBrqouhr82LO+A\nLRQ468gRrunt5Y4T3iv1J8Zjly5dir8vQm0wx8LuOM0GA73J5EkQGBuTl9EMDckgEAjIun2Axx6D\nzI4gtktdFIXimMQcd98t25z/67+CrpCnqk1NXKFkrHslHeooC04L+gY9qeEURbk0KZuOuFnH/S/d\nT3U+RiEncdnqFB/9LoGpLMNCcStzFTZWCAr8jOOlAqU2x/4j+7mk9xIGF3l594CWt1unOe6e4cWx\nv/BU4CayCpGMKs9fsvJtKbk/Sd1IHfpePcXF8MHQZpQFI5f3TlHzrhnDeQbqvXEaNSFCB0N8+G8f\nMnT9ELW730X59h94KnIt3j95SQ2mkESJ8fFxOCHVLbFBVnLgXfAy4lmD5ZwKBLcLlXYMKSex7LSr\nsS4tJnE0gVFjRKlLUPfCMZ5/+hrufa8ae6OJilMMtNlSlJTAYudiJFUa1dABZg3FWMotxLVxVAkV\nRaedw4rZAup4LbMzAk5lNZXTRaCAonQRT138FONlJgpFLlQhEW25lm2PP8vRqkEufe9SkoXF/P7i\nyxGvCdPY+QrXGaeJvLHArNrGOk0NSBKOoIKsKkf9WUbqNCmyLieeUB69Ss8S9xIEScB//GIO/dCK\nJEmcWhOmXy3gDBchfe02fB/lKQ4s4kiJwP2LlqBuauOSxf0s1nsZylbiNbppyEyzKuhne3WK8rYh\nppKjlERL8AsW8jM5VgZmWH/Vd2meaiZba2GmaIYHW9up1p0GgKFgQp8ro0gMg8OBusSIPpLEklWh\nUWkQbQlQeDAF1XQKpfhNWijr5k8t9ehKNYwm4pRU6MiLed79wrv887Kv4JqZpMJjJ6AupTWUo5PD\nbEuuoGNpC9aUxHd+8kXiijhritfQH5BBIKk/jJBfy0zNcxQXg9kdRJm9hSKNhC8/hZDWUZ+4HGfC\nwaWnjvL227LV17rPD9KuN1JQpvElfMzNiUwd30XuojGsUQPpKhGXusDq1RDPxknmknjMHmrsNYyp\n3yGXbkCnG+LwYXku5+7nPmSZZxnvD7/P8OgwNTWV1NR48Hi+wY03Kvj+uu8jaaL8+PuymmS5Rx5x\n9+gb6O9VU1tmoaAN0GDtxJ9VMBMoxeUScBvdUDTIjNfA5s1RPETBB5c2XYrJqOCsi4Jsfc/OYLcV\nUX8xjde188yzmZN5zBvxMhubY3XmR/hcr9LbJ+EyupAQySvj5MQcp7fXEy5M0TcageaXUambSIil\nFEV7iJhUfP8HAmOJHvyqI4yP8/8tHSQIwrmCIPQLgjAoCMLfebUKgmARBOFNQRAOC4JwTBCEGz/r\n2U9HBgiWOaCyki2hEKIk/ad0UHd3Nx0dHZx++uls2bIFkKmgj83fzlx/JpZeC33OPjJnZpDyEsH3\ngnTFYoTzefpblnNoJkw4l6OxsRG3201FRQW2N+PE1UrmDyRPVgKpFLxY28cfXsqhUslyzJ4e2LQJ\nfv0rielHp3n69yIXlQTxXOlCsczOSgKUNGY58+Y4fX1gJk/zShV+Ucfk0WVURiPEq63o6/SkRlLY\nkmmSFh2J0ijz07spE5NMuex876oEmf4ERsMc45Y2pqpUNAeUfG7eSVhpQJebYfl3nuMb7y2nWPlX\nJAmmV3i5d90wnSWdJAli2/YMYWMYRVhuVFnftVIwF7CN23AXS2yeeZ3a+HUYMgmqJpbTVfIBZVGJ\nulyCTDpD9I4o6/rWUa5sJX30QppczUy9OIWUl8gFc8xOzaJ2yGV/VV6HQh1gtmuW9qPt2M+Qh1+M\nqhGGSoZo97RjapcrAaPaiEKbxDM5j2f6SnzKFirsGQyLDTToklxwAVRZqwCJ0rlBohoPrmoXCV0C\nYlB09lpWTCkQA7XkcrBULCEreTC0GHAkHIyFx5iutEJ5Ba5oHEOriYv++WIGPAM0TTYx4dzEqgWJ\n3X8+zrzFRuSbSxi6bZhpZR2LRR2rDYtIKvVkDBnufECDRScS99TQkbQSSodI59PceeBOsnEXSr2C\n1FCKFXaRg7kKBIua+VU/RCpIKIYUnPNVK4eMX2VE0wR9faQGvdhaKhignMt6YcIGSbOWPn8fofEQ\nz/72WXyiDfWHRQwXqZjT52meaiXdCLmKHOJkMRu1K0nYCugFG5mFUiy5OEqni9n5RszRDJaMgELS\noGiMkMmVYQwpaMxZCRYJ1Cp8/P7Rx/n1rluISCup0hgpG/khTa4mvlP9BdL5DIGFBEnc3OqoxUsD\npzmyNDaswJKSyGimECwQ6Y6ws2+Ad99dIKzbT8GaItL8Ni4XaO0B5sdbMGkdLEgSZER+fK0HpaTA\niZ/XXpMHEyfTfTTYdKgDLfzosR+h7NnONaVZrIKGtDpLeYsLm6TirrvkRNqoauT4xcdpdDaStx5B\nkprJ54fYtUsmD3bMvsvNnTfjMXs4MHOA8vIW3O5mxsePo1BArpAjW8hwyXlGAE6tOhWAve/U8+1v\nQ3tJG0rbFI5CM/5MgbmgB6cTNEoNP9r4HdxlSf646RAeQUAT0bB3ai+SJFFUHqK2xEH3zlIkfRaz\n5RzicYHB0UEi6Qh9vj6mIjPsevJKyOnoj3Rh1piRFBli4gKpfIqVy9So/UvZNPMKnPNNKqpOI1Uo\noSExQcJiwGzNo7aOo6GAqXge9f+dvvB/DwKCICiAR4BzgCXANYIgNP6Hx74G9EiS1AGcDtwvCILq\nM549GRlRIlZVilRZyQXHjnEoFvsbOmhmJnSSCurs7PwvQaA108qQOMSegT20trVSeUcl3vu89CQS\nLDWbiT04y4/+Tc07wSD19fX09PQQzuVYtqnA+LIKAt3Jk5VAOJdnXzTC4S4BQZAHql56SVYlbXk6\nwdBtQ5w7NIy6J4z9LDvOi4s4hQCv6CfYt3aQyy8HI3nKFquIqTSkZ7KUjAYodNhRmVUozUpcCxEi\nRh2zpcdZPbSaoF5A3WKmLJtANRkn5PuQHvUSxirSVMwmuXRUzQvWUyh0NrHNYSWhaGX15DZu4BlK\na0M019t4/MLHefL0N8jtWUfE6IfZAGJWpHJnJYWvFKj31WN2+xlKdKH3ryCbLkYvZth88JfMLC5D\nP+9n263bMLyqQK0p4DFk0engbNUGCv4C+sV6snNZArMBjC75H8qT0VAwzqL6qYqFJUF6qkXmLRaK\n2cGHqz6k1l6Lsc14kg7S5YMosiZ2lk2Tz7dgTw6iLdNSiOQQJ/049A5AoCHgo6Aqw1xm5p1/egck\nUNTUYs0IlPpl6ef6hIYZUwW2tTYscQvj4XF6l1YifPc7VGbiRJxGclkFhxeNc+fVd7J97UV8+WCe\n5twBDobrue1BM9nra8hlv0xFRMXaQhlTRiNZY4baWgHrWisLik7qoyqCqSCz0VnW7VjHEt2vsK4x\nEdkdwRNX4tXl0SyzMnbHGO5r3Ogqdfyx489cvug6ts7JXh3q2UlWX1nJuKKGK3tgZ5VEQ1EDvb5e\nbNM2NDkNKUUFDd1+PmpQMZ+Yp2mqiWRzGm2dFtOsCc2oko4vqVHhItVfREatpIlU2e8AACAASURB\nVNbQyMyOM3HElBjSgKjEsERBNlmGMZynJq1jVJvkKx9cy/6rJ9l82nYMXEudSiCw+xJEEYpGZ4kt\nqsI/4YdsOVWzQ4ybL+K2hR4Gb45jTNkZS4BRpWHPv+/BVxih6/AYr05+RKn9KJIxis7qB32QgzuP\nI6XriSqgxCSwpkze6/vRK0nCYXlGpcfXQ2uJnvx0O2/ue5OLMpt42N9HWdBJzB6ltrEWY1r+fE2E\nJ1gzv4bAOwGarE0sqQOFohXI8cQTERRKkaDjfc6sPpcLGi6gJ9vDwsL1/P73D5HJZAiHw0QzUcxa\n80maZk3FGgQEXux/Du+kxMPnPYxknuaP27dREEUmk6tPCk9+cvpPMK99gaHm67FLGmzYWPOHNfT7\n+pkJzfAvt9j50tVTqGyTaKNLqFlaw5de+xJn/PFMEgNrsFPLik4d9F1KquoNRqdjCHkDh/27yYt5\nKmsySDu/x6i4HUyzuF2ryRTcLIvOknFYGAmOcOO2L/Otvf/CaVcf+Tt35P+38VkqgZXAkCRJE5Ik\n5YC/AJf8h2ck4GPDfTMQkCQp/xnPnoyQUs3k589g/rzzSIkiu6PRk3TQwkKczs7P88orr3D48GE6\nOjpYt24dXV1dxBfihLaHToJA4p0EY5VjvPTSS7S1teG+wk16Ms3UoTDNBgOJYwmatuZ4Y0puRjmd\nTo7u9KNWKaj/SjGCV64EehIJJpwhTK9VI5w3h6dK5IarCriVGa65Bs6qinFU72CNNoSxxYjaoabu\nuiJO0YU4vmOOaUOcYW8eM3l0LhUZo4aLigIUChKmpfLMgL5ejz6aIaBTcNS6jRXDq0hoF1g29SSW\nYBJzKETW+x5bjAkG3D7MgRindwf5a1k5eY9AMr0GTbOeW/7ZxIOa79KRGuGfrrZT76inqaycJ8Wj\npAwqDN4B5v7qZ7Z4FvtFdmrna1E6x5kVj6H1NuBTbMAt7aL2+Azi+lMQFAp+/cM7OU/nRpueoFyV\nobYWOo900NPZg9ajJTuXJTIfwV5kAknCnZBImGbQD+h57Ip+bujrY+n4OMWpI4TODqIQFOjr9OT8\nOaxZK8uODCMpo/y2eh5TdQb9yC4EhYCBSZJtF2J66nmQRFp9eTSCB02xho11G1FZVRRiIoeddi44\nMRu4LFEgqanGvNyMNqNlwj9BodiF4tqrWaYMcUS00dAAiUgVexfvpf6U09nXaufcmTc4+zsmqr78\nHX64p5SMNolrawer59UMOkwkdUkAXFe4CPnbqIsoCKaChL1hBKWALjaC5VQn0d1RpGGJyc/fRu3n\nLGSmMrgudWFaZqI90M7F55h54WAjUl8fluQsreeWIdQ0YcnC3ioDDfYGenw9tCdlbbxSVYYtF+Pd\nhiwcgtJwMcmmCO5mN655F4XBAkUXGJAkG4VjFqJGNS2pFgDccT26tBKUItZGK/lIGcZYAksoSaZw\nFoa0neSFKqbahtEIxRjCURzKSnlQ0uulrG09lpgFdUoG2LRzCeFTS1EX6whnz2coDGVmG4O9gxAr\n4Zqio1yyEGa5KC+An0rvJaMIcGjXHUwfcYAAF24I8vAdGXLKHK0VWY4ehWDaR17Ms2HpXWgnlnNL\n4GuUKAOoYhG+dKgYv9VH7ZJabDkb09FpjswfoXGqESS4uOhirus4E9Dg8axgbGyBilUH0eSdJGeq\nuGDRBcxZ5ohEOvjrX5uoqaljdHSUSCaCVfuJxYBOpeOts/sJOz5kpPiXuAxu3C4lS7WX0VC0mBrX\nFSdBACBXsZmShI28Mo9L40IhKNj06M/54k//KlvPRwsoTEHEQB32JXb2RfbRPdtNpu90dOF2zGZw\nxc9EqNnC0X9PcFbXJdQdrUGTL+Kn9/s4t/ZCCs6joCwg6VzkCm46kzOIziIZMMc6WBSo48jckc+Q\nuj9bfBYQKAM+vcFj6sRrn45HgGZBEGaAI8A3/gdnT4ZPrSdx3kbGGuViYc8JEJCkDM8/v0BHxxLu\nuOMOurq66OzsxGw2s6x9Gfsu2EfN8zUnQSC0OUTR+UWkUilaW1sRlAK29TZSh+IsMRpJ9ibRmFWE\nPgiRLBSQChLRuyeZvtLI+it0aLM5lPMCCmBQEyG32UXbjSEsZwY5f3aMbwmDlKgDnFkZY2fKTvVL\nbdQ/LPcW9KUagn8o4c47RS7eo2U4H6YgCJhsCkSrhlXhOYoKH9Ex8KL8fL0eUSVwSLMFXbUBXV6D\nShqkJLgd5WAUQzZLS2iOzRX7mBZHyFWVo1IoMVyaZto0ypreNVhOt3DQlsT2h99w6yPbKBLkm5NZ\nW8BJFqXezPquAWb/PM+Wti2UtZVhj9hZUGzCkK1CnC8QVKxGVzvJl7rBtfYcpPJyubM9MIBOnKWY\nNHV1YNtl4681f0VToiE7lyXtT1P2wXuweTOOWJ7J4v3svXovQ+U6PmxvZ16pBI2Ga6ouBEBQCOgX\nGyiaKaL98AIBY5QITpa/VYZwcD+MjmIUR4l/4yGExx/nibeVCBKYRTtqp1z/Kq1K8tE8M5bzuRQL\nv/wlrIhLWDUt6BfpyZqy+KZ8WLQWsr4sHjHFm6MWbrsNcsPrIa/j1JU23risBSSJLn2QKcdz7N0n\n0NP6PIWDnTQcyzJdXExELc9zOD/nJDdTSaVfTTAVJN+Xh7osWK1Y19uJ7IiQHkyTbBkkvzqHsc2I\nabkJ81IzsYMx1q+HqNJOAiNBHCxZqqV0xVIARporaXQ2ks6naYg2EC+Lo8VDBAuKxFou/c2l/OKM\nt8jqA1S1VdE60Ypkl1j//jloFdM0+22EjQK1AVm65YgbUWeVoBExLbYiBsowp8JIUzPYZ27kuSWT\nVLqKiZZG0Qh23FFY2mzj8GHA60VRsgg1aqwpK5JGg9JawQx6bKfbSag8zAdgVdrKe9k8lWEPt0dn\nOWq0sDQ/CP4GJmL7iOaCSIkYlhMWKCWWYtITabxlXjQJecizx9fDEtcS+vpslM/Ws3RPJ+VaH4Nf\nvoxLet2EDHNQDnbRTtdMFw/seQDngBMEaBabWVG0nP+l+QXt9k6MxjDOzt1UiqfR3Q2t9lYKqgI9\nyT5UKrDbm+nu7mZ4MoJV97c+M/veXcTq8JXk6n5NOCw3tXe+6mPdxDoqn/Cd3EwoSiKz2i1UbP8O\ng+WDFKWKON99PrEj+1gcyDF0zM5fX0mT04QpTLixTljJ+XPU6DphzUPkp9vQ6aDTuRbRfYTPP1XL\n6b2ncvu7tyNGi9l2wM9Xvx4DxxAEtPROpRAlOy58qNwl9M32UT/vocRXxNGFo/9VGv0fx/+txvA5\nQLckSR6gE3hUEATTf3Pm7+K19wK8+tir/Pqee6gbGGB3JIIgaAgEErz9doznn3+M2tpawuHwyf29\nt0i3sLCwgDqtptJZST6aJx/Oc8plp1BeXo7jhIzH1GFCczxDk1pPejxN1bcruHC7gj3RKOM/HSeZ\nKaC6rRijSSBkMvDzW1OUHC4h/KyHm/8lx41LHCRXziJumqM8EGbtfRehO3iMoa/MU3OaBsvyT/YI\nPNgYhV+X8/nXRTKOMBm1CqMRIkoNpEVak48jHXsaQL4ZO3T0C6+zYcMpADgKhzEHuigsZJi3j6Hy\neFio/Iip+CiqphYWzlhNcdMYezK7UKfVFJ9VTDgdRrr2WkZKtXQ8+ioA4pzcmCrNidy0UyT2bpD3\nG96n2FpMrCxGaLILQ3g5eX+YtFiKc+NiSuPg76ogEbJ/AgKFGYrFBE2NErmeHEPlQ2QdWfxeP9a0\nFa1/DD76CHUwzhHPbl5a8jLX/M6OdTCHTaVCcBVzW81V8NBDxI8d4313Eue4hbLRAsdKpzFl6mVj\nwLk5+MMfsCzTE52xwqZNrPPCMTcYkuqTIKCyqshH8qy5/nzWq4f57ndBNzSCFLOjr9OTtWUJz4Sx\naC2EPgwxYrKxY4+C1athbcVamOtg6VJI11fz1nN3ccASJ5CZ57RzIng9C+gMfixHU5x+6m0E1UFE\nSUTtUJOs8WEbbSSQCqAZ0qCvKsg9jzYjaW8aTbGGEncJk9ZJVhxZwWMHH+OJzBPED8ZRq+HFF+FQ\nqomQuRLfS3N0nLGMR2wXYqivOunGWuYvw3eWD126nF2m5dz2zje469q7OGDOk1EGKG4uxpA10Ofo\nI6EVMAiDNKYNLGgVOOecpIxh7CkDqqwCQSdhXOyGmTLSgg7/lhwaq4LjoXXUuksIEUJllyiLldLZ\nIZwEgaylGqXHgBIFhb+8hV5tZjihR1ejI6MoR5OEcm+UzkKWHa8expEvcPCGM+kMBWHwYoZj+2XN\ndB7qS+XBK4/NQ3o8jb/Wjy4mz+z0LPTQ7Grm4YcfpqpQjiGtx6UI0NtYxFT5ItaEEowoRlCh4skd\nT+KP+3EOO7GstZCZyRAKhfiK+AIdMR0dHWlwDNLsXkx3N4yNjFHWV8aE5af8uG2Sdf6reeGJdzjn\nkgga8RMQyGZlW5bFrjTYI3i9kJL8ZML11PTX4JgQT1YCPQs9OIxWFgeMTBXNk1FnWBRdhHJhGlcK\n3nnFSGQ2TkETx3Rcw1V7r8I0WUrl6M1gnSQ11o5CAYtqDJgmTkFXgHta+nBF3eTDLo6N+BjL70Ex\n14kiYiDOAuBDgYi2tJz5/fNsVh7iz6Hn2fz4Zu6+++7/aYr9T+OzgMA08GmP5fITr306/gl4DUCS\npBFgDGj8jGdPxpLLm/j2Hd9m6e23c9nGjSQKBQIFgddem2bDBg0VFVXcf//93HrrrSd9/0t7Srkv\nfx/z6nk8oodkfxLDYgMbTt/Atm3bTr632KKjYkjENl5AW6Wl+NpimnYViF03zNzTczxzr5Zmi5Ej\nR2Aka2B2b5LA0x4Uy8Ncf56WK1wumkcS9FcXmC4rkB8pwKwBV2c//cnkye/Tn0gwkU6zYaOH4tE8\npuoIWa0MAnMaJUJdkqhxAdXRTez07sTgzqA2JggKAzS3NZHV52mU9qGwGpDcSTLqAKm6FainT8dp\ncKL67vfI3PZVNo9tZkY/g6ARKFpfhEapIZFPctcVTkre2gLbtpH2ytIzSy5CQDoTSTuBwqFAqVCS\nrk2jHEsjzC5HG46AIKDfeAro9SwcsxOft5DaOSyDAPMsL45xx01pVDYVTbVNzKtn8I7MUZYpRp2c\nJ7N1K9uGhkkajPQleykSS1h4ep4itZpsUZEsZbjrLvL33ktvpUj5Rzlm1OWMY6cocrasF+zshIce\nwnJNO9E9UXC5uOTGWr52Aahiwt+AQCFSoPayTnR93SBJ5HvGKKQFNKUaRIdIdj6LVWsl+H6QMZeD\nXE723LrpzA00db+J0QhOg5OBahMDQdmE7ju/HMRfkkSfnyPrh+Ly5eQMOQJJWSrbd+YkqfAqzjqW\nxDRqwl4hg4BCrcC8woyh2UB7cTuH5+QFLVvGt/BQ9CGiR6KIeZGGBqg8qxFTcyW7b99NYvgogw9c\nQoXVQ0NRA2qFGtusjWeKn0GZs9DVcSHTrnmCTUGyITcpAiSVSXwWH3OeOe695CGsUi8dkoFQtoN0\neZqwPogtbUKdVSLoBUw1HhAVjEjX4D3SxJIbzMT719JQWsx8Yp6CO4sj7qajg09AQFtKzqwhrteS\naTwFUyLNrhEd2iodWakUWxoM/gQvOAS2LG7kB2tB2LCEpXMKWFjCSKoHo2jE5XJRiEURRIESWwnp\n8TRSi4Q5ITPH3d5u2ixtbN68mRqLLPqwSHGGlGECNZ00LEyxsPkNIkIEV9RFla+KtC2NqdVEdiZL\nKBTCIy5gXBCZmYG4doiV9Q10d8PAwADLDSv46ubLaMgfp33YjdCVorxuhsCMDAKRCJx/vmzIaSYG\n2jyDY3HihSCkluIac2GNqHBb5AHCzWObOXfRGbhyh5gfX09MWcDsNWOPJ3GmYHYoTkWZH4NkQ9Ds\nxhFyYJm6n6OvLaU+fzGJoRVks+DxQMPEOUwVTZLzLSWnFmhQVWAu8fHyvu3YYytQJQ0YimeAWTJA\nWW0HhS4JUbeWr7V+DWetkx/c+YP/KpX+j+KzgMABoF4QhCpB1mheDbz5H56ZADYCCIJQDCwCRj/j\n2ZOx9eUJ7Do7Y6kUtXo9a6xWjiayTE4maWoSUCi01FvruTkjj5PnQjkUKEjpUgymB7HH7DIINMr6\n3NqPJ5uAiXqBuhF5QMjYbERTrCF2nY3hVgUrelawT59iidHItddC5ToDpbkkv3wnir0phdEo4NRo\nuPVdIwu6RfgUKXq1V5Kzw8O/e4DeT/lP/3lhgavd7v+HvDePjqM8075/VV3dVd3V+yqpte+SLVny\ngi0bMNhmB7MmgRBwhhnICkkI886aTDLJhEzIJHyBCVmGhAAJJAHCkkBwCBAWG+Pdsi3LtvZdarV6\n35f3j5IlCwNJzsx7Ts439zk6x13urqruep7neq57uW5MFQr6gkBl/AXSpixGU5EnPz1Fzv9d/m2z\nmZagxE2PXoOj/yFWhm8nojtJnbuOZ//xGBWpMbj0UmKmPqz5BCeN7ZRO/pW2W9ywAf+q8winw5x1\n3ll4b/CiM+lwKA7mknMMSFHC3/kGbNtG5pimc6Emp0jhxx9+lg0HFAq3foxsPErtdC3Jng58uRiK\nMYKwZTOFu/+d6L4Exs2NhB49TLG3F5kpMkMJsifjqMtULspW0fCjH3CibxxL2IJUbkV36BAlk5Nk\ndJq/tOe2SqZ/MY1LJ5FyueDJJ6G6GtP27aTNszgOpslwDmO912C1aEE61qwBvR71lo2kh9NkQ1lE\ncyMnHXqEDOgsmmtBZ9WRC+e07jezs3DwICljLUqtEUEQEFwC9rgdq8HK3PY5JiudLJ/vRfShD4r8\n5pfa1s5tchNIBOid7aXWUcuccJzjchhjbIh0+Ury0QKCRaAvrHk0D63pIcRK7v21hbLhEjylea2K\nELBvtGPuMNNZ2sn+Sa0qe//kfj5/0eeZtk4z8PUBctEc1R89j9S5fpyzTobfHMRdM06ppVRTocwJ\n6Kf0JCuSjFSM0Lm3gRc736DaVoeQdBHKBAgkAgRLgmzdupVL266hpPgiiimMbeSLJDoThKUYlpQJ\nXU5CZ9Yh6U3UvpAhXDyXXFrCfLH23cudLkKpEFFvEiXmXASBkRGyOjdx2UDOLpMeS5MfTZG0KfTH\nFTI5B46EyMXqasYUB9/zmPnlKpgcMGFJS1TFnVz16pVc++q1bN26lcBQACkrYbfbSQ2mKO3UhBZz\nkRzOHzmp/mE1fr+fEkVbaE3ZIseEWcxxJzMfXsumbz5JzBCjudjMqslVTDdOYygzkB5PE5ucxJJL\n4Y1PMDlZRqB4gi0rGzh4EI4d62WZfg0rRtr47q330C06cMgrOWfLa4z12RgZgfPP1+Spf/ELGB8b\ngxC8cuR1rRAyJ+Ma8ZDW5/jdj7bz6KNv8fLgy5xXdR6miMrAXAtzOpH4gTjliSIikOobJpGY4psd\n/47X0Y2ckcn1XkIoaOOxK58hE3IzNxfF74emwCpGXaPkZqtIKHY6lHL0nT/nzfDPKc8vp6nMibN6\nHAgwpzNTcLvxHfMwZa7AvMzM6thqegI9f2zt/pPsj4JAsVjMA58GtgNHgMeLxWKPIAgfEwThtvm3\nfRVYLwjCIeB3wP8pFovB9/rse12r99cnGDk+wkAqRY2isN5qZV88SzSaw2zO83I4TqwnztQjmg57\nqj+FsdbIFVuvYFI/iTAikOjRQOCd1mPMUFBFZp+fxdSq/X/J3dX8/AMQMOTRCQK5gIHJSdh8iwlP\nJMZZX4pw4wM6TCbITGdQTob5fdaDNDRIPrYSz6Zyao4fZ2A+YXfH8A4eGTvJDV4vgiCQqIuxYt80\nM85RfpIbQiDJpgOv80RthsHGBtZP6ik8+RhqcoS2qTAl5hJMJ2IMuM2wYgXx8geo0r3GjvgKfFUb\ncXV8AwC7YqfF3cIHrv4ALQ+1LBwLpULMJedQrrwWzjkHw9M/Qq6SsSS0+zta+QceemqM4kM/Q54O\nUjdVR2t/JTVKEskcp2ixEFu/DWOdEcvVzUjhUegbQKlWSI1kSBxJoC5TOX9fFHtkDGk4hDXpQN/s\nJ9jcTEdfH7msG7vBh7nVit6jp60bYg6Hpkd9ww2cuOYa7vnJl0nkqxHSJYxjxHIqpeDSS+FTn0I0\nyZhXmYnuimLVO7HFtXjAqYyOU+4gRBFWrICf/YyA9RIsq+dVWt0S9oQd17BLa4hSalzoeCZJC22l\ncZvcTCemOT57nCsar6B7uptBYxqZGdKuJhInEmSieX5+vyaRPKWborBJpNtxBZWz5TjN4YXK9qp/\nrqL6S9V0lnRyYPIAc8k5puPTfOHcL/DaXa/x81/8nBeaXyB1zZV81ylQEAsUuguMR8cps5ThMrqo\njFQSsAS4ec3NxFpi5HQ5Xml4FSlSR3OVi9nkLIFEgLduf4sVt6xA0RvJmYooXV9lcMU9TF04RVAf\nRZ8xIRcM6Cwac6o86waSxqfp4LOE1DJN90rU4Ta5GXJMUMi6qfKlKOYL5IdHyeSsBAoGBK9M/HAc\nirB2i8Qrb4jo5SQVITfmCZmgvonD+/ejHFdY/U9r6HdfwsZMgg3HNtA42MjVV1/NxJEJlDkFm9lG\nZiLDso5lBCwBpvum8ff6yfXm6OrqwilqEX4pbeRwbhx5WsZ/64cxhmIIcpzhgWG2RLZwvOI4cpkG\nTsVhTYNphW2AZKacYGaClTXVWCywf/9xVuzp4M2qGvaE9lC/Os9F69dw+OQOylxWVqyA20xDfPWG\nMDqdJjXPnMCe8d8jF2XKHScwx8zsrnubceV7fHLftfxh8A80KU2U4mftlRamiwZG945SFRLJCaCE\negmHpzm3qYuK4x/S1hhyFIs+nE4QhDS/+lU9VmuI+oSfCecUqujieEjmKt/51LuryLx6F6WpajxG\nD0bPOCZhjhOFR3jr+wrLR9qIV3kwtZq4w3UHbd7/mZ4Cf1JMoFgs/rZYLDYVi8WGYrH49flj3y8W\niz+Y//dEsVi8qFgsts//PfZ+n30vs7SWc883v70AAufZ7fxmLko4kkVVs1x6uJcTY1FywRyZQIZk\nfxKlVuGqq64iU5oh2ZvUmEDLmSBwNB4nt0wh8KsA6jItcLpcVeneJXLlFQItiomXX9ZE0WztJtYW\ng4S6E2yMjmNUigR+FcC6xcmBXokm4SUECexrbESXLyezbx8AH376o8QmtrPaYuHI9BFekV/hrN5N\nhOVJXgwOcvcXHyPd1knAnOGV5lb+Zp9APhmn55JrufaIBVEQcfYE6fEboLUV12QfDfHjPDfUTmTN\nFC+Ho6SGUqTH0xz91FGq7dUL389hdDAZmySbz3Lv3x2BLVvQDRzBus6KO3mU8Y0xPnllgrvuvpq4\nUM3yD5bQONXIhUKCEinDqBJiTzRKZEcE23obYlUlTvUo6YITg08iNZ4nfjiOulyl/qVe8tIc9dM1\nyHEJqaGEY6dW2ZgXk7WEKkXB+yEvHdtzRE6JD23dyks33YQlPUVWtEEeUugWO8Nt3qwp5wG2Lhvh\nnWGsBgfOaPmCKwhOAwGAzk6SD29ndHwdNV/WVnedSYc9bsf8khn7Jjvt7XDRRWeON7fJzcHJg1hl\nK2vK1vDG8BsoDg+yEiOZK2Hq0SnyJonkUa1FYjAaJBgKog7fjMIsUiywKG+iFxH1Im2+No4FjrF7\nfDftvnZ0oo7777qfbW9sQ0gKbLtvG8O7h1E3q3iGPAzNDVGmllHMF1mZXkm+Ok+do4596/fx1rZu\n4sYxxg7XcfG5LmYTGgjI1TI6RWNFBpsT+3SYHv+r/DbzW8K6CEm9GbkoI9kX9bISZhcGIcSszrtQ\n7e5TffToe0jIfoSZaZ57cJpgzsrTjxTZ02+gapVM+I0wSo3Cps0CL78MijVBc6KJQl8aV/35RCej\nrOxdiVAQSOu38LXNk1iSFuon69nQ2YkxYaDwSAFzyozBa6Dlxz8hogTY/vp2mseaSQ4n6erqwl7I\nkBGKRPRuTkYGYRxKW8vo7qrFop9B36OnYV8Db1S+gcFvYKh3iN7Zl4g4ndQwBI5+dDEdFOCss2B8\n7zTWSSOhrirOrjwbz6pBNqxopG+0D1Xay+23z7EmG2DmF1qG4OjoKLa8j5H0HnRpHZe1FBkoZpme\nvJLK/VXIr1Zw8o6TDB+N4S36+PiXFIaTFswpM+Vx6HWLVBlPMj09jdfrpVrJEEGiXD8OiOzaBbIc\nIZeb5qmnvoQ/n8FjuoEqUwspi0yXpZFvXfAd2PNx9LpJSs2lGL3jXKNPkjTPciQ+jiyYMdcrqK0q\nwkkBnfjufUf+XPuLqhhu+dRGXty+ndGBASoVhS6bjVvLqghFcqhmONvmZGRS878ne5MLTGDjxo18\n/adfJ3EsseAOeqcdicdRO1Ty0TwTBpUf/xh69khkv7CMI4cErAc8vPwybNoE6jKVhxqWU/jGCsJF\nPcXDEaZ/OU35jR5EoUgXr+O53IJtow1x5UrUgwcZCY8wNHcCb+IYgiDw8MGHqV5XjT9sIy2Mcuhv\nbsEdCrD3n+5GSvno7+jg/DfHOHROE93rmth6TAuglQxMcNhfIN1Yx8rhDMZslN8PVDNWNUsgm6X3\ni/3sXrab8R+MM/ivgwzdrZXb2xU7A6EB1JyFzh8myba0YpjqxXKWFXfmCCP/7qFuYhWuZfVYzitj\n2bmlWI1W1uRmceizhGwpTiSThHeEsa63gt+PbmyAvL+e9HiWYh7CO8Ko5XlM/b0ITRtREnr0CT2F\n5jLe6uggK+mRTGVIRp8GAtd7qXs+RfawTLGqBlpb6S4p4ad1j1GskEEEN+lFJnCaWbusRHZGND2W\n+JkgkA9r7oNiRycnp66j/MIoSpW26OVH8tjjdgyvG7CdbePv/15TY32neUweDk4dpMnVRKOrkd3j\nu/GoHuRtl5GYM2MoMRBsNpKIT5IL55iZmcFUYSJlymMp9Gkdnk6ljsybSW+ixlHDo4ceZWXJyoXj\nfqufqk1V1PXVsSW7hdLNpSTNSU7uPYnnIQ8HNh7gI/JHaD2rFatspc/Xj/rMgwAAIABJREFUh+d6\nC2SNjB6q4/LNGhOYic/gNi1eU29zsDrrpqZuNW/PvU1MHyOp2MhgRD4NBFJ2Hxmrh2BEWpAbKDGX\ncEg6REryw+QkK93DyPWVGOIZPvuvBvwdBg0EqhXOP1/rN6E4Mtzk3oYwGuTSD24FEbpmu9jetZ30\nVCPZXTlebXgVAOWsyxiai/NwvAM5KKNUK5ieeQZDdoaBXw8gISHOiXR1dWHOZZlAJCzZUaMqOpMO\nnaqj7MZP4EtPsvXVrRRvKOIc2YPhR/eQGk8hRSeYbWrCEh3HUXMUS1blK1/5CtdcU8Q/bmeq0k5N\no8jF9RdzOHUYKSWx7WPb0GVT9PR8jNRgirmX5igUCkxMTFDraOGvdpzHVa9dxTllBgYEK8fCTqrD\nbYS6B3AZXTz18B4MgoHKdj1R2UkpHpS8QJ9bplTXTzgcxuVy4cqn6caGO59Clo/x1FOgqkHgOl54\n4WfYYwFmEx3U1ojc9HmF9EiKtjZQVYBBKh2VqOYA1+XdPLBGz1c++G/s+8Ra/OUCplYTiaOLccj/\nrv1FgYDPmqTsmmswPPEE8nzg92/8NSSieaxWA1e63UzPaMHORG9igQkAeFZ6SJ5MkhxIYmwwLjlv\nNJdjTzRK7RoniPCfzxi5916t7d/y26cRbx5i5Jcufv97bTMqiAKxdjejYwKvFj0EfzxGdHcU1yVO\nzi3vJ68z0PrUamzrbNjWrKG2p4dnTryIZGlmZmYPxWKR3/b9lrZz2xAQWDEdIXbOGq4vPkZ3AeRs\nKc6zNV3yFzrNHKqVcCbzZHcfoC7Yx15PkqOWPKYsHK6tobg5gAWJNRYLc9Mp/Lf7OfToKKnZDCPf\nGCEzlcGhOOib7MMSNpM2wJG0DzkxhNCYwVBIYpG83LjnFm5ZfQtYLQixKOYOM0nZgDVTJOTIcDKZ\nXGACp/S5lUs7SEzoURxZUv0pTCOvE1FXIV+ykgJ6xKLAeHkZv21t5cjqD1GmbMBSdgmVsoyxxkj3\nE6UEc01MWD8EgkC0P0HNkEh6lYLkkGjSxbFYNKG8083aZSWyK0LXCictaukSENDZdAtMYLy/lRRl\nVHxG66eQT+bJHspij9tR+hWsXVbey9wmN4ViYQEEMvkMXtWL/H8+SmYmjyiLJBwm+isDhF4NEUqH\naLipgcFzBhGUoKb5PQ8C6bH0QiC+s6STJ44+wcrSlUuuZz/bzrbcNrqSXajLVZLNSeoG6yg8XIAC\n2H5ow7vci1W2EklHSBViWAZv5Jrll1PuXGQCp4MAFgsMDrJ2xaWECiFihhhZg50ECgbroupu3ukl\nZi1lbm5R98pn9jFlmSJb9GqaCyMjWJdVsK4hg6vBgOyXyU5lUWoUSkq0gGbOlCfcJ+LOjLPm8mrM\nJWZWJlbyua9/DmubieGjbfRUHSXoGCKaq+P7nXfi5KtMfWEKpVpBCAaxp4M07mkktS6FPWunpaUF\nYzrDbLFIUuemI9exAOhtH/w0pakResv3MfndC7nv2RyGXz+EHNDjSCTIVpQj+Hx85c69XLzmYh58\n8EG6St7i5kIHzcM/oq62yCX1l7AntodcKEdeynPdZddy4I295MI5MpMZxg6N4XA4aK9oozzi5do9\n19KQEDlRLGegKFMr1ZDL5Rkfn2DwrUMkbCAIAmq1Bz8egvaz0QU+iz1zApfLBQWQ4xmOiVb++nIw\nGg/wwgtgsUyg1y/j/vvuxxKO8fzBz2IypbA1yKRH0kgSPHlBH2q8lxp3DS0vtTBiG2d71ff4u7P/\njrE5K34/KDUKmckM+Xj+Pcf2n2N/USBgTwfpv/RS0i+9xNR8g15BMBCLgd0ms8JsJjyTQnJIJHoT\nC0wANBeA3qdHLl+kyqfsyZkZNtrtlG1wYN/kYPsfdDz+uKbwednNGaLnTdC3UyabhaYmYGKCb+zY\nQF8f7NB7mHlsGudFTnQmHVvUnfTYuxbOrVu9mrNOnuT+w8/w8k+zbOzL8cbwGwyHh1l1jqY9vnIq\nzMvbNmIywfGxSdRiCWvb2vjyHTfzG/s0E9lBvlN9IeKW89lQeJs97gy/nujmeImJaH0bfPY4Z+Nm\nuaqSmM3AeRYu+dcET90p477WzeRDk9gVOz0HezAZbOxZDSd3xUnhQ5x4nSQluAcLOJV6GlwNPJ1K\nMRUIYG43E/KYMccMnPdagY5zRyhkChqwulwgy+jaWxBcDvSGOHKljPi755iOryG7dTU6MYpElOHX\njBzR6QjV/y2h0kbi9rOompfuVlpVnrn/fPqGLiU7l6XsN0l6NuuJNRlQKhQadHF8uQQ7y3YuGdSi\nSyIqFihNuykreN/VHTR63yh992Zoke9BXNEKwPTPp3HWOWkZa0EQBVKD2sJcLBY5dPkhsrOLnedO\nLaaNrkZsig2f6sNj8mAoM5CP5RF0AnGbyoBvmpEHRohJMaq3VDN8wzB5vU5rNjEPAmP/OUb/32ni\nb50lnSRzyTNAwLbBRmRHRIutLFexr7Zz02s3YW4x0/ZCG0qlgrnTvAACoVSIVdWN3PEJEy7jfEwg\n+S4gEArR2nQ2iBC3xMmIVlIYFxrEAxRKypgzlS/0wgDNHTRlmyKbdVDs6eX4twvkSmrJTGYwlGgg\nAKBUa8/yiivg8JjIbB/YCCP6PJzfeD6urAvfeh+ej1YBIi2mGG55gmj5JmpCq6nhP5CsEqZGGeJx\n/OlZ/HN+Ug0piroixYkYhkSWODEKOi9NqaYFEBBkmfHmo3xk9P/QuqqTlR/Sk2z1ok/pqQoamM3X\nkStvItXXzdr6tbjdbgw3X4+VFVQmfk2zbYIGVwM5c47gVJDzH9vJ5269n/+YEdCX63FscjD67Ch+\nv58NrZ14w16O24+TeD7CrC3PCFFKCnqsUicvvrib0sk8arsLDh+mrDZPtbGJ0cQnMAU240xl8Hq9\nZCYyiC49leuMqHEdmcxbxONgMg3jcPi4+vyr0BstjMcPEYu9gVyhgUAunEN+ZoTlPY00eBq48NUL\nOdi5j7b8Xm79SS+XbP8sfj+IkoixwUii93+GDfxFgcDn2z+EzuWi9tJL+c53vgNAsSiRTILFIrNC\nVUnNZrF2Wc9gAgCmJhNqi3rGeR+ZmuImnw+lQsH6/RVkMlpWAECbqoIpz3XXF9myRdMfGXv+51RM\nv8Xx3iIBVUVdruL9kFaj3SEeYszTsXjy5mZKZmZw73iVc/b1cf1sCf/8yj+zpXYLQlxAT5BBt4NX\nMr2oKvTPTGATS9lgt/Ptq2+gJ3ic0cRJ7jffwqtf7uNtHgWbh5eGdtBf56Nyw7lgznO5QwOBbDDH\nHl2CNRYL3xoZQbzZxfgPxzEnzfSN9yH67AwsE8j+JkTCUIv+pReIGUqw7UsTLBXJFAqMGgyMz86i\ntqnoTQJJyUL8i14e/LZC52udWgBWEKC8nGR9PekqO1I2hLpcpbhrP9mGNQy31KEUAkhChNwjOqTp\nHOrRDHurc4ym01TI2gLilCSmlDyOzQ4CTwdofzFL+EoLY5cZKbu9jNpijMZDo2QDWcJvLrbXHMtk\nGCgtsiq0nsvly88AgenHpum7qw9rl5Vu8/2kwtpmYPbZWaquqsIVc2FoNjD9+LxE8ZE4wd8ECW4P\nLpzHrtgRBZEmdxOgCdZ5TJ6FTUR2JkvEZiWgzjD26hgKCgaDga7VXcSSGygKwiITGEkz+7wmzdFR\n0oFBZ6DV07pkHJo7zCQHkuQjeeRKmZbzW/DP+Sm/oxy9Xc+aI2uwrbctAYEPX21nzRqwKTbimTgT\n0Qk8ptNKWM1aOY7i89PqbiXhTZDIyGREEzp1EQRmuy7n4fN/vIQJlJhLMLgNFDAw9Z0ext/0EJhb\nvggC5dozNNZov+1XvwqGCgP5OZG8yweiyHVl11FoLyDoBHwf9tF87XG+7FzGWjVIMNiEdcqBm+10\n/LaRylsUsFqpzGjPpL/YT8GWJd2+CSmcJscsguClNlG7ADwAtru+zP7bPkbH7t2AibctaXJKiIpp\nH8nfnktAPId8/0kaXA189Mor0Y1bmTGn6KWC2oyWh9Le0E5kNMAlzx3jyFdup7PgI2GN49jiIPpK\nlPLycja2rMeWsPHgmh+jd+uxdhRBn0HWh7jL5OHB7/2YDxWvYe3MV2DVKi4P/Sdy0oTekifuilDD\nJrxeL+mRNJZahb/7lkJxskgy+eb8ozrJ9df7SJxIkPOZyOc3EZ9+k7EHxkiPpAnvCGNqMdEx1YH1\nD1ZmXbMcWd7No0/D1Lie84Yfxj9fatv5Wifmzj+7FOtd7S8KBOq8zXRZrVz88Y/z/e9/n0QiQSSS\nwGgESVJwGwzYYpBfbSJ+OE56NL2wYwAwtZgwtZj45Cdh506tXuWvP51j530OLp9P5Xv5ZS01bD7R\nhA6zGa9ezwP3itx3n6ZP8vwjX0CfLzB0YhijETp3duK5Vpt4FandjNacxjQkiYm6Sh54Lk2xs5OV\nUyKvDb3GRXUXkX/ieVzC24zr29k1tgtVhdHQJE5DCQZR5CJPBQa9hT1TO8hO1TG3I06KEpw5J0em\n9vH0336I+s/ehu4znVxQYWG5qiKG8vxBiHKTz8ft5eV80TmFTtURvS/KpHeSgtuGZZ0VzxtpMs5G\n7Nu3EzGXoexNMVUKQ6kUEZOJYCiE2q5SFgsj5iUaWrzsLMlgalqMp/zmW9+iSZZ5ziOgT45gP9cO\nUxMYz65lCCgak4hyhldukPn+XxVJHImTX6ZglySMOu03cun1zOZyeK/3Mvj1YSwRUM+2MF0qUHJj\nCZ5cCu/haUpvLWXu5bmFaw+mUoh5mLhpkPxv8ug9iyDgvMjJsieXIaoiLY+2oK71EO/W0nRjh2I4\nztG2uiXXlBD4VYBCusDc9jl0Nh2zLwYZSWnsQCfq8KpeWtxahlWTqwmf2acxkiJkA1mCNhtZZojX\npHCYtPNesewKdP4ScrfcDo2NAKRGUhQzRUKvheiq6OLei+49o/OTqBexnmXFtExLYa7cWInnOg+u\nK7SxeSr7ySJbiKajzKXmcBi1a4qCiMPo4Pjs8TOZAIDLxdamrcTlOLGESFZYygRcJXr6o54zmECF\nrQK5ysTA5GV41N1MHvaTDWTRe/QYfAbQLTIBSYLLbjUhiyqG6lIK2QKtPa2svFNjPJJNwvsv52F+\n7jkcg9uJDehQLlCI6YsIwSBCaA78fsJKHKQCO6Z24CBAIuZC0OUxiVPoix42GTYtmdft27ax8Xvf\nQxAE1jSu4Tl5GEUKY5vbhBg3EknXIY+M0eBs4Aa/nyOsIduZJlvfgnXsGADrlq2jMJOit9JEdsv5\nxIw1xFKDOLY4EPYJlPvL8ev8zKqzJJ0Fusa7uObmWiyWWlTDOKtoxr47S1YMYm8R4OWXaRt4gowc\npf6KIfotOlzChfh8PlLDKeQKGblKJj2UxukMYbcXyGSO8MEP+kgeT0K5CVjL9OROrdp8MkX3w914\nrvWwR9pD5GsRdly8gxPWE5QlC3xs4kso+Th+Z3Lhtz41Xv679hcFAqKs8o+VlfzNqlW43W6GhoYI\nhUJYLCzISPviOsaW6UgNpDCUGBANIrlCgSdnZvjtR/VEP+HkoYfg6qvhzrsKPPFCnsKT5QSntAnx\nyita8PeUtagqB1evxmgUsNnglmdv4bKAtlUKBN/AZALJLC283zN7kJPnvbjw+tfHf81r1jFaZvII\n992Hv0/rLn+xdwPK1z6DsqGW0ngd3VPdmKxpphOTeE2a//pKtxtJrSKaiZKarCZ1OMiRFRLGiIXZ\nYDfry1rQ6UX2PmyjtFRgmcmEEi7yYiHMFoeDz5eX81IohPqdKlrvaCVYDIJkYflZbvIiZCuaMYRC\nRJx+2J1gzFukP5UibjQSDYVQW1V042n0hhBOt4t4Pk84p/na7x4a4k6fj6c7O9Gt8GKL7qT8Ex6E\nVBzzpgqGUykyLgHRUuSe69L84ic26r5ZR61TXXAFgcYEgtksrstcZMbS7Nsi4ZANhHI5RFkkqBhJ\ndLjx3egj9Epo4XMjvWFqBkC6wkF2JrvABIrFIpJNQl2uIhpE5BIZtU0l1h0jF8uRGc9gXmVGkARK\nrypFbVUJbtcYQNU/VTH121kuPLiou7Ln1j3UObXq8y+f92U+vvrjxHviCzUJU2YFoZBl6Cd6XLbF\nvhRKtULsw19aZAKjabw3eJl9ZhaT3sQn1nziXce45WwrxuUaW9Xb9Sz75TJEaek0lEQJWZIZj45j\nV+wLx11GF2PRsTNBQBTBZmNTzSaScpJ01kDuHUzgrLNg+3YtU/cUE1hbvpZtK7YhV8hgMdEU/yLR\nIQOSQ0LUiwg6gfLPlmNsXIyxyfVWsgUbBa8mymgoNSywZACWLQOrFXltHQa/gZY7WnA3NWn1HPON\nOCZ8ceTVu2DvLmzxIWLrt2EwJCg1jZNNKOSGc8hVZ7aSBdi8ejM7K1NY8rOks1s5uaKH0LQT73Sc\nSlslJUePkpJX4d3iYsunmhGOaUygq7ULfVzPAU8eq2wl7mknHziMUqtQyBWosdWQHcsyYwpgkfyI\nepEbbxTR6yVq1cexpWq5kzvR2/fCunXQ1YUxE8YpfgPzKidvZRxIRTc1+hrSI2nkShmD10AumsPv\nLuWpp44TDu/H5/OROJZAX2ME1jE8s4fMdIaIECH+mzjm9WYezT2KY7ODUFeIZC6AvlhkOGxjglJ8\nxcl3/V3+O/YXBQKCYmGL00mb2cy22DYmBibmQUBckJG2RwV6bFmUKmUhHrAzEuHTJ07wnBDmqwMB\nbDb4xy/nuP/hHOc+MMStfyVw990aMziVAXS6lciLA65n9AAlAzNMlDmQ9W8v7d4Ti2EKRtguaM2g\nxyJj3PSrm+j8yF1It94GXV1I0TjPX/QI5b94gVRZB7mzNuGsdFJvqoeSA4TyE5RZtYKZS51OwrKf\nEnMpilfEMjbH4a1WDFNmyMVoc2t6RCs0TTGcWR15CRIGaDaZMEsSt5aV8UBZmNIW7ZwFyUyVxchw\ni0iwXnNzREvKKQZzDPoK9CWTuJxOEqEQOpOOuQoRoxRAsNupNxrpSyZ5aGKChyYneaWjg5UWCyvr\nKsga4xy/7nVykhPnpW6G02nSdQ6kUpU8YGs1U/7pcppNpiUg4NLrmc1m0ak6cv9SQu8NRuySxNw8\n2LxeV03mhiqs66wkjiYWAr6JF8OcaIBssUAhW0A0iOSTeXaW7SQ7myV2IIa5Q6PD6nKV+OE4iSNa\nZphOr2PZk8tQ21S8N3iZ/PEkkTcjlN5aSt4kkO1OMjbfjMhvXZSyKrWU4jQ6SRxJYPBqm46ICcxq\nKfvDh+dVTTUz1hiXxBsyYxnKPllG4JkA8Z44odcXAe102/4RPQ9/7I/v4KyylaGQVjy58FuaNBA6\nAwQcDhBFuiq6qKmoQTY4yYsmRHVxere0QHe3lviwSgtVUe+s5zPrPoO6XKXirgokXRbPFTaNAcxb\n/Tfr0RkXwUR02nCxkx3bP8bY/WM0/aBp6Y5UEOBzn4O//mtW7V6F/Xw7Oo9HA4HZWXA6Ga8uoXbo\nPn4wMYF82Vqi6QrkYpAPbplC0Gls7nQmcLrVu+s54gVzYpwcDu674HtEJyTWpMq1lMmXX8ZTuoz1\nV63XvvQxjQlYvBYMWQs77DFssg3B0Yw9eBSAWcsslflKUiMp5kjhy2k/UCIBsWgR29wuOq3/xKf5\nD9ptPRrQiSLC1VexOvkGGW853TM+7PpXWNa7jPRwGqVcRkgmUCoU6i31wARTU1P4fD7Cb4RR19qA\ncgw6A3szexnLjmGMGck15gg5Q6x4vo0yWxnLEi6iJpUvfFFg1lCKbmr8j46dP9f+okBAlLUdUiFX\nYO34WmaOzjA3N4fVqlsAAVOkyOtCDBpklBptoDz/Wg7pn9q4v6GB145kaGgo4rgywEW/6+XZCxr4\nwj+I/PSnGnN3uxeLhd5pc8k5mkeSCI1N5Cv9uKwHl4JATw/DJSaGY2PMJmbZObqTsyvPpv0T/6J1\nlhFFhI4OLomVwOOPE6q5FrlCRqlV6NB1kPG+RUKYpMJRQrFQJPP0HLWORgwmP97P7yNdlPjw+csp\nC2oTv8a+9EZzwRxpm8Bmh2Nh4t3u9/Po1BQ6SXML5HRmHJJE4GITxzdUkzUYiFdpyh19njx9yST1\nXi/FaJR4Pk9PTQGVabDZqDcaOZFM8q3RUb7X2EjZPDh2VlSQNsVIHRlGWlaJZJYYTqWIbFuL82Mb\nkQSB2vmF/0q3mw+dJrvo1OsJzi/4Ix+xoNabsEsSofljrR/30H6hEVEWsay1EHpNWzyVV2LsXQ25\ngTSiLJINZYnujWry1S/MLgEBc5uZeHecWHcMtU0bQ+6tbgRRwPMBD4FnA1r8w64ndK6JNbvh93OL\nrqdMIMPMr2YWXsePxFGqFURVxCJLuNQyemcOL7hmQGMCqQENBLKBLKJJxLLKgk7VcejiQ3Rf2k0h\nvTTjCWBSn6PXmD3j+CnLp/IMf2MYq2xlIjZxBhNQJAWT/rRBabEsVC0rksKPbvwRBtVNUHEuYQIA\nPh88+KAm4Xy6NdzbgP8fW+HIEcrurMO+2c57mt3Ocv6FdXftYfWh1QvB4yV2221w443IpbI2Tk/1\nZg0GweVipqWFfCjEP7S0oGxuJ9avQ58cRwlNYnAK2iL6HiBQaaskpYe0HEXPESa8E4x7RnCP+zWa\nPzpKNiohl8ha4G8eBERFRCwK9Lj02BQbhbyX1vwYY4ODjOpG8cQ9pIfTuHzr6fDdCUBPD6xrDCLI\nMkpshhF+QXn0BLRqsR7pA9cAcNf/V0HC7KVeepKynjLCb4SRE4NwySXIVTKVciX9/f0Ui0WMGIkd\niuE8W8taa/R28gAPILgFBqVBgskgq61WWLOGFncLG/PNhGWZ66+Hxo1li52s/gftLwoEBJ324NOj\nacSiyNzQHHNzc5jNOgTBoLkCQnkkh8Tjnij7y7TJ9Ng3TIy/bqZCMJIdViipzfPr2Vmu9bkRBAGv\nF956C555BvbtW4wHvNNOBk9yacCB0NWFubQCj/n4UhA4coQjXvCqXg5OHWTX6C7W+dctPUlnJzzx\nBAwNESysQKnUGEt7tJ2EYxd54yQ17lJG7hnh6AePclv8UiZKPsDan7k4GHVS0yDiM3uRRRmf2bfk\n1NlgFtmp5yO+xeNlsswlTie7EtqCkxFVHJJE1ecqeHBDjp985SsklmuDNlgqcCgex+N04kun+dnU\nFP3nGXAU9y2AwC+np4nm82y0Ly4EeocDxZHm6OeziBUa4xhOp/Fd7aHik+XUKAo18yCw3mbjutOE\nzq06HclCQQtIp9OUy/ISEPjUpxbc6jg2OQi+ECSfyuPdneH4BXoYyoAAmckMkbci6L16Zp9dCgKm\nZhOp/hTRPVHM7UuDZQaPAecFThwXagv46DkGLvyDwO9nFwPEe+/oZf+NR8gntOyk+JG4VnBo1WGX\nJEqt5YzMHl2yK1eqlQUmkB5NI5drC97qg6tZN7gOU7OJyFuRM8ZYOJdbYCHvZtOPT9P/j/1YDdoi\nsQQETC7cJvfSnbfZvAACoElqqLITV/uaM0Dg/UwQBGhqwrraSsO9De/9xvlxoa/zIpe+u8vmDDsd\nBJxOqKujURQRzz5bS0OdyWEwZ+HttzF4tR4bkkN611PVOetoUBs4UfgdReUH3Nh2I/7N1UQ33w7X\nXkvh7PPIh/PoXXqtQ2EoBJEIQi6HRIwRixmLwUJqNEfcHOWJf/gHejO9qDMq6ZE0jqYqEglt/A4O\nQqd3DMrLERobuLrsbeRUGObVijn3XPKdqzgcq8ZRbUPNBai63U/sQAw5PwF9fSiVCmW6Mg4fPkxJ\nSQmRnREsnRZcZdqzWe7tpI8+6lbUsb+wn6GhIdqMRujp4XPrPssV0hpmDQZEESyNpTD+/3cmIGo0\n9NTkio5F55mApPUVSBYQBIGn1rQjX7ScbxscvPkmzAxIlNXnOXxYoHTGTqYszva5OS49bXI0NmoA\n/n7deE4ET7BhVISuLqxlNbiKAQzmKIVsgfjROKmX9rLHnuDyhss5MHmAt8beokPoWHqSzk6K//Vf\ncN11pMfyGhOoUWiZaCFk2QHmKaqG9Yx8a4SqL1Sx+Zd2jl30ac7pSXNUZ6esDEpLSymnHFFY+nhy\nwRwlPhMXvqPL/XJVZRZtEU6KRhySxDVuN/tjMe4//3yMlRb0Pj2qqmdvNIrX6cSbSnHf2BjWD3vw\npV9YAIEnAwE+WlKCePpCY7dTkkmxd6Kf8LwPfDiVonKeKfxbTQ3n2t999ygIAo5598+7gcDpVrJN\nC+QOfmGQ4VoBX5sVMVKgkCyQGkoR2Rmh8u8rCW4PEt0dXQABURZRahQCTwVQ28/MDmt+pJnKv9cm\nbu8GCauqR/jxLMWiFshNvBahtx7Gn50hn8oT3RPFssZC0arDJklU2SoIho+/NwiMpDW/OiAaRARB\nwL7Zztzv5864l0g+z+h7gECxWGTsvjHIg1nUvtvpsscuo2upKwiWMAEAySpRjBWxSJY/CwT+ZDtV\n3l1W9qd/5h0g4HK5iMfjtLe3Y/Brc15faoJEAoNfQalS3jPo6TQ62XPbHt7IjhOwT/Pti79N64Wt\nRPTt0N9P9t/u1yRGdIIWK2lshN5e6O1F0qd5/IqnKcaKFNIFSrduRNy/nz2BPYhDIqnhFMYqmZl5\nUjg5CbXKOH1OJ5O1tTxy9VMILS3aeQH0enT79vCL31q5734BvF7KP6zHus6KsTAKExPIJRIuXBw+\nfBifz0foDyHs59kXgvMd3pX48NH2V23sbNjJzp07qdbrIZmEQAB7Ok3g1PXK/jcwAWEpCMQn44RC\nIaxWA6Iokw1mkZwSuRz89At2Dv7EyQUXgH3bOJ2ri+zfD/K4ypuWSRqNRnwGw/tdjpf6XyKUWvTd\nngyepHEoBmvWILo9+KNeipY97G7bzeErDxP65ZsM+c2sr1jP7vHd7B/fDxfAwJcGNNEpIF3WipDP\nk7v0uoXFQalVKD1eSl6YQ80oFL4ySPND2sIU2xmBr0ziKqTprfb9cpZmAAAgAElEQVQhilBfW091\ntHrhvhLHtXzgU9//neaXZYJFbRGKiSoOvR5Fp+MjPh8H43Esy814rvHg0OuZy+UocblwpNN0x+Ns\nMRg0ZNTrqTdqMZZtvqUMBJsNfTjMtfk8z0oSE+k0M9kspfO/7we8Xpzvg66ngsPDfwQEZL9M689b\nGb13lB1nFWmzmElWSIgGkWRvksjOCO4r3agtKtlAFlPDIk1Tl6tkZ7IL7qDTzeA2LKR9zuSycG8F\n1zyYZ++XTtJzcw9jX3Dx/CXQ99MJJn44gXWtFfeVbvJ3erFJEo32Kgr51JKYgFKtMHEyxnQms8AE\nTjfHZscCCIzeP0pmRqsIj+RyTGUy5ApnuooiuyLkQjlMLSbMBW3HKomLz9ttci9NDwXNt3P99Qsv\ndWYd+XiefDS/JDvof8x0Og0ISkv/9M+8AwROybuvWLFiwZ1kqNOOGSot7xkUPmVWq5UdK1bw085O\n7fVarbAQu51Mzored9pYbNFaetLdjWSBFeoKUoMplGoFdfUqPn3BBXz3+e+S6k2RHk5jbVAWQGBq\nCiqlMQZdLoZrauCppxZcQaeb2z3vYvN6kRIBVu5ciT40AsUiBmMSW8G2CAKvhrBttCFJGn53ulbw\nX/wXxWSRypZKduzYQcWpRX9oCGsiwUIouPR/ERNID2k7pXQgPc8EDAiCgVwwh96p5/HHoa5aQPyv\nPTz8WJ7glhHOWS2ybx9EhgwESiILKaHvZcVikRufupHbnrttYQEfHjuKdS6hqVO63VSk7DiDT+O6\n3MXaE2tRhSEilRWsKFnBs73PUiFX4KnzMPvsLINfHARg7PdWRsVrGd1bRS6Sw+A1YKw1EtsVo3Wk\niVzUz8oT63Bd4kJn0lFySwmj3xnlidZWKuq0Sbt161a++OAXyYVzxA7HeLv5bdLj6YXv/07zGwxM\nF/SIgkhRZ8Y0P4hunZ+onjqVxu824pAkXJKE2eHAmkwiAmfDwu5ulcXCN+vqqDYurbjGZoNwmHXx\nOHMeD+179rDWakUS/7Th49Lrmcxk2BEOs85qfU8QALCfa8f9qyb2XSPj0esJV4hILonIrgjFfBGl\nRsG11YXarmq7vXlT29TFtMb3sUA2i3O5mSN3WBgZjNH0wyaObdHz1jmQ+0OE4buHqf5yNZJVYu5q\nC3ZJos2pxWZOd83oSvVIs3mOzkXfFQRsZ9uIH4oz/ctpTt5+ksDTmqKr8/UUH/kJTKTOZAPjD4zj\n/6QfQ5kBNacuuR5obkiv+o6egq2tcOONCy8FnYBoFMlMZ5YEhv9H7ZZbtDnyp9opEJidBZdrAQTa\n2tq0ALwO9C2lYLFgqDAuJHy8n60/7zxM87EnY52RzFSGfDJPZiqzdAw0N8Obb8KuXUgOA7m5HKkB\nDQRoaUE8dowNl2xANIrEj8ZxtSxlAqX5McY9HsZqamBigqRax9GPHH33m/J6YVqrgTi1Y9cLIUwp\nE5OTk5Q5y4gdiGHr0thdeTkYKWA1WsnOZGlqamLXrl2UnNogDA2hRqNMnHr9v4MJaItgajCF6BPJ\nz+XnQUBewgS+/nX4h78XaLaYENcHcSg61q/RsXs3jA2JLKsXuOodmi4A+UKe7qluAIbCQwgI9AR6\neOjAQwAUu7tJNdSAJFF0OFk+YeKF9p9yUcVFnOjfg5yPIphqWOZZRjqXplPoxLLSQvuL7Yz/cJzw\nm2EmfhxA+sn9jHxzDNkvI4gCSpWC3qnHaTuPbKIMVV1cvKr+sYqOP3SQ9KgLAWtjlRH3JW7Gvz/O\n8NeGoQjJ/uT7MoHxTAab4sCmLAaNW1WV/6irWwjaOiWJOqMRzGbUeJyPlpRgSyS0RR6wShKfr6g4\n88HMswWxv587Vq9mZsMGXp/fhf0p5tTr+c3sLPVGI16DAZMokisWSb/LbhhgcoOMq0xzawX9Igaf\nAZ1Zh7XLiiAIlN5aSv23li5CltUWLGssfzR3eiabxa3XI9ziZucXrTgvcDKRzbKh0snAKgnrOiuW\nTi3IHs7lsEkSTc5qAAT9osjR8WyKWRdMnYyTHkmjVCwNZOqMOixrLBy7+RjeG7wLrGDFz1Nc8RwM\n3NB7RuA48lYE56VODCUG1LS6JBANcMPyG/j2Rd9+z+9WLBYZe2AMySqRmcj8v3EHAXz72wtFan+S\nvYMJlJWV0dDQgN1uR9AJyKUyhnVNcMUV+D/tp/rL1X/0lB//+Me59dZbAU3mRanU3HOZKa3QbcGu\nvBL274cf/hDJbyMXypE4nsDUaFpkCWh6YaJRxFsnLWEC7vQYIy4Xg1VVACTEamJ7Y+9+U955+Q3Q\nduweD4bcNHJC5ktAc7oCdZm68Fz27wcjeZRahex0lsbGRuLxOO5UCmprYWgIJRJh5NSGqbSUwugo\n3/ve91i1ahXd3d1/+jN4H/uLAoFTlhpMoXaqEIW5uTlsNgVRlMkFc8QEPbmcpgq5QlV5YmaGGinP\nQfFHHDigPYfD56ym7V0G6eOHH2fdg+tI5VLsGt1FV0UXP7vmZ/zt7/6WaDqK9fgQUnsHxWKRkUeS\nVKYEej85yWWNl7H7Z/cwWFOGJ1iCUW+k2d1Me7gdpU7B4DFQd08dhy4+hLnTTMlHSjC1mBb9xLLI\n2v61NHs/jHXkg0vuSbJJWFdbMZmgunrxeOXfVjJyzwhzv5vDdYWL1EDqPZlAmSwzlk7zww88h8u8\ntHvnnRUVC4VbDr2eWqMRLBakWIwHm5shElkAgfc1m03zrZaU/PH3vsNcksRj09NcPL8DFAQBuyQt\n1CS80waSSaoVrehsskxrJqMuV7Gu0xiLwW3Q9I1OM+fFTpY/vfyP3ksgm8Wj11OlKAzOF42Np9Nc\n5/Fw92cKNPywceG9oVwOuyRRbtV0lO4cnOKOE1p68MFYjD2rIfvs3LsyAQD31W58N/movbuW0Msh\n8sk8tXty/PtPFDInk0sqpAsZLe5hrDNi8BkwJo1LmMDReByj3ohHXXQHJfuSS66XC+Y48ckTiIpI\nMVv8fwcCf669AwRqa2s5eFqtRumtpajnlMNPf4pkkdA73idwN29NTU2cPa+/BaDUagrBgScDS5lA\nezu8/TbEYkgt5RoInJKbPxU4DodRl6koFQoej0AwCIWCxgSssTEGnU5OVlSAIJCgWisMnPceLLHy\ncpiXt2Z8HNauxZAYQxcS+Wdg2XB6SSW0LEMumsNYayQzk6FxPkPCHo/D+vUwNIQhGGRofpxSVkai\nv58nnniCr33tayxbtuxPfwbvY3+xIOBc60TJKkxNTWG1KgiCgWwwS0yUWL5cy/BpN5t5bnYWY+QA\nn97+N1St7F3INCmkC0tytYvFIvfsuAeDzsCrg6+ya2wXZ5WdRZuvjfOqz+Pet+6laTyDsvL/svfm\ncXLUdf7/89Ndfd/dc585JvdJAuFIgAASQC4vFNbFY/0iKi7LeoGycri4i/7UdR/Kiigquii6IAKi\ngIDhDBCOkHOSSTKZJHMfPdP3/fn9UT09PTM9yYRcA/k8H488Ml1T1VVdU12vet8r6H+0n/BOM66G\nFJWNGlfMvwLT357hjSVlBFp1N9N/XfBfnLX7LGwzddO18h8rKftgGY1f158YGm9uxLt65EsshGCW\naykNvdeW/Mxnnw1nnTXy2rnEiWuFi7ob6nAucZLYnZjQEnDnb/J292wCB4iDBDRN9/u7XBAO64UT\nQ0OTEwGvF/bte0ci4DeZ6EiluKjIRTfsErq/u3vkIs+zJ99K3GcysXGFoPLjlUy/fTpVV0+8byEE\nBtPoy3l9KMQ127cXXuekZCCTIZAXgeH9dqZSLHU6MVSZaLGkCusPZTJ4jEY8Fg9Os5PHlq3kl11d\nDKbTvB2J8NIlRrx/CBcqRMdS+8Va5tyj98Exuo20/6idPU2C2gYHkRkm0n0jqaLxXXGsDVYMZgPm\nKjO2yIgIBNNpFq1fTzA9sn56IM2rs18lsW/k3BXqFjL6DWpKikD+GrAVuRyn3TLtoG68g2GbbiP0\nSohYc6z0ewmByWfSRWC43bzBoDcL274dx0IHlnoLJpPeyXNwUBcBe7CdFr+fXrMZnniCSChALpoj\nExz/AJObMRu5rVn/XnV0wIoVmEN7oD+HEajcHRl3nWQjWazTdUtgzhy9rscxNKQHGfbuRevvZ09c\nF/vWUAhTMsn//eY3XHDBBYXpiofLlBOBXCZHsiOJc6mTgClAc3MzHo+9YAkM5UwMeyyWOJ1Esllk\npAW/zY9h1feZlc9u6/xlJxsv2Eh3Xzc7+nfwTOszpHNpvnrGV3l8x+O81v4ap9adCsANp93AnS/d\nySn9Fli0iD2376HqawsQA7of9/S601ixKchvZw0Q2Bogl85x/szzsbRYCiIghGDer+fhPVv/4pZd\nVsb020bn+TscoxI5RnH99br4F7Pw4YU0fKMB63Qr8d1x3RIIjH9KEkJQa7GwORrFp5VOrQP4akMD\nN9TV6YFgTYNEYvIiMLzOOxEBTcOraZxa1DN6WARuaW0dlbMPsC0WY5rVik/T2FGXo+oTVXjP9pbO\nSQdi2dLdFJ8dHOS5wZEHgcFMBqfRiMlgGCUCHckkNRYLqzwenh8aeTofylsCQgg+sfgTLC2bxUq3\nm78PDvJ2JMK0lT7SQpLYnSh5bMWuKd+5Ptq+3ca603U3XcgtR4lAbHus0LLDXGXGMejAb/MT2RSh\neyhBDvh70WeJ7YhBjkJvJMi7Ue2GQqqrwTZFvt7FMYExmW1HCut0q96ELZwZ7Q4qQvNqZIKZ0YOn\n8i6hio9VMPN7M2HPHhoDEbq79QaTpt4Odvh8egxrzRqS+/WHhOS+8TGd/U85Sa/bolvXRiPMm4ex\new/kJI9ixdQjsQRGuwCzkaxuCfSkCAQCVHq9aPE4nHwytLUhurtpz2RIpVLc+Z3vEHe78SWTsHOn\nbq4cAabIVTJC/2P9aD4Nc5UZn+aju7u7IALpgTT9KY2GBpBZySKr/occDG7jzvfdSU/Zg5z/wS5k\nTrL/h/sJ1gQ57WensfIXK/nQ7z/El0//MpfMvoTHdjzGhq4NnFyjD0JZWb+SeYG5zOlIMdBVh8xJ\n/FfN0i9aQNvVitNg5c/mVhodjcS25Wca7IoXRGAy1NWN5MRPhuF0Q+sM6wEtAWBSIlBpNhMYzuJx\nuSASOTRLwOOBsUHjSVBjsXCh3z8qkOzVNLZGo+xOJNgdH3FrPBMM8mpID+z7DhBAHiaRzVK7bh09\nqdS4370eDrM3kSCXN917864ggGqz3rpiKJMhlM1SZjJxeVkZf+gZuakO5mMCAHddfBcBe4A1fj9P\nBYO8HY1yUVkZr19qQvNpB33q9p3nIxvK8vzpktk2G/2uMSJQNAfDXGVmze413HHOHWz/zHb6HtOv\nw78ViWV8ZxxLvYXu+7tHzsWeBOVXlJMZzGBwGBCGI9Nb5rDxevUbYzJ5aLGEQ8A63UqqJ0Uumhud\nHVSE5tW7D2NgpCHh3LmwbRuaR8M51wznncdHxEM0N0OZOwXBIF1eb8F1mdyXxDrdWmgbXkw0VYvW\ntVufp11TA/X1iP37MFsTNFtriPtmY+3YMGqbbFiPCZjbNyM6Orjnttv0B61p02DbNoTRiMHt5uWX\nX+bBBx/EMWsWtLTAqlWFeMbhMuVEoPWWVnLRHJpPw5HzAffh7msku9dLZiBDV8xEQwO0frOV8C37\nqTeb2du3kQtmXsDHbB/m2y9czLO/fZZXGl/hq5/8Kh/q+hCdX+7koTMf4uOzPs6iikVkU1lqMjV0\n/ksnyc4kQgh+sODLaFY7bT+JM+2b0xBOp660sRg88QRDq08DAU2zmwi/GSYzlEEmJaaKg/svh7ng\nArj77kM/J7YZthFLoERMAKDGbNZF4ECFEMUMu4QOxRJ4B1YAwCcqK/lF3tQdxqtp/Lm/H00Iduef\nyAfTaf6puZl7587FbzIV6guK/a/hMaLwViTCYCbDi0VP8MO8Hg6TlrIgEL2pFGX582MQgjqLhddC\nISrNZgxC8P5AgM3RaMH8HspmCyIwzBqfj4d6e0nkcpzqcvHEhVB73eg4TCl87/Phu6qcwWkG6iwW\nusdYAvHtcWxzdIE1V5oxtZuocdYQ3RIl2hKj3mLh6WIRaIlTeXUl6b400S1687xEWwLnUicmn2mc\na+y4YjTq148+Y/GAq26MRFhX4m95MGwzbGQGM+SSuQldS5pXI7QuhH2efcRKKwoOc889sHs3NdZ+\nNm2CBf5OshUV5IxGhvLXYXJ/Evfp7pKWQCpqR2oWeOMNXQTq6mDfPsxigIuuuZGMYzqWDX8b2SAa\nxd/xML6b1rCw7wvI22/nsuXLMdTVQXm5fq6qqnC73Xzwgx/krrvuwtTQAN/4ht4F870YE0j1pojv\njIMGQy8NYUvbgTMxPXwqg7cuIT2Qpj2sUV+vV3V2/LSDv9ZWATnq3HVc++drOX/b+Xxk40e4/5z7\n+fLpX+ZDv/0QsTdjWC+x8vqM19l40UZOfv1kFicWk2pPsf+/9NGBZ4W8mGafRGJPgsDlAf0PMGzG\nPvEEVR/+JNcsu4ay5WWEXgrpPtwZExe1HEkstRbSfWmSHckDWgLbYrEDWgKjcDp1EQgGC1WgB+Qw\nREAzGArB6WG8mqYX9Pn9BUvggZ4eTnO7uSDvMrAajRiEIJ43e18cHKT8pZdoLbIc1oVCWA0GXhhz\n4+hPpxlIp1nqdNKWL87qK7IEABqtVl4JhQr1DhaDgY9VVPC/+QyP4cBwMQscDkxCsNjhoMZiYbsj\nxfR/n6APSRGmgAnvL2biNpmotVjY78gc0BJIdaVI7EmQi+VI705yttdLOJMpCFS8JY59jp3Kqyrp\n/m1+5nY+/9063Vo6cDkB6YF0wYV01AgEJvaFFvH7nh5+3d190PXGYp1uJRfPITNyYhHwaaR706Mn\nD86bB1u36u6VO+6AD3+YSm2AzZthnqedZHU1ZSYTg5kMmYEMwixwzHeUtATSwTQp3wy9fUVNjf59\nGRjAFO+gauGZJEMWLF0jAXHOPhtf6O/kbr6NDY6fwFNPk9nRBrW1+v2noQGqqmhsbOSOO+7gyiuv\n1GsF3noLbr/9kM/RREwpEeh/vB/bDBuB9wfY+x97sWQMCKqRHV4Sr/oIvRRiT79uCcR3xbFOs/La\n759jWfUycokcsddi3PGLO2i9rJVXvvIK177vWiwNFjaev5HZd8/mpBdPouJjFdz147v44U0/pOlH\nTXTe20kmnIENGwhnplN5deVIV8dAQDftXnwR+0WXcc+l91Dx0Qp6H+ol/Hr4kFxBh4Mw6ilwmf6J\nLYFai4V4Ljd5ERi2BNraIJ/+dkC83kMrEDrY22ka4WyWT1RVFSyBt6NRVo6xSoatgWA6zce3beMk\nl4t7i3KlXwmF+FRVFS8Mjm7Y9kY4zDKXi+lFvv/h9NBhGq1W1oVC1BQF0z9RVcWvu7uRUhZSRIsR\nQrDG72eJ04krL2xjrROgZGuIUP79ai0W2opEQEo5KiZgCugBzMiGCEaPEXYlKTOZOM/nK7iE4i36\nBL3ApQGCT+vLEnsSemPFmbZCcHiYoVeGaPuPtnHHBLDzhp28efqbJNsnbmfxTnjz9DeJvJ1PpwwE\nJhUP6Eil6E9P3FtpIoxeI0hA6pPnSqF59b/lKBFoatID1uecA5/5DJxzDmUGXQRm2jqJV1bSaLEw\nlMmQ2JfAWm/F0mApaQlkghlS7mm6CFRX6xZQdTVmgiQiTjIRMPfvGtlg2za2Gm7FcPnFpCvnIKNx\ner7wEEljPgOssREqK3nuuee47rrr9GULFsAXvnBofuWDMKVEoO+RPmRaUv6hcoQmSBkMODCSbnPj\n+XQ3qa4UXVGN8nI9GNf0wyZeeuklllUuI7QuhHORE82t4V3lLdzIq6+ppubzNVReWYl9tp3qT1dT\nY7ZTl7Rgm2bDd56Prl92IV9eR/fOGVR9suhpt6xMHyG4eHHhadlSayFwcYA939pzzEQA9BQ4YRET\nBvtq8y0cDlkEdu3Sc5IPRlkZhYkWRwCvpmERgov9fqLZLOFMho2RCEvG+Ix9mkYwnebm1lYuKyvj\n53Pm8IuurkLF7bpQiH+uraU5FiNUdDN+PRzmZJdrVCroWEtg2rAlUNRFdoXLhQQ2RCKFwPBY/n3a\nNG5saEAIQU2+RqOYLdEo8197bVwdRCibxW004tY0Il5Bok/fLt2bBjHipxZGQdJn4KlH9hK4OIBp\nT4qApvE+n49ngkFdNFpi2GbZcJ3sIro5SjaRJdGmWwKWBgsyPVoE9tyyh/Yft49Uthfd8OO74tjn\n2nlz5ZtkE+/cIkjlcrxcZJFFt0XpvDcv2JMVgWSSvncgAtmhrH43E7qfvRTDIjBq8JTFokeA9+2D\nb38b/H68coAdO6DW3EvU76fKbEYCkT16HGZ4EthYwv0pOsy1etOh4bYadXWYK82E3wxjqTEjIiFI\npyEaRUpJJmnBYDdgrrQQ9p1KefJpYqG8Zd7YCFVVo70Nn/885AduHSmmlAgEnwois5KyD5ThWOgg\nLDTKSSKHLNR+w42hwoy1xkymO4XRbcR3ro+dDTuZvnU6wWeDeM8d79aorXmDGUvWj154/fWFUvv6\nL9ez59ZWsk+9SLJhOY75RRdIIAC//a3uzC+i7kt1pNpTWGeW7nR4NLBO1wvOJnI/DT/NHqh9wyiG\nRWD37smJwHXXwa23TvZwD4pP0zjF7cZqNDLdamVXPM6maFSf9DZmvWAmw5MDA3y+poYFDgfTrVYe\nHxhgfyJBIpdjnt3OcpeLdaGRhm3FIlBsCZQXPfU3Wq0EM5lRloAQgksCAR7v79cDw8bxT5V1VmtB\ndKvNZjrHPPVvjkYJZbOjfPigZxu586JiLzeTzFsCw66g4b/t2mCQvZ4s1hei+M73YYxKyhMGzvZ6\neWFoiFRvCiEEpoAJo92Ifa69YA1oXg1rgxWZkWTj+s0wvCGsxw0kJFoTpINpXpnxCqm8CCX2JJj5\nvZkYHUbiLaNrDw7G77q7eXJAb8b3/OAg/5j3r+dSObLhLD2/69GL4iYpAu3vUARSnSkMdgPCJMgM\nlE4mKGkJwOg4hd+POz1ANgtVxl5CPh9eTcOjaQzu1UXAWj8+MCxzEi2Uo8+cT10cFoH6eszTPYTX\nh7HUW/Vz0NenVxaXV2B06tlnpnITHbsXYCJMuD3fn+l97xudNz72WI8QU0oEhCZo/GYjwqj73UI5\nM8td7chKOxXTLibzv6fjnm4hvnMkK2dP/R7cP3Ez8PgAvnN949/0iSfgP/9z5HV/Pzz2mB5hf/FF\n3Ke6Wf6AG1wOGn48piNoIKA/IVx44ajFrpNclH+sHNdyF8cK2wzbhPEAeIeWQHe3HhiejJvH4RiZ\nYnUEuMjv5458ifQMm41nBwfxaNo4EfNqGs2xGAOZDHPzLV0/X1PDv7W28se+Pk5z61XEZ3o8BZdQ\nKpfjlVCI5U7nKBHoG+sOKrqRF/N+v5/HBwZKuoPGUsoS2BqNUmEy8WBv76jloSJR8VdYyebnHRe7\ngiKZDP+4bRtltTYCrTkcCx0M1hsob5eFTq27tgxhm2UriIb7dDc9D/RgbbTyzy0tGN1GjHZjoZhs\n//f3U3d9HZ4zPQy9OMTAXweQKUl8R5xcMke6L42lxoKtyTZOBHof6kVmJ44v/E9HB3/q01Opm2Mx\n2hIJUrlcYTqZY6GD/sf7Jx0TeKfuoFRnCs2rYbAaSubwgx4TcK1wjSrYGkuv04ktqYtagD4Gi0Qg\nsi8/MazOQqozNeq8ZEIZhIRB4xgRuPhizGctIr5DFxAqKqC3F7q7kb7yQn8nc4WZiF+//wzudJDL\n5OCjH4WPfeyQz8WhMikREEJcKIRoFkLsEELcWOL3XxFCvCWEeFMIsUkIkRFCePO/2yOEeDv/+9cO\ntB+ZkVR+XG9eJmc4GZJmzq0RxL36DX9vuyjEA2wzbUgp6Up1MWfFHKJbo7jPcI9/07Y2ePtt2LxZ\nf/3LX8Jll8E3vwnf+hYAtq4NaGvOxLtqjCVRVqb/G57CUcSCBxbgPqXE/o4S1hnWA1ZSVpvNCA5R\nBDZu1FPRjlDRyaEwzWYrtKueYbXyp74+ljjGN3/zmUz8ZWCA093uQmfTj1dW8vGKCm7YuZPT832P\n3h8I8KuuLvbE49zc2sopLhczbTYaLZZCYLi3RGAYKMxNGOYsr5fN0SgWgwHTQc5NtdlMxxhLYGss\nxpfr63m0r49ULkck76YKZbMFS6CpzIHMQjaW1R9qmvRr/OG+PpY4nTQ2OMkJ3XXRU2fA26Z30D3L\n62XLxgFss0ZckZ7TPfQ/0o9sMHNXRweGc104ljiIt8TJRrP0/amP6mur8azyMPTSEH2P9ZG0QHBb\nRC90q7MgjEIXgZ0jIpAeSLPlii2FZbe0tnJf18hkq0gmwyuhEFuienbStliMHHqxX7o3jbnCTNWn\nqmi7o42+5HJSy1cf8FzGs1nC2Sx96fQhBbYBkp1JLFUWjC4j6YEREdkZixUsFYPJwPJXl5PYk6Dv\n0b6S73NbKISM6eLtS/fS7/Hgzde5JPLtQQwWA5pPI9U1Iv7pvKCHZYVehzP8YHX11ZgvXAGgi0B5\nOaGODmKdnaNEwD7XTvn1i+ATnyBTP4vIhggvDw2Ncq8VM/DkQGGfh8tBv/1CCAPwY+ACYAFwlRBi\nbvE6UsrvSSlPklIuA74OrJVSDkfqcsDq/O9XHGhf5kpzIbWt2+kgYxDUhMMM2fUv6759eqX3sAgM\nxAewmWzM/8/5zLhzxqgJSAXa2vQn+fvv11M+775b96t98pOwYwc8+SS8/PL4SRugR/cvuOC43CTH\nErgoQNMPJ27aZTIYWOhwUHWQzqkFXC5dHCfjCjrKTLfZeGloiMUlcsh9msbTwSBnuEcEVwjBTY2N\nPLtkCZ/OZyyd4fFwU0MDK996i991d3PvHH3i1bS8JSClHGcJ1FksGBhvCVgMBs7zeg9qBYDuhusc\nYwlsi0a5wO9ntt3Op5qbKX/5ZV4NhUZZFvMcDuJeQbo/PQ5ce6UAACAASURBVEoE/re7m6srK3FX\nW+mshoxN0F4H9jb9C3+mx0PntrDe+yaP+3Q32UiWWK1+/fd59c6a8ZY4oddChYE6nlUeBtcOMvBk\nkCfXQE9zpBBMBrDNGi0Cg38fLPStAnhpaIgdsVjh9y8MDdFks7El799ujsWwGQzsjMdJ9aQwlZuo\nuLKCyqsr6WhdxK6/HrjpXGcqRZ3FgiYEkQkKACci1ZnCvdKN+zQ3a1v7Ci66B3p6+MG+faPW7Xmg\nh51f2llSaFpsNmwh3bXmjPfS4/VS+1aGplZI7x9pGW5tsI6q1u7p0c9RLmGEBx4Y9b0aLl6z1luh\nooKHt23jyeZmsu6ywhjT+i/XM+3fpsF99+E8dwZDzw3xw/37C1bWWHbesHOUCB0Ok7m7rQBapJRt\nUso08ABw+QHWvwr4XdFrMcn9YHSP3MQ7clZkDlw9EbqMeUtgr541ldiVwDrTSke4gxpXDZZaC/X/\nWqLxmZS6CNx8sz5cdc0amDkTTj1Vb4p2773w6U/D00+PL9cFuOaad5bYfxQwOowHdT9tPOUUyiYr\nAk6nbh1NARGYYbWSAxaXsgQ0jUg2yxklahlW+3yjgrpfrKvjtmnT+L8FCwrnwWsyIdDTPXtSqVGW\ngMlg4Irycr2f0hguDgRKBoXHMtYdlM7l2JVIMNtm49rqalK5HGd5PGzNxwmGW3zMs9sZ8uhTyYYf\najqTSV4Lh7msrAxztZnuGQY6kkn2VOcwteZFwO3GsCE+yhKwTrdiqjDRV6VbSl2plH5Db9H7E3lW\n6ufOsdhBqiOFYZqZDUshvCNaSCsFxrmDBv42gLCIwgS1rbEYPUWummeCQa6qqEAA3akUzbEY5/l8\n7IzH9bnQ5SYMFgP1/1rPnJ/Nof/xfnKpiatc9wfj1JjNlOVHkh4Kqc4UljoLPR7J/27v5OH8zfPt\naJTtRcIFEHotRGJXgtjW2Lj3aTGZMMdjGMlgjfTS5XYz/dsDfPpTEdgYL4iApd5Coi3B9S0txLNZ\n2ntiRBwgYjn40If0zKA8w8Vrw5ZAqquLYHs7WWegZLtv79leBp/Tq91DmQwtN7TQuz3Mra2thXWS\nnUnM1YfXamOYydyca4FiKd2fXzYOIYQNuBB4qGixBP4mhFgvhLjmQDsqnibUuteAySIwZCT7MvoF\nX7AE8jGBzkgnNa4DDLcIBvU/xqpVsGiRPlz48cdHgivnnadbBJ2dI4N8i7FYjlqF43HH5dIHV8yc\nebyPpHATHpsZBLoIGNCzdibDNTU1nD5GMBqtVu5oa8NuNFI3xvXzwIIFJZ/4P1xezldLdVQdw1h3\n0K54nFqzGZvRyKeqq3lw4UJWeTzsjMcJFQWG59nt9Lpyem3MrgQtFRl+2tHBB8rKsBuNVHy0ghe/\nYKM9mWRHdRa5W9+H++4grt4c6TUj50MIQeDSAK1NIyJgn2Un1hIj9FII90rdijJoBtynu8lc4Ka9\nFtI7k4WMImCcOyj4dJDyj5QT3x1nIJ2mK5UaVZn9zOAg5/l8zHc4WJe3dFZ7vQURMJeP3KQstRbs\nc+wMri09e7nnDz1kZ27i/EdzlGnaQYPDY5/iU50pUuVGHs0GOT1nZ304DOiN/vYmk8TzloWUkvBr\nYQKXBuh7pG/ce3ZkMkSdTr706UG0YC99BjfmlhTP/NxHYpm1IAK2GTb2NYf4UXs7b4TD9PQkiFQY\nMCTGWxeaU8PgMIyKCaS6usjaSouAc5mTwU0RetJpQtksvX/oZcd/7OHf29roTqXIxrLkErkJp68d\nKkfaz3Ep8GKRKwhgZd5N9H7gOiHEqtKbws+6f8Y3v3kbt956G88/vxaHXz+8HRH9Im1rK3IHNdkK\nlsCEtLWNjIL7y1/0SruxX/hvfUvP651sVs17heGb6hSwBKZbrcy22ZhV4oncZzKx2OnEOdlYRwka\nrVbuam/n9/PnH9THP4zfZOLTkwiYz8y7Q/YnRp6W542xaJpsNnbG44WGdABlZjMRr6B7U5iESXLx\nvm3c29XF/8vv01JjwbBIn/ncVSeIbYiw8aKNtP/3fp6628tLudHtjOf+fC7rl0mq8u4p2ywb8e1x\nhtYN4Tndw/5Egod7e5l11yz6Pu1hfx2YWlMjvfXR3RWpXr0vf7w1TjaSpeyyMhK7E2yLxTAJQW/+\n5tybTDLtj1G005q57DH4Y18fc+x2Zuc/a6o3hanCRDKXK/jkyz5URu8fRwfLAeKtcVq+2MKe71Vw\n0gMJ3v9Ajr50mp5UigWvvcbGyPjWzV2/7GLXV0dy7pOdSf5uiVBTaWdVzsn6UIhIfprdTJuNXfki\nu2R7EpmT1F5fO04EBjMZUlIy6Hbz3Rv7EX19GLdb4VQHmZPtbP11VWE4kX2enb0bdX/9a+EwA30J\nZLWGVkIEQG8oaZ9jh/JyTH19lA8O0q95Cu6gYsxVZtLdutU6lEqT7k2TfnSQsh74r8ce45abbuE3\n1t9w+xEqGJvMN6IdaCh6XZdfVoorGe0KQkrZmf+/F3gY3b1UkuvPvoEXXriN55+/jd7e1fjr9RO0\npd9GX5/emG96eRqZkZjKTHSEO6h2HuCLOplCKJNJdw+daEwhEbAbjWw/9dSSQ2rO8Xr59+Ie2++A\n9/v93DNnTsmYw+HSYLXypfp6PrZ1K+lcjm2xGPPto1MQh0WgODAMoAVMdK8bpKMG/rhgAftOP31U\nsVytxcLGaBSqTcz/7Xxqrqth+avLOWmOf1xxHMDOeJxVHg9dKd01khnMYC43Y6408+LQEN/btw/7\nLDtdjhzCZSBpF4ReDhVEQBgFtuk24rviBJ8J4nufT+9b1ZpgazTKCperYAlsfKKbq38NruUupu2F\nR/v6mGu3Myv/WdM9ujvopaEhLt+0icF0mrIPltH3p75RWTXZRJatV26l4aYGtlxgovPfypj3fIa+\ndJqt0Sh96TRr3n6b19/o5e01bxNt1oPQ0U3RUT7xVGeKLa40DVUOvBFBayLBulCIeXY78+12duRF\nIPyaPjrUe7aXeEucZMeIFdeZSuHVNHqdTv3eYTJR+ZoBy7luPJrGUFGcwj7PTnJ7nEsDAdaHw4T6\nU9jqLJgTuktwmId7e3k1FKLx640Y7UZigQD+YJA54TD7co6SloDRaSSL5ANWH+lgBqPTSOIfvFz1\nAOycM4evXvFVvrDgC9x2220HuDInz2REYD3QJIRoFPr8xyuBR8euJITwAGcDjxQtswshnPmfHcAa\nYPNEO3ppp34xLlmiD4avWWBGWAQdQSOPP64X9YX/0lfIqZ6UJTCZatgTkWERGJ5kM0VpsFq5pMSA\noEPh87W1fOIdtryYDDc1NODVND64eTPPBoPMP4Al4C7yFdvLzMReC9NeA6e6x2ea1VgsbIxECJhM\nlF1WRtklZVhqLZzl9Y7qdgq6K2NXPM5Kt5uuVEoftDLTWnAFDWYy7M27rbpSKZa7XPQ2iFExARiJ\nC3T/ppvAJYFC36qt0Sgfec2M/039xjv0RpiOc20ELgoQCApC2Sxz7Xam22zsTSRI9qQwl5vZEo2S\nlJLf9/Zib7LjWODgzTPe1N0/iSwt17VgbbBS9691dKRSuFa4qNiaoT+eZlciwUV+P9/fUU7P+VtJ\ntCUIv6q7eeKt8VGtLlIdKV63x6mrsJMNZljkcPCrri6WOp3MttsLAe3QayHcK9wYTAZ85/sYeGqg\n8B5dqRSLHA76XC7Szc1QXs7MVzN43+fTRaCoGNE4y4Jnd5ab6ut5LRQiPpDCWWfFmoSB/HqpXI7r\nWlr4bVEbjC63m7pQiMrBQdpyDjRXaQt3wAuXZj3Qk8FUaaL/ag/ve1HwdDBIrP3IxQNgEiIgpcwC\nXwSeArYAD0gptwkhrhVCfLZo1Q8AT0opixONK4EXhRBvAa8Aj0kpn5poX0+8auLXv4Yf/hDWr4e5\nV3hAQnlA8stfwqqKEK03tzLnF3ozMiUCh4HLBZWVev6/4rAwCMGDCxaw0uPh9XCYk8ZWPZtMaEKw\nKx4fFX/wVVpx7MvimWUvpL8WU2s2szEaHen8muckp5PWRIKBIr95XzqNUQjmOxx05Z/WHfMdhdbm\ng5kMHckk6VyO7lSKU1wu9tYCRjDXjNxQbE02Ou7uINWdovwj5fw5o2fKtHZGWHRvlLOfyJHIZsls\njMFCK+ZqM44+/cl3nt2OxWCgymwm0pPEVG5iSzTKGp+vkFq65KklNNzUQMfdHbxc8TLh9WHm/FLP\n5OpIJqkpt5Oo10i+HWVXPM6CXo3GG3u55T8F7ivLCvO2E7sTZKO6CGSjWWRG8pYhxowaJ5lghlPc\nbh7q7WWJ08kcm43txZbACv0ByL3CPWpKWGcqRY1mIu71Et+6lZw7gJaUlC1xjRuJus4QI2sXnBS2\n0pdOE+1P46+3Y0pBX1I//7/r6SGVy+nWHJDqS9H5yyT1+4N4+gdoSztLWgLbYzHCfkFTxIShN4O5\n0kx/jcAekiwSNpp3D2GpOfAc5kNhUg5SKeUTUso5UspZUso788t+KqW8p2id+6SU/zBmu1Yp5dJ8\neuii4W0nYuZCreDCP/lkKLsoQPU11fhzSZ57Dmb8cTuLn1yMc6H+JZtQBIb/WEoEJmbuXL1WQnFE\nsBmNfL2xkcFVq0q6nZpsNtqSyVHuoMpqPQYye37pBn61Fgt96fQ4ETAZDJzmdvNSkTWwKx5nps02\nqoL5nm8Y2XiJfoMfzGTIAfuTSbrzlsCOmiyWeutIryx0EQg+FWT67dPJGOCKrVsZqjOSejOG8a04\ni7focQHz1iS2pU7M1WZkV5pKk6lgATXZbCTyKaLDNRO743G2x2IIo6D8g+UsfXYpK5pXcNKLJ6E5\n9XPSkUpRY7GQOsWGtj5GayjGkn/pZ9rNjTSu9LOxMkO8JY6UkvjuOLmoLj6ZoQx4jFRYLLjL9Jbz\np7hc1O+QLCmyBGROEn4jjOtkXQRcJ7sIvx4ufPbORIIPfy6ML+ghu2MHiaSbV07VM8w8+U6iwzw5\nMEB2loV4c4yTXS5MQzkqKm1kzdAfTiGl5Pv79vGDpiY2RiJ6L6oXhki8YcY72IcpOEhX0gol5kD/\nLRjEXGXG0pfD1JfFXGlmMJcl3mDioxEPm3YNHltL4FjirRuvitNunYZvMMoMY5RzH56Fc/HIF6xk\ndlBrq97C9emnlQgcCI9HbwWhOKJM1NajKR/0LnYHTavRr+Vli0pX0g5XgY8VAdDrBYo7p+6Mx2my\n2agymwuWwBPJIXam8m268zewtkSCrlSKaVYr/TOMGKePfqJ0LnfiPsNN+RXl7IrHCZhMbC5Pc8af\n0vjO81HRKenaH8OxL0P5Ql0EUp0p3jz55FEiIPsyBUtgidPJ1VVV3N3RMWpflhoLmlsXACkl7ckk\nNWYzxtOcuN9IUvmbEFavidrra7mivJwnfFHiLXrmUS6aG7EEIlnSdsEihwOT30QmmOGkDo27PwcL\nTTZm22zsyNcuGCwGzGX6DdR5kpPIxohenQuIR4bwtGSoaHFg3rGDSLuVJy4TWAyGcZbAk8EggflO\nYttirHC7CUQF9oCZrEUQDOmpvqlcjqsrK9GEoCOVItYcY+/qAAaRJmNw4kubGbSOT5n9WzBIWa0N\nrTeDpT+HqdzEUCZDerqJD4RchNsT7PUeua6vU0oEyhvG+8fM5WZmnWPj4ssF3jNHnphya/9O7bZ2\nqpxFvt5YDD74QVixAm66SW/kpERAMQUYFoFid1BVjR5Ads22l9xmuKdRWQkROMvj4fmi4PCuRIKZ\nVisBk4lQNkswnaYlHi+4jAYzGcxCsDdvCVSazfSdYyP3i9HfD89pHk568SSEQbAtFuM0t5vG2W5O\nfxEClwbomq8x+MtuuusN1LtsaB4NmZZUZkY+12k2F0Rz9DtyCKDCZOJLdXX8uquLvYkE0WyWpwYG\nRu03lM1iFAKXpuE83U31aynOuTfFzP9qKvRzesIbIdYSI74rrgdPi9xBMRssdDj0dtEDaTzPxTHm\nwNaepdJsJpXL0dsaHTUL+g1iaHUWYttiZGNZZt85SPDuWjJmD472djI2Pz0LtcLfbdgSaE8m6Ugm\naVzsIbZNP0f+qF5FnLUJgpE0GyIRzvB4EEKw2OlkYySii0CjgZTfTyrrJTAoiI9JiEvncjw3OEhj\nvZNsT5qyQRAVuggw3YJsTXFKzMr/ZHvIHmJV9URMKRGomlm6Bex377fz7V+N/qIk7/sFn9iiYdWK\n+oB87nN6x88//UmvDo5E9LxcheI402SzYQRsRRlQpnITRqdxwv73Tk3DbTQSKJEee6rbzZZYrHBj\n2hGLMdNmwyAE5SYTTweDSCgUXQ1ls8x3OGhLJOhOp6k0m6m3W9lvH99nZ9iaaY7FmGu3c+aScoxZ\n8F/oJ7jMjPhVPy0zJXUWC0IIzNVmkp1JsokswWeCXISHsAvWRyPMdzgQQlBtsfC5mhq+umsXF7z9\nNpdv3syvi1pQ3NHWVqgK9zfZySB58VxBzRJ34Vyc3RAgaRMMvTSEY6GDXCzHUwMDdA8kCFtyLHI4\nCl12+x/pQ5gF8V1xhBDMttv56fo2tvrSZHI5pJR8Yts2eudrhF8P0/6jdvbNN+Jf7SV4rv5gmTut\nFm9egIuzg54cGOB9Ph/O+Q6i26JcGggwLaGh+TSkzUAonGJbNMq8fJbYYoeDjdEoseYYzbVZshXl\nZF1lNL2ZJTqmjdGroRAzbTa8tTZS3SkqBgWZMiND2SzGJiuxlhi+PrDVWMYVwb1TppQI1M4qHSkP\nBMb3LkvvbWVhsOgJ6b774PXX4Sc/0ds83HmnnmY0BVo+KBRNNhvu/LziYax1VpatX3bAwUS1FktJ\nd5DNaORMj0f3TUvJM8EgZ+V7MVWbzfx1YAC7wVDIVBnMZFjscLApGkUTAofRSL3FUsgYKsW2vAjY\nm+xYZ1qxN9lJnmxD68iwY6YsWCjDLqHBtYNsunwT1vYMab+B7+3bx4KixIOvNTTw7OAgy1wuXl++\nnK/u2sUde/ZwfUsLf+nv57fz5wNQbjbz79+Al//ZPurcXFdbS1uNZODJARyLHGSjWa7dsYObNu2k\nz5xlUV5wTD4ToZdDlH+4vNBE71/r6pjeb2RPIMsTAwNsjEbZEY+zZ55g8O+D7Pv+Ph68xki12Yxc\nUwdA4qy6Ql1HsTvoyYEBLvD7sc+zE2uOYRACOZjF5DMhbAbC4TTbYrEREXA62RgOE2uO8XZ1BmNF\nBaK6EvugJGIf/TT/VDDI+T4f5kp9sFBZUJAqNzKYyWCdaSW+M06qM8VPz144LgvtnTKl7pAN8w48\np3UU7R3M7M37xTo64Ctfgd//fiTbZc0avSeQQjEFWOhw8JkSxWeOuQf+Is+y2Wiwlu56eUkgwJ/7\n+3lxaIhqi4WZeZdTldnMEwMDnOnxjHIHLXE69XGa+Zt3g9XK3sT4CVnDNOdvZN7zvCx5Uq+oN56i\nH29o3khb82ERiG6Kkovm6PxZJ45KCy8MDbGgqGbCo2nsPPVU/rupiQUOB48sXMhAJoMBeGLx4kIH\n2YDJxBsnQ23FaOt/lcdDX6OB4AtDOBY5yESzRLJZVmkuhiySOfl9aX69W6hruatQAf0PlZWcFbWz\nYJaXn3V28oeeHpY7nbw5I0v3b7rxrfHxVm2GKrMZT53exLKrwlNoHeI2GgllMmRyOZ4OBrnA78dS\na0EmJYm9CTKhjN7F1G4gEknr5y5/L1rkcLBnbwSDxcBOWxpLZSXGJv1aCFtGi8DTRSKQ7k7jHYRY\nwMBQJoNrtoPopijZePaAHYUPlSklAr6ayYuAubuXiv4EJBLw3HN63+1Fi0avVKIXvEJxPHBpGv/f\nO2jR8fDChZw1wQzoSwIB/tLfzx96evhIeXlh+XDV8Lk+3yhLYEl+1GZlPtbQaLVyf08PjevW4Xz+\neSpeeqlQ+TzcEG6u3Y5BMxRat/uqbPz1KiPpJSPObEu13lo5ujmK9zwv3fd3U1VjxwijLAHQhWBY\nPE7zePhBUxM/nDWL+iKhsxmN2A2GgqgNI4SgaYEXkZTY59mRGcmZDjcfswdYU19WqAbXfBr+C/1Y\nZ1pJ7BoRueT+JCfP9fPC0BC/6uriW9On80xDAs2rUX1zPbFsloDJRKBSF4HvJhL8c51uFWgGA8td\nLqrXraPGYqE27wqr+HgF+763D6PDiDAKNLuR/lCK3nSaafnPNN9uJ7M9QWSmRoXJhKGmBvMSPRYz\nZB0RgXQux4ZIhNPcbn3EaHcK94Ak6tNnUXgbrGSjWcxV5iM61nZKicCkP1g8jhaNM1Dj02eDrl8P\np5xydA9OoTgOGISY8HvRkB9u8/POTj5cVFA33En2HK+3EBMYdgcV//79fj/3z5vHs0uX0nXGGXyw\nrIxf5f307ckkTqOx4BMfpsJk4rufzVLhH7lpm6t110V0U5TGmxsxmA04Ky3cNXs2K0oUwU2GMpOp\nEEwv5tST9M/ZXyvIWAVnmlxkY1l83pG4SvWnq6n8eCW2mbaCOwgguS+Jp9HOFeXlWA0GLvL7SToM\nzGhbztA0jUqzfnOtyBcWXjhnDhcXzUB4ddky1p10Eg8WDXiv/WItnT/rLPTxMdmNtA7EWJqw0nOf\nfi6tRiOfDHnZXJPl8rIyuOUWtG/8K72XOOgtGxGB7bEY9RYLTk3DVGki1ZXCOSAJ+Q36vGuzCdtM\n2xGtEQA4cjbFsaSjg36PmXTTNNi+XY8FHMGpVwrFu4VLAwGyUjK36Im72mKhyWaj0WplIJMhkc2S\nlboPP6BpBUvAZjSypmja12dravjIli18o7GxEA8Yy3AX1uJGfOYqM4PbBok1x3Cd7KL8inIsNRau\nrTlAIedBqDabmVOql9RcJzkj/NzQz0ornGFykY1EMDpGrP7qz+iulmw0S6I1gcxJhEGQ3Ke3gv63\n6kauKC9HCMECu52tmTgOaSyIoyV/Tj4/pqmkEIKmMefEMdeB50yPPiIUMDuMZBM5Vu3U2HXzLqqu\nrkIYBef32bGu8lM/e6QpYe/dNfTlC8kA3opECoWGmlMDAdIgCFlyhVGnfU02hHZkp4u9K0UgubeV\n3Y4US09aCVu3wltvlRz8olC81/mXujouG9NWY4Hdzvv9/sJ85sH8DUQIQaPVWhCBsSxzOvFqGs8E\ng4V4wFgq8tsWu2/M1WYGXxjEXGVGc2nM+vEsvYH8YfDnRYtKBsTtc+34v9PIz3vbWWqVzMNKX2So\ndA8ehxHNp5FsT2KpsZDqSult582GwvEvdDjYHI3i1bQRYdM0ePZZhLd0Ed9Y6r9ST+cv9FnKVoeG\nNQEzYiYygxnCb4Zxn+Im1hzDf9Ho8Zre/OjUYd6KRFhaVGhorjQTyqTpSafJAVaDAVuTDZk6Mqmh\nw7wrRaB5w9PEKrzYFizR+/1XVxcGwSsUJxLlZvOoucmgz1lY7dNHrTqMRvYlk4X6hEardcLBQ0II\nrqmu5lPNzSRyOb5XIoZRUcoSqDaTbEsSuFR3nRjthx+Lm2guhsFsYOmXp3P6xjAGxyCGuCQbyWIK\nlO4CbJuZb48twBQwYTCP9oAvdDh4NRzm1VCI7xd/3nPOmfSx+tf48a/Rb/B2p4YlCXVh/RwEnw7i\nXOok8nZk9PxyGFeAtiES4caGkV6d5iozmUSOvYlEIZZS87kaJQIAuze/QO30uTBnju4Kuuqq431I\nCsWUxG8ysSseL2S5fGfGjFGDdcbymepq5tvtNFithZnGxTiMRqwGwygRsFTrPzsWHbs+VN+dOZNu\nzxay0SzZSLakJQD5hni74hhshsIsgGIWOhz8y86drHC7udDvL/EOh4bJoeGOCMoGBZYzPQSfDmKp\nteBY6ChMcBumWASklGwoYQnIWEYX8XySi31W6cLCw+FdJwJSSgZ3bubUc6/RRQBUUFihmAC/prE7\nkSiIwKwSLp5iLAZDwYoohRCCT1dVMbvIX28qN4ERHAuPnQjMdzhIuc1ko1ly0dyEIjCcIaR5tJIi\nsMDhICUl354+/Yhk3BjsBq4SZbh7wP2RclpvbiXVkaLpv8eP1iwWgbZEAqvBMMpVZ6o0ISIm9iaT\nk5py946P+ai981Egm8vyk9d/QsVQmuo5J+tD4H0+JQIKxQT4TSZ2F1kCR4L/mT0bV9H7CYPAUmfB\nufTYTuEzOowHtQTcp7rp/WMv8R3xUS0jhvGZTGw55ZRCod3hYrAZmIWVTG8a6wwrzqVODDa9bfVY\nikVgQ1FQeBj7XDuGWZaCO+ho8a6yBC753SVEUhGeMM1C1NXpYyIfeghOO+14H5pCMSUJ5C2BsTn3\nR5rl65ePGid5LDA6jORiOV0EHKVFwH++H9cyF3vv3EvjraX7iB2pylvQ4yGp9hTpHn28Zv3X6tF8\nWkkro1gE3o5GR7mCAOpvqGdTfz8Dm3qOqgi8aywBKSXP7XmOv378rzh6BqE2P+b4nHPGj4xUKBTA\n+JjA0eJYCwCAwWE4qCUAMOvHszA6jaOG5xy1Y7IbyMayhfGaZZeW4V1V2sqwGQxkpSSRzbIrHi85\nXtVd1LbiaPGuuXuGkiGMBiNOzQ5dXXAYOcgKxYmCX9PYf5R9yseLybiDQM8KWv7WsbFUjHbdOkn3\n6uM1D4QQAm++Md2eRKJQYVzM8PwJ5Q4CuiJdetvonh69F77lyFbNKRTvRQImEzmO7pPk8cJoNxbm\nChxIBAAsVcfmfmGwG0j1piDHhC6qYoZdQhOJwPDN33MUW+C8a9xBXZEuqh1VcP/9U34urkIxVRhu\nynY0byLHi8m6g44lRruRZFsSU4VpUtlGXk2jJ5WiO5UalXY7zLA7SFkC6FPE/u2BDui6Dx588Hgf\njkLxrsCfv3m8Jy0Bh5F0X3pKiYDBZiCxNzHpmgmfprExGqXGYkEr0fbepWICI3RFurh0XTvsbNMH\npCsUioMy3HrhvSoCmWAGJOMqgY8XRrsRmZKYKyYXf/BqGhsikZKuINC7lzoMBpUdBNAz1IEtntZr\nAxQKxaR4z1sCPekpYwWAHhMADhoUHuZgIgB6cFiJFXwZzgAADAZJREFUABDq3EPKZVczAhSKQ8D/\nHrYEDHYDqe7UlBKB4b5JhyICmw4iAh5NU+4ggGR3Oxn/xOXsCoViPL5jkGJ4vDA6jKS6U2juqfPZ\nhi2BQ3EHJaUs2adpmP+bP/+IFrSNZVKWgBDiQiFEsxBihxDixhK//4oQ4i0hxJtCiE1CiIwQwjuZ\nbSdLpqdLuYIUikPEZDDwl0WLcL4HLeip6A56J5YAcEBLYKHTieEIThIby0FFQAhhAH4MXAAsAK4S\nQswtXkdK+T0p5UlSymXA14G1UsrByWw7aXr70CpUQFihOFQuCgSO6DjCqYLBYUBmJAbH1PFqG2yH\nbgnAgUXgaDOZs7cCaJFStkkp08ADwOUHWP8q4HfvcNuSpLNprEMRzJW1h7qpQqF4jzJcjDWVLAFh\nEAiLOCRLQBOC2uNY/DoZEagF9hW93p9fNg4hhA24EHjoULcthZSSvlgfvbFeGtJ2DModpFAo8kxF\nEQDdJXQoIlBvsWA8jpbakY6oXAq8KKUcfCcb33bbbYWfV69eTaw2xmcf+ywPffQh6lM2FRNQKBQF\nhoOwU00EFvxxwaSb1S13ubhv7uQ95GvXrmXt2rXv8MhKMxkRaAcail7X5ZeV4kpGXEGHuu0oEaCv\nj6+99V3aw+3c88Y9XJU0KxFQKBQFpqol4Fs9+SxGs8HAmYcwy2D16tWsXr268Pr2228/lEMryWTc\nQeuBJiFEoxDCjH6jf3TsSkIID3A28MihbjsOKWHuXLa99TeuWXYN9719H+VxoURAoVAUMJgMCJOY\nciLwbuOgIiClzAJfBJ4CtgAPSCm3CSGuFUJ8tmjVDwBPSinjB9v2oEe1fz/09xPfuY3vnv9d/DY/\n/mhWiYBCoRiF0WGcVLdOxcRMKiYgpXwCmDNm2U/HvL4PuG8y2x6ULVsAWEkDXquXW86+Bf+Pvq1E\nQKFQjMLgMChL4DCZOgm2AJ//vP7/5s0AnCr1wTFfXPFFHEMxJQIKhWIURrtRicBhMrVE4Fe/gmQS\ntmyhtc7BvIRLX55KQSymD5NRKBSKPEaHEoHDZWqJQCIBr75KbvNmHp2eonYwpy/v7we/Xx8sr1Ao\nFHmUO+jwmVoicMop8OyzyK1b2HxSHeb2Tn15X59yBSkUinE0fK0B9wr38T6MdzVTSwSuvx5+/Wti\nDjNlp5wN+/LFxkoEFApFCcouK8MUmFx1rqI0U0sELr8c9u5lZ7WZpYvXQCgE8bjuDlIioFAoFEec\nqSUCLhfy5JN52RPmzOlnQ22tXjOgLAGFQqE4KkwtEQD2f+rDPH+SjxpXDdTX6y4hJQIKhUJxVJhy\nIvD4yS5s56zRXwyLwJYtUFd3fA9MoVAo3oNMORF4Zf8rnFF/hv6ivh5eegmeegquuur4HphCoVC8\nB5lyIrCxeyNLq5bqL+rr4d574Z/+CQ6h055CoVAoJseUEoF0Nk1zXzMLyhfoC+rrwWiEG244vgem\nUCgU71GmlAjs6N9BnbsOh9mhL1i5Eu67T88SUigUCsURZ0qJwMbujSypWjKywO9XsQCFQqE4ikw5\nEVhcsfh4H4ZCoVCcMEwtEejZyOJKJQIKhUJxrJhaItCtREChUCiOJVNKBIYSQzR6G4/3YSgUCsUJ\nw5QSgfnl8zGIKXVICoVC8Z5mSt1xKxwVx/sQFAqF4oRiSomAx6rGRyoUCsWxZEqJgNusJgQpFArF\nsWRKiYCyBBQKheLYMikREEJcKIRoFkLsEELcOME6q4UQbwkhNgsh/l60fI8Q4u3871470H48FiUC\nCoVCcSzRDraCEMIA/Bg4D+gA1gshHpFSNhet4wHuAtZIKduFEMUTYHLAaill8GD7UpaAQqFQHFsm\nYwmsAFqklG1SyjTwAHD5mHX+AXhIStkOIKXsK/qdmOR+cFtUTEChUCiOJZO5OdcC+4pe788vK2Y2\n4BdC/F0IsV4IcXXR7yTwt/zyaw60I+UOUigUimPLQd1Bh/A+y4BzAQewTgixTkq5E1gppewUQpSj\ni8E2KeWLpd7koZ88xHrPegBWr17N6tWrj9DhKRQKxbuftWvXsnbt2iP6nkJKeeAVhDgNuE1KeWH+\n9U2AlFJ+p2idGwGrlPL2/OufA3+VUj405r1uBcJSyh+U2I/c2LWRRZWLDvczKRQKxQmBEAIppTic\n95iMO2g90CSEaBRCmIErgUfHrPMIsEoIYRRC2IFTgW1CCLsQwpk/WAewBtg80Y5UTEChUCiOLQd1\nB0kps0KILwJPoYvGvVLKbUKIa/Vfy3uklM1CiCeBjUAWuEdKuVUIMR14WAgh8/u6X0r51ET7UtlB\nCoVCcWw5qDvoWCGEkJlsBqPBeLwPRaFQKN4VHCt30DFDCYBCoVAcW6aUCCgUCoXi2KJEQKFQKE5g\nlAgoFArFCYwSAYVCoTiBUSKgUCgUJzBKBBQKheIERomAQqFQnMAoEVAoFIoTGCUCCoVCcQKjRECh\nUChOYJQIKBQKxQmMEgGFQqE4gVEioFAoFCcwSgQUCoXiBEaJgEKhUJzAKBFQKBSKExglAgqFQnEC\no0RAoVAoTmCUCCgUCsUJjBIBhUKhOIFRIqBQKBQnMJMSASHEhUKIZiHEDiHEjROss1oI8ZYQYrMQ\n4u+Hsq1CoVAojg8HFQEhhAH4MXABsAC4Sggxd8w6HuAu4BIp5ULgisluqzjyrF279ngfwnsKdT6P\nLOp8Ti0mYwmsAFqklG1SyjTwAHD5mHX+AXhIStkOIKXsO4RtFUcY9SU7sqjzeWRR53NqMRkRqAX2\nFb3en19WzGzAL4T4uxBivRDi6kPYVqFQKBTHCe0Ivs8y4FzAAawTQqw7Qu+tUCgUiqOEkFIeeAUh\nTgNuk1JemH99EyCllN8pWudGwCqlvD3/+ufAX4H2g21b9B4HPhCFQqFQjENKKQ5n+8lYAuuBJiFE\nI9AJXAlcNWadR4AfCSGMgAU4FfgBsH0S2wKH/0EUCoVCcegcVASklFkhxBeBp9BjCPdKKbcJIa7V\nfy3vkVI2CyGeBDYCWeAeKeVWgFLbHq0Po1AoFIpD46DuIIVCoVC8dznuFcOqmOzwEULsEUK8nS/W\ney2/zCeEeEoIsV0I8WS+lkNRAiHEvUKIbiHExqJlE54/IcTXhRAtQohtQog1x+eopyYTnMtbhRD7\nhRBv5v9dWPQ7dS4PgBCiTgjxrBBiixBikxDi+vzyI3d9SimP2z90EdoJNAImYAMw93ge07vxH7Ab\n8I1Z9h3ga/mfbwTuPN7HOVX/AauApcDGg50/YD7wFrordVr++hXH+zNMlX8TnMtbgS+VWHeeOpcH\nPZ9VwNL8z070OOvcI3l9Hm9LQBWTHRkE4626y4H78j/fB3zgmB7Ruwgp5YtAcMziic7fZcADUsqM\nlHIP0IJ+HSuY8FyCfo2O5XLUuTwgUsouKeWG/M8RYBtQxxG8Po+3CKhisiODBP6WL9T7f/lllVLK\nbtAvJKDiuB3du5OKCc7f2Gu2HXXNToYvCiE2CCF+XuS6UOfyEBBCTEO3sl5h4u/3IZ/T4y0CiiPD\nSinlMuD9wHVCiDPRhaEYlQFweKjz9875H2CGlHIp0AV8/zgfz7sOIYQTeBD4l7xF8P+3c/8oDURB\nHMe/PwgptLSIhQqCB7C30cYDWIhgodgIHsET2FoLNqJFLPxTegQRLCKpVRDRHEFwLPapUVmMElzD\n+32aZB9bDMPbzGbY2b5d31UXgTtgout4LK3ZD0TEffrsAMcUf/8eJDUAJI0Cj9VFOJDK8ncHjHed\n5z37jYjoRGpYAzu8tyecyx5IqlEUgL2IOEnLfdufVReBt0E0SXWKYbLTimMaKJKG0l0CkoaBeaBF\nkcfVdNoKxUCflRMf+9Zl+TsFliTVJU0CU8D5XwU5ID7kMv1IvVoArtJ357I3u0A7Ira71vq2P/v1\n7qBfiZJBtCpjGkAN4Ci9dqMG7EfEmaQLoClpDbgBFqsM8j+TdADMAiOSbimeZtkCDj/nLyLakppA\nG3gCNrrucrNXkss5SdPAM3ANrINz2QtJM8Ay0JJ0SdH22aR4OujL9f2bnHpYzMwsY1W3g8zMrEIu\nAmZmGXMRMDPLmIuAmVnGXATMzDLmImBmljEXATOzjLkImJll7AX+WOLdXiBxFQAAAABJRU5ErkJg\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x112f13690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.87408281  0.86894992  0.88520639  0.81509912  0.80310858  0.87474134\n",
      "  0.89770608  0.83629769  0.83989451  0.83988167  0.91796576  0.83157239]\n",
      "[ 12  34  74  21  52  25  61 121 105 117 122  83]\n",
      "[[ 0.87408281  0.84198758  0.83095137  0.77289377  0.76298459  0.84347413\n",
      "   0.80929407  0.78524201  0.76351916  0.7417324   0.88074651  0.80166061]\n",
      " [ 0.82674453  0.86894992  0.8684125   0.79339043  0.77292125  0.87160892\n",
      "   0.8584579   0.81103531  0.7836935   0.79153106  0.90748786  0.82629995]\n",
      " [ 0.82593965  0.86042719  0.88520639  0.79974682  0.79037779  0.83143806\n",
      "   0.8805091   0.81751759  0.82966816  0.79325491  0.90855979  0.80361183]\n",
      " [ 0.80557427  0.86363636  0.85942889  0.81509912  0.76501505  0.83307072\n",
      "   0.84140891  0.79677429  0.78391327  0.77680246  0.89321209  0.80919564]\n",
      " [ 0.79793726  0.82494213  0.8805909   0.77356712  0.80310858  0.8361272\n",
      "   0.89060234  0.81944993  0.80918614  0.77996056  0.90482579  0.82518941]\n",
      " [ 0.80527478  0.83128157  0.85180944  0.79826546  0.77658686  0.87474134\n",
      "   0.83099008  0.80792382  0.76390008  0.77259626  0.89731522  0.79476907]\n",
      " [ 0.84821429  0.84175084  0.87230704  0.78463693  0.79503167  0.85940199\n",
      "   0.89770608  0.8188264   0.80448319  0.78644224  0.91224409  0.80508563]\n",
      " [ 0.83984726  0.81118476  0.87393978  0.7605042   0.74904092  0.81879449\n",
      "   0.82483351  0.83629769  0.77414109  0.81308611  0.91257773  0.81467566]\n",
      " [ 0.82992662  0.81876052  0.86431298  0.74954212  0.76555411  0.83506407\n",
      "   0.87879236  0.82309236  0.83989451  0.81978845  0.9066289   0.8079398 ]\n",
      " [ 0.82335654  0.79776936  0.86247526  0.7568412   0.78021652  0.84260085\n",
      "   0.8277638   0.81665946  0.81576441  0.83988167  0.91515461  0.80626881]\n",
      " [ 0.81762878  0.79703283  0.87168504  0.74932665  0.75207762  0.80770764\n",
      "   0.84152731  0.81293061  0.80744268  0.80929363  0.91796576  0.79601453]\n",
      " [ 0.81412848  0.81231587  0.87592593  0.76381707  0.78245362  0.84806834\n",
      "   0.8584579   0.81343067  0.80523039  0.81134847  0.89876338  0.83157239]]\n"
     ]
    }
   ],
   "source": [
    "print receptor_names \n",
    "print np.max(score, axis = 0) \n",
    "print np.argmax(score, axis = 0)\n",
    "print score[np.argmax(score, axis = 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.812496    0.90352349  0.87701239  0.82927506  0.77951574  0.86623892\n",
      "  0.82875972  0.83034864  0.85362316  0.79257734  0.91862656  0.85199364]\n",
      "[  7  33 258  10 175 142 260 202 261 136 267 153]\n",
      "[[ 0.812496    0.77735408  0.82427432  0.79906348  0.72928006  0.28708544\n",
      "   0.70375972  0.74571212  0.70584722  0.6955348   0.8323379   0.80524706]\n",
      " [ 0.791552    0.90352349  0.85154303  0.8039889   0.72141013  0.8434588\n",
      "   0.73861279  0.78997814  0.78622737  0.74592573  0.87690168  0.82292074]\n",
      " [ 0.783008    0.86615314  0.87701239  0.78716615  0.75803126  0.83373835\n",
      "   0.81957649  0.81829774  0.83325087  0.77618029  0.91636761  0.82950098]\n",
      " [ 0.791328    0.83709579  0.84738754  0.82927506  0.73945065  0.31395654\n",
      "   0.71495246  0.75925537  0.70681977  0.72117019  0.84715404  0.81393102]\n",
      " [ 0.7704      0.86650905  0.86449839  0.81616372  0.77951574  0.8452945\n",
      "   0.79019015  0.8147175   0.82743265  0.75772361  0.90746318  0.84103474]\n",
      " [ 0.763456    0.87594061  0.86638601  0.82015262  0.76611161  0.86623892\n",
      "   0.79794728  0.81798246  0.81468716  0.78117939  0.90588673  0.84504648]\n",
      " [ 0.776752    0.87108501  0.87010694  0.79906348  0.76705151  0.84487491\n",
      "   0.82875972  0.81029651  0.83765292  0.7816593   0.91627148  0.82443738]\n",
      " [ 0.77768     0.87922005  0.87230691  0.79559487  0.76103333  0.8451896\n",
      "   0.80149092  0.83034864  0.82925831  0.7750005   0.91044948  0.84294276]\n",
      " [ 0.770624    0.86882245  0.87509761  0.79694762  0.76063352  0.83830137\n",
      "   0.81782627  0.8272098   0.85362316  0.76770181  0.91702447  0.84088796]\n",
      " [ 0.771472    0.88140635  0.86760143  0.8062435   0.7631937   0.85195545\n",
      "   0.7877917   0.81117931  0.82565818  0.79257734  0.9063994   0.83671722]\n",
      " [ 0.755216    0.86559386  0.87140384  0.79105099  0.75526766  0.83193762\n",
      "   0.82694468  0.81961493  0.83715812  0.79115759  0.91862656  0.83033268]\n",
      " [ 0.785152    0.88613484  0.86641317  0.81706556  0.7761349   0.8634067\n",
      "   0.78189283  0.82732891  0.81564265  0.7849787   0.91071863  0.85199364]]\n"
     ]
    }
   ],
   "source": [
    "print receptor_names \n",
    "print np.max(score, axis = 0) \n",
    "print np.argmax(score, axis = 0)\n",
    "print score[np.argmax(score, axis = 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.83248618  0.91438457  0.89488128  0.8378541   0.83491072  0.80198413\n",
      "  0.86353189  0.82380641  0.84657375  0.81664925  0.88643991  0.84362099]\n",
      "[188  46 253  24 141  70 384 423 236 255 361 416]\n",
      "[[ 0.83248618  0.89326906  0.87784599  0.80632724  0.8250924   0.77065581\n",
      "   0.7860671   0.80418096  0.82450639  0.79615577  0.87225372  0.83205017]\n",
      " [ 0.77309613  0.91438457  0.88256221  0.81081155  0.79719923  0.78617377\n",
      "   0.76970853  0.78768577  0.75946574  0.75978855  0.84751248  0.78671532]\n",
      " [ 0.79133226  0.88200154  0.89488128  0.79812425  0.83264095  0.75367586\n",
      "   0.82387031  0.81119685  0.83456114  0.811151    0.87981217  0.82910446]\n",
      " [ 0.75994293  0.88123263  0.87893018  0.8378541   0.78325785  0.75983709\n",
      "   0.72241784  0.75679133  0.69221835  0.72978295  0.8161576   0.7767624 ]\n",
      " [ 0.82633315  0.89255929  0.88504906  0.80807722  0.83491072  0.76167502\n",
      "   0.77719092  0.79548424  0.81465074  0.78609836  0.86180444  0.83115753]\n",
      " [ 0.79717318  0.90291004  0.87740554  0.82811987  0.80451872  0.80198413\n",
      "   0.79244914  0.79777751  0.77791604  0.77064873  0.85942127  0.79814108]\n",
      " [ 0.78872392  0.89737978  0.88092915  0.8044679   0.80723619  0.75365497\n",
      "   0.86353189  0.82203032  0.82814004  0.7983066   0.88125053  0.83997233]\n",
      " [ 0.79351703  0.8934465   0.87829999  0.81628021  0.79887553  0.74903926\n",
      "   0.85538928  0.82380641  0.83439522  0.77414762  0.87647714  0.83637946]\n",
      " [ 0.81124041  0.88250429  0.89393262  0.80252652  0.82856994  0.77767335\n",
      "   0.81264671  0.80605912  0.84657375  0.80156314  0.87881095  0.81951976]\n",
      " [ 0.81618958  0.90282132  0.89000922  0.79905392  0.83175595  0.76125731\n",
      "   0.82866295  0.81877076  0.83484321  0.81664925  0.87865584  0.82680592]\n",
      " [ 0.79552345  0.89590111  0.8828468   0.7867631   0.81957416  0.75342523\n",
      "   0.86062207  0.813599    0.80988883  0.78450796  0.88643991  0.83752873]\n",
      " [ 0.79944712  0.90178624  0.87914702  0.81420212  0.80692384  0.76779449\n",
      "   0.85859253  0.82139066  0.83052928  0.76145469  0.87898722  0.84362099]]\n"
     ]
    }
   ],
   "source": [
    "print receptor_names \n",
    "print np.max(score, axis = 0) \n",
    "print np.argmax(score, axis = 0)\n",
    "print score[np.argmax(score, axis = 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11cbdce10>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9050>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9190>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe92d0>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9410>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9550>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9690>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe97d0>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9910>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9a50>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9b90>,\n",
       " <matplotlib.lines.Line2D at 0x11cbe9cd0>]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDGWc/wNTzY+QDFS1WQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ca9ca10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.84020392  0.91132507  0.92049571  0.79837499  0.83260163  0.91104031\n",
      "  0.772954    0.79677248  0.86777334  0.77410305  0.89375838  0.81808132]\n",
      "[ 13 306 794 521 571 412 667 340 547 270 493 322]\n",
      "[[ 0.84020392  0.76106633  0.81766518  0.75863287  0.78895122  0.84666568\n",
      "   0.66033898  0.72027521  0.6952913   0.65621872  0.78527755  0.74183147]\n",
      " [ 0.80269394  0.91132507  0.90631371  0.75607171  0.82012195  0.88719621\n",
      "   0.6825908   0.76944863  0.84237829  0.75755922  0.88576026  0.81413012]\n",
      " [ 0.81025946  0.89516112  0.92049571  0.76971651  0.82825203  0.88947836\n",
      "   0.75757869  0.77387017  0.83653631  0.74551148  0.88906543  0.80258363]\n",
      " [ 0.80909491  0.8982331   0.90820562  0.79837499  0.82460976  0.88752223\n",
      "   0.73716707  0.78235326  0.83827614  0.73381251  0.88236122  0.79349384]\n",
      " [ 0.80881802  0.90114014  0.91421134  0.77923254  0.83260163  0.90512745\n",
      "   0.73455206  0.77177826  0.83956903  0.71816335  0.88622955  0.79474266]\n",
      " [ 0.77621056  0.88571841  0.88034758  0.75620419  0.82357724  0.91104031\n",
      "   0.69377724  0.73379111  0.83032721  0.73223547  0.85832663  0.78232609]\n",
      " [ 0.81205922  0.89231594  0.90852094  0.77887927  0.81395935  0.88934499\n",
      "   0.772954    0.76265672  0.84383081  0.72841416  0.88199249  0.78658437]\n",
      " [ 0.76401127  0.89056347  0.90173792  0.76488122  0.81941463  0.88749259\n",
      "   0.66239709  0.79677248  0.81296089  0.74956783  0.87935774  0.79281825]\n",
      " [ 0.79459908  0.90076902  0.9015106   0.76446172  0.83026016  0.8909751\n",
      "   0.75702179  0.75701265  0.86777334  0.72718588  0.88636364  0.80220489]\n",
      " [ 0.78764435  0.90114014  0.89793943  0.76379935  0.82374797  0.88651452\n",
      "   0.64946731  0.76911583  0.84065443  0.77410305  0.88645079  0.80736396]\n",
      " [ 0.78829585  0.89594458  0.90870426  0.7808443   0.81702439  0.89673977\n",
      "   0.71302663  0.77491612  0.84110136  0.73751251  0.89375838  0.80702616]\n",
      " [ 0.78106422  0.90703668  0.90511109  0.76148106  0.81545528  0.88768524\n",
      "   0.68038741  0.75378649  0.8290822   0.75778667  0.8885291   0.81808132]]\n"
     ]
    }
   ],
   "source": [
    "print receptor_names \n",
    "print np.max(score, axis = 0) \n",
    "print np.argmax(score, axis = 0)\n",
    "print score[np.argmax(score, axis = 0), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.94488189  0.94301471  0.88786092  0.87510201  0.82027235  0.86705139\n",
      "  0.81548807  0.81359438  0.85547326  0.80131602  0.9261809   0.83023406]\n",
      "[ 81 198 152  94  70 113 167  75 165  59 197  80]\n",
      "[[ 0.94488189  0.90463936  0.87860217  0.85357726  0.81596488  0.84347348\n",
      "   0.79141717  0.80685975  0.82107947  0.76084848  0.90350757  0.81772391]\n",
      " [ 0.9265555   0.94301471  0.87788244  0.81974293  0.78055287  0.83862325\n",
      "   0.79260527  0.79311081  0.82387226  0.73703896  0.91953189  0.80058799]\n",
      " [ 0.8941794   0.91542367  0.88786092  0.82276931  0.78748262  0.84807639\n",
      "   0.78956373  0.79253671  0.83402647  0.71335065  0.92321271  0.80822566]\n",
      " [ 0.93546395  0.91931022  0.88095005  0.87510201  0.80122121  0.85346249\n",
      "   0.78875582  0.80033857  0.82865339  0.75277922  0.90778987  0.81290283]\n",
      " [ 0.93061603  0.89466036  0.88084524  0.85017682  0.82027235  0.85026106\n",
      "   0.77575801  0.80384205  0.81818044  0.76337662  0.90233075  0.81471202]\n",
      " [ 0.91607226  0.92491246  0.88395478  0.83735718  0.80818874  0.86705139\n",
      "   0.79022907  0.79508335  0.84002186  0.75270996  0.91285672  0.8204891 ]\n",
      " [ 0.93226803  0.92757353  0.88084524  0.8171586   0.77772656  0.80467161\n",
      "   0.81548807  0.78460972  0.83117297  0.72836364  0.91884541  0.81238885]\n",
      " [ 0.93711595  0.91906513  0.88018839  0.85823585  0.81409074  0.84721077\n",
      "   0.80303678  0.81359438  0.82780341  0.78091775  0.90061783  0.81690155]\n",
      " [ 0.9274973   0.92757353  0.8798949   0.80219668  0.77617738  0.83946139\n",
      "   0.80919114  0.78887131  0.85547326  0.7404329   0.92105521  0.81183376]\n",
      " [ 0.91310792  0.90493697  0.88233362  0.83388874  0.79531165  0.81575982\n",
      "   0.78690239  0.79972031  0.81305021  0.80131602  0.88738518  0.82022183]\n",
      " [ 0.92212444  0.92037815  0.88094306  0.82137514  0.7744166   0.80300907\n",
      "   0.79291417  0.78221764  0.82396333  0.72375758  0.9261809   0.80374379]\n",
      " [ 0.94197931  0.92279412  0.88143221  0.86830114  0.8057025   0.85127782\n",
      "   0.79621709  0.80504177  0.82812215  0.77539394  0.90573044  0.83023406]]\n"
     ]
    }
   ],
   "source": [
    "print receptor_names \n",
    "print np.max(score, axis = 0) \n",
    "print np.argmax(score, axis = 0)\n",
    "print score[np.argmax(score, axis = 0), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_pred = nn_pred(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10565061  0.09092465  0.08561691  0.05906787  0.19737617  0.12739871\n",
      "  0.08851941  0.04361931  0.10755444  0.06461294  0.05143892  0.06365821]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print Y_pred[99,:]\n",
    "print Y_test[99,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NR-AR 0.540094339623\n",
      "NR-AR-LBD 0.651261373036\n",
      "NR-AhR 0.833827286663\n",
      "NR-Aromatase 0.727867080913\n",
      "NR-ER 0.67086391869\n",
      "NR-ER-LBD 0.711547619048\n",
      "NR-PPAR-gamma 0.583305274972\n",
      "SR-ARE 0.693584993052\n",
      "SR-ATAD5 0.607583224379\n",
      "SR-HSE 0.716351118761\n",
      "SR-MMP 0.827189048855\n",
      "SR-p53 0.566038602941\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABrQAAAFwCAYAAAD5dptnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f8e2f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(30, 6))\n",
    "for i in range(Y_test.shape[1]):\n",
    "    ind = np.where(Y_test[:, i] != 999)\n",
    "    fpr, tpr, _ = roc_curve(Y_test[ind, i][0], Y_pred[ind, i][0])\n",
    "    print receptor_names[i], roc_auc_score(Y_test[ind, i][0], Y_pred[ind, i][0])\n",
    "    #ax[i].plot(fpr, tpr, lw=2, label='NN')\n",
    "    #ax[i].legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t5.247316\n",
      "  validation loss:\t\t4.38\n",
      "Epoch 2 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t4.797203\n",
      "  validation loss:\t\t4.15\n",
      "Epoch 3 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.566295\n",
      "  validation loss:\t\t4.03\n",
      "Epoch 4 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t4.425128\n",
      "  validation loss:\t\t3.93\n",
      "Epoch 5 of 220 took 0.096s\n",
      "  training loss (in-iteration):\t\t4.335952\n",
      "  validation loss:\t\t3.87\n",
      "Epoch 6 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t4.243492\n",
      "  validation loss:\t\t3.77\n",
      "Epoch 7 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t4.143920\n",
      "  validation loss:\t\t3.69\n",
      "Epoch 8 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t4.066857\n",
      "  validation loss:\t\t3.64\n",
      "Epoch 9 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.972731\n",
      "  validation loss:\t\t3.56\n",
      "Epoch 10 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t3.899562\n",
      "  validation loss:\t\t3.50\n",
      "Epoch 11 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t3.840069\n",
      "  validation loss:\t\t3.45\n",
      "Epoch 12 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.753952\n",
      "  validation loss:\t\t3.37\n",
      "Epoch 13 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.683001\n",
      "  validation loss:\t\t3.30\n",
      "Epoch 14 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.624446\n",
      "  validation loss:\t\t3.26\n",
      "Epoch 15 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.550675\n",
      "  validation loss:\t\t3.19\n",
      "Epoch 16 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.488060\n",
      "  validation loss:\t\t3.16\n",
      "Epoch 17 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.432830\n",
      "  validation loss:\t\t3.09\n",
      "Epoch 18 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.363999\n",
      "  validation loss:\t\t3.06\n",
      "Epoch 19 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.310482\n",
      "  validation loss:\t\t3.00\n",
      "Epoch 20 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.254552\n",
      "  validation loss:\t\t2.93\n",
      "Epoch 21 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.194190\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 22 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.151970\n",
      "  validation loss:\t\t2.87\n",
      "Epoch 23 of 220 took 0.095s\n",
      "  training loss (in-iteration):\t\t3.101574\n",
      "  validation loss:\t\t2.81\n",
      "Epoch 24 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t3.053418\n",
      "  validation loss:\t\t2.76\n",
      "Epoch 25 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.000906\n",
      "  validation loss:\t\t2.72\n",
      "Epoch 26 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.961238\n",
      "  validation loss:\t\t2.68\n",
      "Epoch 27 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.905465\n",
      "  validation loss:\t\t2.65\n",
      "Epoch 28 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.866787\n",
      "  validation loss:\t\t2.59\n",
      "Epoch 29 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.825436\n",
      "  validation loss:\t\t2.57\n",
      "Epoch 30 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.788285\n",
      "  validation loss:\t\t2.52\n",
      "Epoch 31 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.730384\n",
      "  validation loss:\t\t2.49\n",
      "Epoch 32 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.695710\n",
      "  validation loss:\t\t2.45\n",
      "Epoch 33 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.655799\n",
      "  validation loss:\t\t2.42\n",
      "Epoch 34 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.617196\n",
      "  validation loss:\t\t2.40\n",
      "Epoch 35 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.583966\n",
      "  validation loss:\t\t2.34\n",
      "Epoch 36 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.546536\n",
      "  validation loss:\t\t2.32\n",
      "Epoch 37 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.511796\n",
      "  validation loss:\t\t2.28\n",
      "Epoch 38 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.474932\n",
      "  validation loss:\t\t2.26\n",
      "Epoch 39 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.448341\n",
      "  validation loss:\t\t2.23\n",
      "Epoch 40 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.411361\n",
      "  validation loss:\t\t2.21\n",
      "Epoch 41 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t2.389726\n",
      "  validation loss:\t\t2.17\n",
      "Epoch 42 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.357825\n",
      "  validation loss:\t\t2.15\n",
      "Epoch 43 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.315170\n",
      "  validation loss:\t\t2.13\n",
      "Epoch 44 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.292597\n",
      "  validation loss:\t\t2.11\n",
      "Epoch 45 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.261204\n",
      "  validation loss:\t\t2.07\n",
      "Epoch 46 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.243325\n",
      "  validation loss:\t\t2.05\n",
      "Epoch 47 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.210409\n",
      "  validation loss:\t\t2.03\n",
      "Epoch 48 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.187075\n",
      "  validation loss:\t\t2.00\n",
      "Epoch 49 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.158079\n",
      "  validation loss:\t\t1.99\n",
      "Epoch 50 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.130696\n",
      "  validation loss:\t\t1.95\n",
      "Epoch 51 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.113718\n",
      "  validation loss:\t\t1.93\n",
      "Epoch 52 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.087189\n",
      "  validation loss:\t\t1.92\n",
      "Epoch 53 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.061956\n",
      "  validation loss:\t\t1.92\n",
      "Epoch 54 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.035233\n",
      "  validation loss:\t\t1.90\n",
      "Epoch 55 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.014819\n",
      "  validation loss:\t\t1.88\n",
      "Epoch 56 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.999906\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 57 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.976699\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 58 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.960245\n",
      "  validation loss:\t\t1.81\n",
      "Epoch 59 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.938821\n",
      "  validation loss:\t\t1.79\n",
      "Epoch 60 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.919416\n",
      "  validation loss:\t\t1.78\n",
      "Epoch 61 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.901603\n",
      "  validation loss:\t\t1.75\n",
      "Epoch 62 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.881196\n",
      "  validation loss:\t\t1.75\n",
      "Epoch 63 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.858062\n",
      "  validation loss:\t\t1.73\n",
      "Epoch 64 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.846503\n",
      "  validation loss:\t\t1.71\n",
      "Epoch 65 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.817049\n",
      "  validation loss:\t\t1.70\n",
      "Epoch 66 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.808877\n",
      "  validation loss:\t\t1.71\n",
      "Epoch 67 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.796482\n",
      "  validation loss:\t\t1.67\n",
      "Epoch 68 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.783439\n",
      "  validation loss:\t\t1.66\n",
      "Epoch 69 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.752916\n",
      "  validation loss:\t\t1.63\n",
      "Epoch 70 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.751738\n",
      "  validation loss:\t\t1.64\n",
      "Epoch 71 of 220 took 0.096s\n",
      "  training loss (in-iteration):\t\t1.735943\n",
      "  validation loss:\t\t1.61\n",
      "Epoch 72 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.710085\n",
      "  validation loss:\t\t1.61\n",
      "Epoch 73 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.707579\n",
      "  validation loss:\t\t1.59\n",
      "Epoch 74 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.683892\n",
      "  validation loss:\t\t1.60\n",
      "Epoch 75 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.684947\n",
      "  validation loss:\t\t1.57\n",
      "Epoch 76 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.656157\n",
      "  validation loss:\t\t1.55\n",
      "Epoch 77 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.641873\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 78 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.638274\n",
      "  validation loss:\t\t1.55\n",
      "Epoch 79 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.620204\n",
      "  validation loss:\t\t1.53\n",
      "Epoch 80 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.611027\n",
      "  validation loss:\t\t1.51\n",
      "Epoch 81 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.592381\n",
      "  validation loss:\t\t1.50\n",
      "Epoch 82 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.596656\n",
      "  validation loss:\t\t1.50\n",
      "Epoch 83 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.573460\n",
      "  validation loss:\t\t1.48\n",
      "Epoch 84 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.559309\n",
      "  validation loss:\t\t1.48\n",
      "Epoch 85 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.553764\n",
      "  validation loss:\t\t1.45\n",
      "Epoch 86 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.534398\n",
      "  validation loss:\t\t1.46\n",
      "Epoch 87 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.529893\n",
      "  validation loss:\t\t1.48\n",
      "Epoch 88 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.516549\n",
      "  validation loss:\t\t1.45\n",
      "Epoch 89 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.515933\n",
      "  validation loss:\t\t1.43\n",
      "Epoch 90 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.498800\n",
      "  validation loss:\t\t1.45\n",
      "Epoch 91 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.503978\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 92 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.480201\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 93 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.472206\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 94 of 220 took 0.090s\n",
      "  training loss (in-iteration):\t\t1.477384\n",
      "  validation loss:\t\t1.39\n",
      "Epoch 95 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.463471\n",
      "  validation loss:\t\t1.39\n",
      "Epoch 96 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.444949\n",
      "  validation loss:\t\t1.42\n",
      "Epoch 97 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.446468\n",
      "  validation loss:\t\t1.38\n",
      "Epoch 98 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.443626\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 99 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.429197\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 100 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.419516\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 101 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.411175\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 102 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.401023\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 103 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.397515\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 104 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.391049\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 105 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.377664\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 106 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.365785\n",
      "  validation loss:\t\t1.34\n",
      "Epoch 107 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.373227\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 108 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.371964\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 109 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.353252\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 110 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.351757\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 111 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.340054\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 112 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.346800\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 113 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.346122\n",
      "  validation loss:\t\t1.30\n",
      "Epoch 114 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.328998\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 115 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.333303\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 116 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.310509\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 117 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.312396\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 118 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.303404\n",
      "  validation loss:\t\t1.28\n",
      "Epoch 119 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.298964\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 120 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.308841\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 121 of 220 took 0.089s\n",
      "  training loss (in-iteration):\t\t1.295879\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 122 of 220 took 0.095s\n",
      "  training loss (in-iteration):\t\t1.289322\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 123 of 220 took 0.095s\n",
      "  training loss (in-iteration):\t\t1.277598\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 124 of 220 took 0.093s\n",
      "  training loss (in-iteration):\t\t1.282345\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 125 of 220 took 0.097s\n",
      "  training loss (in-iteration):\t\t1.269852\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 126 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.266350\n",
      "  validation loss:\t\t1.28\n",
      "Epoch 127 of 220 took 0.105s\n",
      "  training loss (in-iteration):\t\t1.273279\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 128 of 220 took 0.099s\n",
      "  training loss (in-iteration):\t\t1.258810\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 129 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.251936\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 130 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.260443\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 131 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.250275\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 132 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.254116\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 133 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t1.249643\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 134 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.238217\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 135 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.242539\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 136 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.231998\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 137 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t1.223104\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 138 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.234146\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 139 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.213068\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 140 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.222329\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 141 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.225980\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 142 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.213218\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 143 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.207778\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 144 of 220 took 0.104s\n",
      "  training loss (in-iteration):\t\t1.208537\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 145 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.215995\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 146 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.207130\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 147 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.204765\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 148 of 220 took 0.092s\n",
      "  training loss (in-iteration):\t\t1.202111\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 149 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t1.203379\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 150 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.182687\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 151 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.199068\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 152 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.186291\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 153 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.195101\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 154 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.173695\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 155 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t1.184914\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 156 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.170202\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 157 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.175624\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 158 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.177828\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 159 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.171363\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 160 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.175380\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 161 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.161879\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 162 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.159807\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 163 of 220 took 0.099s\n",
      "  training loss (in-iteration):\t\t1.168275\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 164 of 220 took 0.101s\n",
      "  training loss (in-iteration):\t\t1.175773\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 165 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.169798\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 166 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.171284\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 167 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.152783\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 168 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.155963\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 169 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.174183\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 170 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.141100\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 171 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.162297\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 172 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.167303\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 173 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.168418\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 174 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.139156\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 175 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.152509\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 176 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.135223\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 177 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.149918\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 178 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.154276\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 179 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.129798\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 180 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.134540\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 181 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.147915\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 182 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.142811\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 183 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.134331\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 184 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.132309\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 185 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.133301\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 186 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.131675\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 187 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.141849\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 188 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.126016\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 189 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.127301\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 190 of 220 took 0.096s\n",
      "  training loss (in-iteration):\t\t1.132786\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 191 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.117855\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 192 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.152686\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 193 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.124601\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 194 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.127858\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 195 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.128907\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 196 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.126344\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 197 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.129762\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 198 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.124577\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 199 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.109592\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 200 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.123439\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 201 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.108719\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 202 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.100516\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 203 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.128212\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 204 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.105088\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 205 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.107512\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 206 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.109864\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 207 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.122769\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 208 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.108410\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 209 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.103160\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 210 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.110825\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 211 of 220 took 0.090s\n",
      "  training loss (in-iteration):\t\t1.104182\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 212 of 220 took 0.117s\n",
      "  training loss (in-iteration):\t\t1.116868\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 213 of 220 took 0.119s\n",
      "  training loss (in-iteration):\t\t1.108609\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 214 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.112390\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 215 of 220 took 0.116s\n",
      "  training loss (in-iteration):\t\t1.115003\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 216 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.124643\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 217 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.089442\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 218 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.111388\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 219 of 220 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.101866\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 220 of 220 took 0.089s\n",
      "  training loss (in-iteration):\t\t1.105728\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 1 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t5.163880\n",
      "  validation loss:\t\t4.25\n",
      "Epoch 2 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t4.765245\n",
      "  validation loss:\t\t4.04\n",
      "Epoch 3 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.586627\n",
      "  validation loss:\t\t3.93\n",
      "Epoch 4 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t4.471416\n",
      "  validation loss:\t\t3.82\n",
      "Epoch 5 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t4.352282\n",
      "  validation loss:\t\t3.73\n",
      "Epoch 6 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t4.265735\n",
      "  validation loss:\t\t3.67\n",
      "Epoch 7 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t4.176863\n",
      "  validation loss:\t\t3.59\n",
      "Epoch 8 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t4.079775\n",
      "  validation loss:\t\t3.50\n",
      "Epoch 9 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t4.000724\n",
      "  validation loss:\t\t3.42\n",
      "Epoch 10 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.951704\n",
      "  validation loss:\t\t3.36\n",
      "Epoch 11 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.852882\n",
      "  validation loss:\t\t3.32\n",
      "Epoch 12 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.775694\n",
      "  validation loss:\t\t3.25\n",
      "Epoch 13 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.716005\n",
      "  validation loss:\t\t3.19\n",
      "Epoch 14 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t3.647178\n",
      "  validation loss:\t\t3.12\n",
      "Epoch 15 of 220 took 0.103s\n",
      "  training loss (in-iteration):\t\t3.583473\n",
      "  validation loss:\t\t3.07\n",
      "Epoch 16 of 220 took 0.097s\n",
      "  training loss (in-iteration):\t\t3.514604\n",
      "  validation loss:\t\t3.02\n",
      "Epoch 17 of 220 took 0.090s\n",
      "  training loss (in-iteration):\t\t3.455163\n",
      "  validation loss:\t\t2.96\n",
      "Epoch 18 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t3.397937\n",
      "  validation loss:\t\t2.91\n",
      "Epoch 19 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t3.346019\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 20 of 220 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.275174\n",
      "  validation loss:\t\t2.82\n",
      "Epoch 21 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.231247\n",
      "  validation loss:\t\t2.79\n",
      "Epoch 22 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.172333\n",
      "  validation loss:\t\t2.73\n",
      "Epoch 23 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.126319\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 24 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.073819\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 25 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t3.033353\n",
      "  validation loss:\t\t2.59\n",
      "Epoch 26 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.979323\n",
      "  validation loss:\t\t2.56\n",
      "Epoch 27 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.935213\n",
      "  validation loss:\t\t2.53\n",
      "Epoch 28 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.880800\n",
      "  validation loss:\t\t2.48\n",
      "Epoch 29 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.843188\n",
      "  validation loss:\t\t2.44\n",
      "Epoch 30 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.799912\n",
      "  validation loss:\t\t2.40\n",
      "Epoch 31 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.764575\n",
      "  validation loss:\t\t2.37\n",
      "Epoch 32 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.719643\n",
      "  validation loss:\t\t2.34\n",
      "Epoch 33 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.677373\n",
      "  validation loss:\t\t2.33\n",
      "Epoch 34 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t2.648964\n",
      "  validation loss:\t\t2.27\n",
      "Epoch 35 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.612676\n",
      "  validation loss:\t\t2.24\n",
      "Epoch 36 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.576763\n",
      "  validation loss:\t\t2.21\n",
      "Epoch 37 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t2.539338\n",
      "  validation loss:\t\t2.20\n",
      "Epoch 38 of 220 took 0.089s\n",
      "  training loss (in-iteration):\t\t2.502923\n",
      "  validation loss:\t\t2.15\n",
      "Epoch 39 of 220 took 0.095s\n",
      "  training loss (in-iteration):\t\t2.475261\n",
      "  validation loss:\t\t2.12\n",
      "Epoch 40 of 220 took 0.102s\n",
      "  training loss (in-iteration):\t\t2.435913\n",
      "  validation loss:\t\t2.09\n",
      "Epoch 41 of 220 took 0.123s\n",
      "  training loss (in-iteration):\t\t2.408150\n",
      "  validation loss:\t\t2.07\n",
      "Epoch 42 of 220 took 0.126s\n",
      "  training loss (in-iteration):\t\t2.371706\n",
      "  validation loss:\t\t2.04\n",
      "Epoch 43 of 220 took 0.095s\n",
      "  training loss (in-iteration):\t\t2.347656\n",
      "  validation loss:\t\t2.01\n",
      "Epoch 44 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.324196\n",
      "  validation loss:\t\t2.01\n",
      "Epoch 45 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t2.287632\n",
      "  validation loss:\t\t1.97\n",
      "Epoch 46 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.261051\n",
      "  validation loss:\t\t1.95\n",
      "Epoch 47 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.229432\n",
      "  validation loss:\t\t1.93\n",
      "Epoch 48 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.214076\n",
      "  validation loss:\t\t1.90\n",
      "Epoch 49 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.177896\n",
      "  validation loss:\t\t1.88\n",
      "Epoch 50 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.149751\n",
      "  validation loss:\t\t1.87\n",
      "Epoch 51 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t2.131921\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 52 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.114387\n",
      "  validation loss:\t\t1.83\n",
      "Epoch 53 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.089538\n",
      "  validation loss:\t\t1.80\n",
      "Epoch 54 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.065591\n",
      "  validation loss:\t\t1.77\n",
      "Epoch 55 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.036008\n",
      "  validation loss:\t\t1.76\n",
      "Epoch 56 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.013417\n",
      "  validation loss:\t\t1.75\n",
      "Epoch 57 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.996759\n",
      "  validation loss:\t\t1.74\n",
      "Epoch 58 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.976540\n",
      "  validation loss:\t\t1.71\n",
      "Epoch 59 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.952792\n",
      "  validation loss:\t\t1.70\n",
      "Epoch 60 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.940951\n",
      "  validation loss:\t\t1.67\n",
      "Epoch 61 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.913742\n",
      "  validation loss:\t\t1.66\n",
      "Epoch 62 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.895800\n",
      "  validation loss:\t\t1.64\n",
      "Epoch 63 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.875865\n",
      "  validation loss:\t\t1.63\n",
      "Epoch 64 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.869553\n",
      "  validation loss:\t\t1.61\n",
      "Epoch 65 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.846378\n",
      "  validation loss:\t\t1.60\n",
      "Epoch 66 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.840164\n",
      "  validation loss:\t\t1.59\n",
      "Epoch 67 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.812719\n",
      "  validation loss:\t\t1.57\n",
      "Epoch 68 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.801277\n",
      "  validation loss:\t\t1.55\n",
      "Epoch 69 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.788315\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 70 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.765153\n",
      "  validation loss:\t\t1.53\n",
      "Epoch 71 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.756441\n",
      "  validation loss:\t\t1.52\n",
      "Epoch 72 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.740578\n",
      "  validation loss:\t\t1.51\n",
      "Epoch 73 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.720554\n",
      "  validation loss:\t\t1.50\n",
      "Epoch 74 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.709377\n",
      "  validation loss:\t\t1.48\n",
      "Epoch 75 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.694575\n",
      "  validation loss:\t\t1.47\n",
      "Epoch 76 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.683347\n",
      "  validation loss:\t\t1.46\n",
      "Epoch 77 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.667699\n",
      "  validation loss:\t\t1.45\n",
      "Epoch 78 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.650811\n",
      "  validation loss:\t\t1.43\n",
      "Epoch 79 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.641452\n",
      "  validation loss:\t\t1.44\n",
      "Epoch 80 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.631597\n",
      "  validation loss:\t\t1.42\n",
      "Epoch 81 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.615933\n",
      "  validation loss:\t\t1.40\n",
      "Epoch 82 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.602936\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 83 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.592032\n",
      "  validation loss:\t\t1.39\n",
      "Epoch 84 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.588511\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 85 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.571088\n",
      "  validation loss:\t\t1.38\n",
      "Epoch 86 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.576762\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 87 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.561545\n",
      "  validation loss:\t\t1.36\n",
      "Epoch 88 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.548434\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 89 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.540366\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 90 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.514598\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 91 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.523090\n",
      "  validation loss:\t\t1.34\n",
      "Epoch 92 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.506376\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 93 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.495819\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 94 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.495109\n",
      "  validation loss:\t\t1.30\n",
      "Epoch 95 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.477424\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 96 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.470541\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 97 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.459396\n",
      "  validation loss:\t\t1.30\n",
      "Epoch 98 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.466581\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 99 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.446768\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 100 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.430214\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 101 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.434192\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 102 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.425976\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 103 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.422597\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 104 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.415668\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 105 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.405966\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 106 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.392763\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 107 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.395985\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 108 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.385082\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 109 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.374308\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 110 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.370289\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 111 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.376428\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 112 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.363132\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 113 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.360045\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 114 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.356827\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 115 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.338817\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 116 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.343768\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 117 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.347570\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 118 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.326941\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 119 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.331554\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 120 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.326511\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 121 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.331895\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 122 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.307422\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 123 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.310308\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 124 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.302715\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 125 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.299293\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 126 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.309753\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 127 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.292455\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 128 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.280786\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 129 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.285763\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 130 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.287202\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 131 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.268822\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 132 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.271164\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 133 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.264968\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 134 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.271039\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 135 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.251696\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 136 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.251945\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 137 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.261981\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 138 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.236223\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 139 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.251189\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 140 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.238160\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 141 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.243686\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 142 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.226185\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 143 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.243761\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 144 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.232379\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 145 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.228787\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 146 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.235083\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 147 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.224533\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 148 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.232964\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 149 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.203682\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 150 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.218324\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 151 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.196531\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 152 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.221705\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 153 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.224279\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 154 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.214024\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 155 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.200726\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 156 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.196592\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 157 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.200608\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 158 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.197030\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 159 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.195575\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 160 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.180110\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 161 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.197392\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 162 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.192522\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 163 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.199811\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 164 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.193757\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 165 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.185050\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 166 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.186274\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 167 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.180142\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 168 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.177732\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 169 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.171245\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 170 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.185229\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 171 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.180553\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 172 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.167698\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 173 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.175536\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 174 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.166339\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 175 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.181149\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 176 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.175004\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 177 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.162980\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 178 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.172719\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 179 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.177577\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 180 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.160814\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 181 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.163445\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 182 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.156966\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 183 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.150555\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 184 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.157229\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 185 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.154864\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 186 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.150867\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 187 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.143387\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 188 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.151590\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 189 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.142812\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 190 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.146172\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 191 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.143567\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 192 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.139955\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 193 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.167374\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 194 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.138265\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 195 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.136347\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 196 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.148418\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 197 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.138347\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 198 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.142597\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 199 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.142071\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 200 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.131164\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 201 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.136370\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 202 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.136705\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 203 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.138965\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 204 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.147941\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 205 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.133774\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 206 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.127073\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 207 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.134360\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 208 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.134837\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 209 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.134622\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 210 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.125791\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 211 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.138513\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 212 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.122855\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 213 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.134285\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 214 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.126482\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 215 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.137296\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 216 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.137657\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 217 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.114802\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 218 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.121917\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 219 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.112916\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 220 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.120172\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 1 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t5.188578\n",
      "  validation loss:\t\t4.33\n",
      "Epoch 2 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t4.777110\n",
      "  validation loss:\t\t4.11\n",
      "Epoch 3 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t4.610803\n",
      "  validation loss:\t\t4.01\n",
      "Epoch 4 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t4.474087\n",
      "  validation loss:\t\t3.88\n",
      "Epoch 5 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.357537\n",
      "  validation loss:\t\t3.81\n",
      "Epoch 6 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t4.267901\n",
      "  validation loss:\t\t3.73\n",
      "Epoch 7 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.174732\n",
      "  validation loss:\t\t3.64\n",
      "Epoch 8 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t4.099483\n",
      "  validation loss:\t\t3.59\n",
      "Epoch 9 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.008613\n",
      "  validation loss:\t\t3.51\n",
      "Epoch 10 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.931897\n",
      "  validation loss:\t\t3.45\n",
      "Epoch 11 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.853336\n",
      "  validation loss:\t\t3.38\n",
      "Epoch 12 of 220 took 0.090s\n",
      "  training loss (in-iteration):\t\t3.778806\n",
      "  validation loss:\t\t3.33\n",
      "Epoch 13 of 220 took 0.117s\n",
      "  training loss (in-iteration):\t\t3.719525\n",
      "  validation loss:\t\t3.25\n",
      "Epoch 14 of 220 took 0.103s\n",
      "  training loss (in-iteration):\t\t3.645139\n",
      "  validation loss:\t\t3.21\n",
      "Epoch 15 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t3.587901\n",
      "  validation loss:\t\t3.14\n",
      "Epoch 16 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.517661\n",
      "  validation loss:\t\t3.08\n",
      "Epoch 17 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.457085\n",
      "  validation loss:\t\t3.03\n",
      "Epoch 18 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.403270\n",
      "  validation loss:\t\t2.97\n",
      "Epoch 19 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.347352\n",
      "  validation loss:\t\t2.93\n",
      "Epoch 20 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t3.280780\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 21 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.232645\n",
      "  validation loss:\t\t2.83\n",
      "Epoch 22 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.178052\n",
      "  validation loss:\t\t2.78\n",
      "Epoch 23 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.125222\n",
      "  validation loss:\t\t2.73\n",
      "Epoch 24 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t3.077295\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 25 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.026735\n",
      "  validation loss:\t\t2.65\n",
      "Epoch 26 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.975164\n",
      "  validation loss:\t\t2.61\n",
      "Epoch 27 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.935590\n",
      "  validation loss:\t\t2.58\n",
      "Epoch 28 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.887413\n",
      "  validation loss:\t\t2.54\n",
      "Epoch 29 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.839793\n",
      "  validation loss:\t\t2.50\n",
      "Epoch 30 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.802096\n",
      "  validation loss:\t\t2.46\n",
      "Epoch 31 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.757458\n",
      "  validation loss:\t\t2.41\n",
      "Epoch 32 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.721756\n",
      "  validation loss:\t\t2.38\n",
      "Epoch 33 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.679227\n",
      "  validation loss:\t\t2.34\n",
      "Epoch 34 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.640147\n",
      "  validation loss:\t\t2.32\n",
      "Epoch 35 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.610897\n",
      "  validation loss:\t\t2.28\n",
      "Epoch 36 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.572118\n",
      "  validation loss:\t\t2.25\n",
      "Epoch 37 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.534681\n",
      "  validation loss:\t\t2.23\n",
      "Epoch 38 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.504841\n",
      "  validation loss:\t\t2.19\n",
      "Epoch 39 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.464429\n",
      "  validation loss:\t\t2.16\n",
      "Epoch 40 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.437735\n",
      "  validation loss:\t\t2.13\n",
      "Epoch 41 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t2.403007\n",
      "  validation loss:\t\t2.11\n",
      "Epoch 42 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.367345\n",
      "  validation loss:\t\t2.08\n",
      "Epoch 43 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.363272\n",
      "  validation loss:\t\t2.05\n",
      "Epoch 44 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.320063\n",
      "  validation loss:\t\t2.03\n",
      "Epoch 45 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.291970\n",
      "  validation loss:\t\t2.00\n",
      "Epoch 46 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t2.259039\n",
      "  validation loss:\t\t1.98\n",
      "Epoch 47 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t2.240324\n",
      "  validation loss:\t\t1.96\n",
      "Epoch 48 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.217339\n",
      "  validation loss:\t\t1.94\n",
      "Epoch 49 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.193279\n",
      "  validation loss:\t\t1.91\n",
      "Epoch 50 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.156793\n",
      "  validation loss:\t\t1.89\n",
      "Epoch 51 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.135017\n",
      "  validation loss:\t\t1.86\n",
      "Epoch 52 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.110238\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 53 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.088180\n",
      "  validation loss:\t\t1.82\n",
      "Epoch 54 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.067562\n",
      "  validation loss:\t\t1.80\n",
      "Epoch 55 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.034869\n",
      "  validation loss:\t\t1.78\n",
      "Epoch 56 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.028713\n",
      "  validation loss:\t\t1.78\n",
      "Epoch 57 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.003584\n",
      "  validation loss:\t\t1.74\n",
      "Epoch 58 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.980148\n",
      "  validation loss:\t\t1.74\n",
      "Epoch 59 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.959600\n",
      "  validation loss:\t\t1.72\n",
      "Epoch 60 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.942661\n",
      "  validation loss:\t\t1.68\n",
      "Epoch 61 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.923191\n",
      "  validation loss:\t\t1.69\n",
      "Epoch 62 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.915131\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 63 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.880560\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 64 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.880556\n",
      "  validation loss:\t\t1.63\n",
      "Epoch 65 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.855159\n",
      "  validation loss:\t\t1.62\n",
      "Epoch 66 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.837726\n",
      "  validation loss:\t\t1.60\n",
      "Epoch 67 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.809444\n",
      "  validation loss:\t\t1.59\n",
      "Epoch 68 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.804650\n",
      "  validation loss:\t\t1.59\n",
      "Epoch 69 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.795063\n",
      "  validation loss:\t\t1.55\n",
      "Epoch 70 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.765832\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 71 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.753448\n",
      "  validation loss:\t\t1.53\n",
      "Epoch 72 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.733904\n",
      "  validation loss:\t\t1.52\n",
      "Epoch 73 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.734901\n",
      "  validation loss:\t\t1.51\n",
      "Epoch 74 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.711899\n",
      "  validation loss:\t\t1.49\n",
      "Epoch 75 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.696567\n",
      "  validation loss:\t\t1.50\n",
      "Epoch 76 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.687103\n",
      "  validation loss:\t\t1.49\n",
      "Epoch 77 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.681849\n",
      "  validation loss:\t\t1.46\n",
      "Epoch 78 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.659470\n",
      "  validation loss:\t\t1.44\n",
      "Epoch 79 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.658312\n",
      "  validation loss:\t\t1.44\n",
      "Epoch 80 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.635418\n",
      "  validation loss:\t\t1.42\n",
      "Epoch 81 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.617400\n",
      "  validation loss:\t\t1.42\n",
      "Epoch 82 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.616613\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 83 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.608815\n",
      "  validation loss:\t\t1.39\n",
      "Epoch 84 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.595494\n",
      "  validation loss:\t\t1.38\n",
      "Epoch 85 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.575940\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 86 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.571260\n",
      "  validation loss:\t\t1.36\n",
      "Epoch 87 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.572234\n",
      "  validation loss:\t\t1.36\n",
      "Epoch 88 of 220 took 0.089s\n",
      "  training loss (in-iteration):\t\t1.547635\n",
      "  validation loss:\t\t1.36\n",
      "Epoch 89 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.545159\n",
      "  validation loss:\t\t1.34\n",
      "Epoch 90 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.543161\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 91 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.524575\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 92 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.507001\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 93 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.502893\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 94 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.494895\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 95 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.490151\n",
      "  validation loss:\t\t1.30\n",
      "Epoch 96 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.469826\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 97 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.473964\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 98 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.456688\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 99 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.451570\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 100 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.447699\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 101 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.443596\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 102 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.421892\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 103 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.426274\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 104 of 220 took 0.116s\n",
      "  training loss (in-iteration):\t\t1.412682\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 105 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.417693\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 106 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.403098\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 107 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.398565\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 108 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.388492\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 109 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.394508\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 110 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.372220\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 111 of 220 took 0.090s\n",
      "  training loss (in-iteration):\t\t1.365682\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 112 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.379423\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 113 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.360958\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 114 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.358426\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 115 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.362102\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 116 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.347869\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 117 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.326840\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 118 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.331735\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 119 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.343079\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 120 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.317496\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 121 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.325160\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 122 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.326215\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 123 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.311003\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 124 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.324732\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 125 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.288406\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 126 of 220 took 0.092s\n",
      "  training loss (in-iteration):\t\t1.316741\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 127 of 220 took 0.099s\n",
      "  training loss (in-iteration):\t\t1.289098\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 128 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.301728\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 129 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.293663\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 130 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.287890\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 131 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.272643\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 132 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.279229\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 133 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.260567\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 134 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.271048\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 135 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.266826\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 136 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.258176\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 137 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.251762\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 138 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.258693\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 139 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.262605\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 140 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.258142\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 141 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.255570\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 142 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.230281\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 143 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.228430\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 144 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.248725\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 145 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.239135\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 146 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.234446\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 147 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.231225\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 148 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.222620\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 149 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.219766\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 150 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.214802\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 151 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.219259\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 152 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.219140\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 153 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.221565\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 154 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.215695\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 155 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.204421\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 156 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.207119\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 157 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.217025\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 158 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.201853\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 159 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.200175\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 160 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.207407\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 161 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.189343\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 162 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.202132\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 163 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.190043\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 164 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.194473\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 165 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.185754\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 166 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.187420\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 167 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.207567\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 168 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.168498\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 169 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.188475\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 170 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.185743\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 171 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.190144\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 172 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.184058\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 173 of 220 took 0.120s\n",
      "  training loss (in-iteration):\t\t1.191277\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 174 of 220 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.177841\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 175 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.191291\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 176 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.182573\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 177 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.183326\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 178 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.172709\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 179 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.156830\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 180 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.169201\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 181 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.157964\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 182 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.161615\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 183 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.167556\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 184 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.169485\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 185 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.164857\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 186 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.160897\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 187 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.171432\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 188 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.140834\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 189 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.148193\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 190 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.155855\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 191 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.150391\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 192 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.161738\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 193 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.148037\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 194 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.146941\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 195 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.170063\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 196 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.140096\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 197 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.155430\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 198 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.139514\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 199 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.152761\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 200 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.156394\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 201 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.145599\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 202 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.158179\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 203 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.153837\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 204 of 220 took 0.102s\n",
      "  training loss (in-iteration):\t\t1.133306\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 205 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.138805\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 206 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.135872\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 207 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.142255\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 208 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.135826\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 209 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.136352\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 210 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.155755\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 211 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.140218\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 212 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.125267\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 213 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.137979\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 214 of 220 took 0.107s\n",
      "  training loss (in-iteration):\t\t1.122889\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 215 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.131198\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 216 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.136536\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 217 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.130168\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 218 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.134849\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 219 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.118671\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 220 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.126831\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 1 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t5.147884\n",
      "  validation loss:\t\t4.21\n",
      "Epoch 2 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.769690\n",
      "  validation loss:\t\t4.04\n",
      "Epoch 3 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.596075\n",
      "  validation loss:\t\t3.91\n",
      "Epoch 4 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.468036\n",
      "  validation loss:\t\t3.80\n",
      "Epoch 5 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t4.342838\n",
      "  validation loss:\t\t3.72\n",
      "Epoch 6 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.260810\n",
      "  validation loss:\t\t3.64\n",
      "Epoch 7 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.168132\n",
      "  validation loss:\t\t3.57\n",
      "Epoch 8 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t4.085155\n",
      "  validation loss:\t\t3.50\n",
      "Epoch 9 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t4.005393\n",
      "  validation loss:\t\t3.43\n",
      "Epoch 10 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.933835\n",
      "  validation loss:\t\t3.37\n",
      "Epoch 11 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.853446\n",
      "  validation loss:\t\t3.31\n",
      "Epoch 12 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t3.785186\n",
      "  validation loss:\t\t3.26\n",
      "Epoch 13 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.705402\n",
      "  validation loss:\t\t3.19\n",
      "Epoch 14 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.654974\n",
      "  validation loss:\t\t3.13\n",
      "Epoch 15 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.591908\n",
      "  validation loss:\t\t3.07\n",
      "Epoch 16 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.519708\n",
      "  validation loss:\t\t3.02\n",
      "Epoch 17 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.462742\n",
      "  validation loss:\t\t2.96\n",
      "Epoch 18 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.401897\n",
      "  validation loss:\t\t2.92\n",
      "Epoch 19 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.340290\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 20 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.292035\n",
      "  validation loss:\t\t2.83\n",
      "Epoch 21 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.230844\n",
      "  validation loss:\t\t2.79\n",
      "Epoch 22 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.178986\n",
      "  validation loss:\t\t2.72\n",
      "Epoch 23 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.141497\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 24 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.080690\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 25 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.033120\n",
      "  validation loss:\t\t2.60\n",
      "Epoch 26 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.978820\n",
      "  validation loss:\t\t2.57\n",
      "Epoch 27 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.943131\n",
      "  validation loss:\t\t2.53\n",
      "Epoch 28 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.895018\n",
      "  validation loss:\t\t2.49\n",
      "Epoch 29 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.851860\n",
      "  validation loss:\t\t2.46\n",
      "Epoch 30 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.804037\n",
      "  validation loss:\t\t2.41\n",
      "Epoch 31 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.760899\n",
      "  validation loss:\t\t2.38\n",
      "Epoch 32 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t2.718879\n",
      "  validation loss:\t\t2.35\n",
      "Epoch 33 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.684598\n",
      "  validation loss:\t\t2.31\n",
      "Epoch 34 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.653514\n",
      "  validation loss:\t\t2.27\n",
      "Epoch 35 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.611135\n",
      "  validation loss:\t\t2.25\n",
      "Epoch 36 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.590041\n",
      "  validation loss:\t\t2.22\n",
      "Epoch 37 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.542536\n",
      "  validation loss:\t\t2.19\n",
      "Epoch 38 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.503439\n",
      "  validation loss:\t\t2.16\n",
      "Epoch 39 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.474356\n",
      "  validation loss:\t\t2.13\n",
      "Epoch 40 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.443694\n",
      "  validation loss:\t\t2.11\n",
      "Epoch 41 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.411195\n",
      "  validation loss:\t\t2.08\n",
      "Epoch 42 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.382027\n",
      "  validation loss:\t\t2.05\n",
      "Epoch 43 of 220 took 0.097s\n",
      "  training loss (in-iteration):\t\t2.347349\n",
      "  validation loss:\t\t2.03\n",
      "Epoch 44 of 220 took 0.109s\n",
      "  training loss (in-iteration):\t\t2.320259\n",
      "  validation loss:\t\t1.99\n",
      "Epoch 45 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t2.294794\n",
      "  validation loss:\t\t1.98\n",
      "Epoch 46 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t2.271161\n",
      "  validation loss:\t\t1.95\n",
      "Epoch 47 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.235904\n",
      "  validation loss:\t\t1.93\n",
      "Epoch 48 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.206078\n",
      "  validation loss:\t\t1.90\n",
      "Epoch 49 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.189800\n",
      "  validation loss:\t\t1.89\n",
      "Epoch 50 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.164082\n",
      "  validation loss:\t\t1.87\n",
      "Epoch 51 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.139225\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 52 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.111079\n",
      "  validation loss:\t\t1.81\n",
      "Epoch 53 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.093173\n",
      "  validation loss:\t\t1.81\n",
      "Epoch 54 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.067292\n",
      "  validation loss:\t\t1.77\n",
      "Epoch 55 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.038289\n",
      "  validation loss:\t\t1.76\n",
      "Epoch 56 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.017294\n",
      "  validation loss:\t\t1.75\n",
      "Epoch 57 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.006841\n",
      "  validation loss:\t\t1.72\n",
      "Epoch 58 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.979635\n",
      "  validation loss:\t\t1.72\n",
      "Epoch 59 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.964980\n",
      "  validation loss:\t\t1.69\n",
      "Epoch 60 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.953278\n",
      "  validation loss:\t\t1.67\n",
      "Epoch 61 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.929733\n",
      "  validation loss:\t\t1.66\n",
      "Epoch 62 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.905690\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 63 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.893813\n",
      "  validation loss:\t\t1.63\n",
      "Epoch 64 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.865944\n",
      "  validation loss:\t\t1.61\n",
      "Epoch 65 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.852462\n",
      "  validation loss:\t\t1.60\n",
      "Epoch 66 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.837071\n",
      "  validation loss:\t\t1.59\n",
      "Epoch 67 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.817553\n",
      "  validation loss:\t\t1.57\n",
      "Epoch 68 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.809415\n",
      "  validation loss:\t\t1.56\n",
      "Epoch 69 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.790877\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 70 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.765078\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 71 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.758644\n",
      "  validation loss:\t\t1.51\n",
      "Epoch 72 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.739812\n",
      "  validation loss:\t\t1.51\n",
      "Epoch 73 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.725433\n",
      "  validation loss:\t\t1.50\n",
      "Epoch 74 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.715161\n",
      "  validation loss:\t\t1.48\n",
      "Epoch 75 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t1.697413\n",
      "  validation loss:\t\t1.47\n",
      "Epoch 76 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.682612\n",
      "  validation loss:\t\t1.47\n",
      "Epoch 77 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.679085\n",
      "  validation loss:\t\t1.45\n",
      "Epoch 78 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.655046\n",
      "  validation loss:\t\t1.43\n",
      "Epoch 79 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.661952\n",
      "  validation loss:\t\t1.44\n",
      "Epoch 80 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.640092\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 81 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.616744\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 82 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.614066\n",
      "  validation loss:\t\t1.39\n",
      "Epoch 83 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.600222\n",
      "  validation loss:\t\t1.39\n",
      "Epoch 84 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.584800\n",
      "  validation loss:\t\t1.38\n",
      "Epoch 85 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.580204\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 86 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.572325\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 87 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.552691\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 88 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.546081\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 89 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.537340\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 90 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.535579\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 91 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.520542\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 92 of 220 took 0.153s\n",
      "  training loss (in-iteration):\t\t1.518337\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 93 of 220 took 0.113s\n",
      "  training loss (in-iteration):\t\t1.498928\n",
      "  validation loss:\t\t1.30\n",
      "Epoch 94 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.491517\n",
      "  validation loss:\t\t1.30\n",
      "Epoch 95 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.485998\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 96 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.481527\n",
      "  validation loss:\t\t1.28\n",
      "Epoch 97 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.463978\n",
      "  validation loss:\t\t1.28\n",
      "Epoch 98 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.453544\n",
      "  validation loss:\t\t1.28\n",
      "Epoch 99 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.449210\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 100 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.443407\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 101 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.431295\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 102 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.426281\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 103 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.419192\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 104 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.436213\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 105 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.400945\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 106 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.397968\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 107 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.395317\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 108 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.397624\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 109 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.374018\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 110 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.372967\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 111 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.373929\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 112 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.359893\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 113 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.362299\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 114 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.343889\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 115 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.348647\n",
      "  validation loss:\t\t1.19\n",
      "Epoch 116 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.335423\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 117 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.354522\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 118 of 220 took 0.121s\n",
      "  training loss (in-iteration):\t\t1.328004\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 119 of 220 took 0.090s\n",
      "  training loss (in-iteration):\t\t1.328556\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 120 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.325880\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 121 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.320038\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 122 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.337434\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 123 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.304614\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 124 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.307056\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 125 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.308370\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 126 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.287438\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 127 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.290899\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 128 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.287111\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 129 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.281542\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 130 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.292376\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 131 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.288385\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 132 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.263937\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 133 of 220 took 0.113s\n",
      "  training loss (in-iteration):\t\t1.276740\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 134 of 220 took 0.104s\n",
      "  training loss (in-iteration):\t\t1.274912\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 135 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.262180\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 136 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.257388\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 137 of 220 took 0.096s\n",
      "  training loss (in-iteration):\t\t1.250492\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 138 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.273177\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 139 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.248917\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 140 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.241181\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 141 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.239077\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 142 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.256833\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 143 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.251371\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 144 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.237787\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 145 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.217158\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 146 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.229527\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 147 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.226583\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 148 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.235766\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 149 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.239556\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 150 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.218000\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 151 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.213376\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 152 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.225096\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 153 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.207748\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 154 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.196979\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 155 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.206449\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 156 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.198635\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 157 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.198267\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 158 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.205767\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 159 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.199220\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 160 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.210489\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 161 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.206431\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 162 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.189380\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 163 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.184754\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 164 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.187325\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 165 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.182015\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 166 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.186851\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 167 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.190316\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 168 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.183423\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 169 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.187921\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 170 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.180884\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 171 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.197539\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 172 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.161448\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 173 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.173484\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 174 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.175276\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 175 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.170210\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 176 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.178078\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 177 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.178160\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 178 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.179632\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 179 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.168181\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 180 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.170507\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 181 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.160734\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 182 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.148108\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 183 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.166602\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 184 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.157045\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 185 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.162256\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 186 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.168371\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 187 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.160002\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 188 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.173153\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 189 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.165904\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 190 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.168159\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 191 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.156263\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 192 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.150437\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 193 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.155078\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 194 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.143147\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 195 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.142857\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 196 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.173955\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 197 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.149839\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 198 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.143916\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 199 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.142262\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 200 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.155518\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 201 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.161977\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 202 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.154308\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 203 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.131958\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 204 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.125737\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 205 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.152418\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 206 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.137396\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 207 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.131608\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 208 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.148982\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 209 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.132328\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 210 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.141656\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 211 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.135031\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 212 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.143073\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 213 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.129029\n",
      "  validation loss:\t\t1.03\n",
      "Epoch 214 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.113176\n",
      "  validation loss:\t\t1.06\n",
      "Epoch 215 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.133085\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 216 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.132776\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 217 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.143300\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 218 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.124038\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 219 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.123802\n",
      "  validation loss:\t\t1.04\n",
      "Epoch 220 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.132157\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 1 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t5.186747\n",
      "  validation loss:\t\t4.23\n",
      "Epoch 2 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t4.770232\n",
      "  validation loss:\t\t4.04\n",
      "Epoch 3 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.608407\n",
      "  validation loss:\t\t3.92\n",
      "Epoch 4 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.468343\n",
      "  validation loss:\t\t3.84\n",
      "Epoch 5 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t4.370289\n",
      "  validation loss:\t\t3.75\n",
      "Epoch 6 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.285077\n",
      "  validation loss:\t\t3.68\n",
      "Epoch 7 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t4.181424\n",
      "  validation loss:\t\t3.59\n",
      "Epoch 8 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t4.103682\n",
      "  validation loss:\t\t3.53\n",
      "Epoch 9 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t4.016724\n",
      "  validation loss:\t\t3.45\n",
      "Epoch 10 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.947823\n",
      "  validation loss:\t\t3.40\n",
      "Epoch 11 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.851721\n",
      "  validation loss:\t\t3.33\n",
      "Epoch 12 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.797425\n",
      "  validation loss:\t\t3.28\n",
      "Epoch 13 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.723012\n",
      "  validation loss:\t\t3.23\n",
      "Epoch 14 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.655320\n",
      "  validation loss:\t\t3.16\n",
      "Epoch 15 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t3.594480\n",
      "  validation loss:\t\t3.10\n",
      "Epoch 16 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.522714\n",
      "  validation loss:\t\t3.07\n",
      "Epoch 17 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.469211\n",
      "  validation loss:\t\t3.02\n",
      "Epoch 18 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t3.403480\n",
      "  validation loss:\t\t2.94\n",
      "Epoch 19 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.351775\n",
      "  validation loss:\t\t2.89\n",
      "Epoch 20 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.289627\n",
      "  validation loss:\t\t2.84\n",
      "Epoch 21 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.236653\n",
      "  validation loss:\t\t2.80\n",
      "Epoch 22 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.182789\n",
      "  validation loss:\t\t2.75\n",
      "Epoch 23 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.142527\n",
      "  validation loss:\t\t2.71\n",
      "Epoch 24 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.074349\n",
      "  validation loss:\t\t2.68\n",
      "Epoch 25 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.032715\n",
      "  validation loss:\t\t2.62\n",
      "Epoch 26 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.979087\n",
      "  validation loss:\t\t2.58\n",
      "Epoch 27 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.943287\n",
      "  validation loss:\t\t2.56\n",
      "Epoch 28 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.903419\n",
      "  validation loss:\t\t2.50\n",
      "Epoch 29 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.843943\n",
      "  validation loss:\t\t2.47\n",
      "Epoch 30 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.808488\n",
      "  validation loss:\t\t2.44\n",
      "Epoch 31 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.761245\n",
      "  validation loss:\t\t2.39\n",
      "Epoch 32 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.720942\n",
      "  validation loss:\t\t2.35\n",
      "Epoch 33 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.682458\n",
      "  validation loss:\t\t2.35\n",
      "Epoch 34 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.649270\n",
      "  validation loss:\t\t2.31\n",
      "Epoch 35 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.617090\n",
      "  validation loss:\t\t2.27\n",
      "Epoch 36 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.575687\n",
      "  validation loss:\t\t2.24\n",
      "Epoch 37 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.532475\n",
      "  validation loss:\t\t2.20\n",
      "Epoch 38 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.509033\n",
      "  validation loss:\t\t2.19\n",
      "Epoch 39 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.475504\n",
      "  validation loss:\t\t2.14\n",
      "Epoch 40 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.441052\n",
      "  validation loss:\t\t2.13\n",
      "Epoch 41 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.412943\n",
      "  validation loss:\t\t2.10\n",
      "Epoch 42 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.373588\n",
      "  validation loss:\t\t2.07\n",
      "Epoch 43 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.345945\n",
      "  validation loss:\t\t2.05\n",
      "Epoch 44 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.324867\n",
      "  validation loss:\t\t2.03\n",
      "Epoch 45 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.288885\n",
      "  validation loss:\t\t2.00\n",
      "Epoch 46 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.265080\n",
      "  validation loss:\t\t1.98\n",
      "Epoch 47 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.234096\n",
      "  validation loss:\t\t1.96\n",
      "Epoch 48 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.209119\n",
      "  validation loss:\t\t1.93\n",
      "Epoch 49 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.182346\n",
      "  validation loss:\t\t1.92\n",
      "Epoch 50 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.169965\n",
      "  validation loss:\t\t1.89\n",
      "Epoch 51 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.130975\n",
      "  validation loss:\t\t1.87\n",
      "Epoch 52 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.109225\n",
      "  validation loss:\t\t1.87\n",
      "Epoch 53 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.084913\n",
      "  validation loss:\t\t1.83\n",
      "Epoch 54 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t2.069031\n",
      "  validation loss:\t\t1.80\n",
      "Epoch 55 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.039099\n",
      "  validation loss:\t\t1.78\n",
      "Epoch 56 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.015886\n",
      "  validation loss:\t\t1.77\n",
      "Epoch 57 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.999309\n",
      "  validation loss:\t\t1.75\n",
      "Epoch 58 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.977236\n",
      "  validation loss:\t\t1.73\n",
      "Epoch 59 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.965415\n",
      "  validation loss:\t\t1.71\n",
      "Epoch 60 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.938876\n",
      "  validation loss:\t\t1.70\n",
      "Epoch 61 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.919165\n",
      "  validation loss:\t\t1.69\n",
      "Epoch 62 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.893198\n",
      "  validation loss:\t\t1.67\n",
      "Epoch 63 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.884902\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 64 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.861686\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 65 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.858878\n",
      "  validation loss:\t\t1.62\n",
      "Epoch 66 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.828504\n",
      "  validation loss:\t\t1.62\n",
      "Epoch 67 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.812008\n",
      "  validation loss:\t\t1.59\n",
      "Epoch 68 of 220 took 0.098s\n",
      "  training loss (in-iteration):\t\t1.797454\n",
      "  validation loss:\t\t1.58\n",
      "Epoch 69 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.786927\n",
      "  validation loss:\t\t1.58\n",
      "Epoch 70 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.771081\n",
      "  validation loss:\t\t1.56\n",
      "Epoch 71 of 220 took 0.114s\n",
      "  training loss (in-iteration):\t\t1.758631\n",
      "  validation loss:\t\t1.55\n",
      "Epoch 72 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.731683\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 73 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.736837\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 74 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.702307\n",
      "  validation loss:\t\t1.52\n",
      "Epoch 75 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.689935\n",
      "  validation loss:\t\t1.50\n",
      "Epoch 76 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.689155\n",
      "  validation loss:\t\t1.49\n",
      "Epoch 77 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.666776\n",
      "  validation loss:\t\t1.47\n",
      "Epoch 78 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.650279\n",
      "  validation loss:\t\t1.47\n",
      "Epoch 79 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.649017\n",
      "  validation loss:\t\t1.45\n",
      "Epoch 80 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.627737\n",
      "  validation loss:\t\t1.44\n",
      "Epoch 81 of 220 took 0.071s\n",
      "  training loss (in-iteration):\t\t1.618336\n",
      "  validation loss:\t\t1.44\n",
      "Epoch 82 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.603236\n",
      "  validation loss:\t\t1.43\n",
      "Epoch 83 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.590099\n",
      "  validation loss:\t\t1.42\n",
      "Epoch 84 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.585012\n",
      "  validation loss:\t\t1.41\n",
      "Epoch 85 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.580526\n",
      "  validation loss:\t\t1.40\n",
      "Epoch 86 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.561745\n",
      "  validation loss:\t\t1.39\n",
      "Epoch 87 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.558179\n",
      "  validation loss:\t\t1.38\n",
      "Epoch 88 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.543079\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 89 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.531867\n",
      "  validation loss:\t\t1.37\n",
      "Epoch 90 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.527990\n",
      "  validation loss:\t\t1.36\n",
      "Epoch 91 of 220 took 0.101s\n",
      "  training loss (in-iteration):\t\t1.517478\n",
      "  validation loss:\t\t1.36\n",
      "Epoch 92 of 220 took 0.101s\n",
      "  training loss (in-iteration):\t\t1.504116\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 93 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.490775\n",
      "  validation loss:\t\t1.36\n",
      "Epoch 94 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.493662\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 95 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.477709\n",
      "  validation loss:\t\t1.32\n",
      "Epoch 96 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.465316\n",
      "  validation loss:\t\t1.33\n",
      "Epoch 97 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.454842\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 98 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.451900\n",
      "  validation loss:\t\t1.30\n",
      "Epoch 99 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.445098\n",
      "  validation loss:\t\t1.29\n",
      "Epoch 100 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.437415\n",
      "  validation loss:\t\t1.31\n",
      "Epoch 101 of 220 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.429882\n",
      "  validation loss:\t\t1.28\n",
      "Epoch 102 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.428376\n",
      "  validation loss:\t\t1.28\n",
      "Epoch 103 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.410862\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 104 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.410488\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 105 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.404453\n",
      "  validation loss:\t\t1.27\n",
      "Epoch 106 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.395570\n",
      "  validation loss:\t\t1.26\n",
      "Epoch 107 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.384609\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 108 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.384910\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 109 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.367489\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 110 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.371157\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 111 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.367462\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 112 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.363880\n",
      "  validation loss:\t\t1.24\n",
      "Epoch 113 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.350484\n",
      "  validation loss:\t\t1.22\n",
      "Epoch 114 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.349622\n",
      "  validation loss:\t\t1.25\n",
      "Epoch 115 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.335108\n",
      "  validation loss:\t\t1.23\n",
      "Epoch 116 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.338116\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 117 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.328748\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 118 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.330115\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 119 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.316980\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 120 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.307175\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 121 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.310855\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 122 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.296322\n",
      "  validation loss:\t\t1.20\n",
      "Epoch 123 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.302503\n",
      "  validation loss:\t\t1.21\n",
      "Epoch 124 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.312313\n",
      "  validation loss:\t\t1.18\n",
      "Epoch 125 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.299810\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 126 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.293023\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 127 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.290326\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 128 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.291014\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 129 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.267777\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 130 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.263722\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 131 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.267766\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 132 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.258287\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 133 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.262294\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 134 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.253996\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 135 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.253865\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 136 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.259400\n",
      "  validation loss:\t\t1.17\n",
      "Epoch 137 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.246220\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 138 of 220 took 0.101s\n",
      "  training loss (in-iteration):\t\t1.263415\n",
      "  validation loss:\t\t1.16\n",
      "Epoch 139 of 220 took 0.108s\n",
      "  training loss (in-iteration):\t\t1.246472\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 140 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.226650\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 141 of 220 took 0.072s\n",
      "  training loss (in-iteration):\t\t1.247148\n",
      "  validation loss:\t\t1.15\n",
      "Epoch 142 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.243054\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 143 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.233400\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 144 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.226666\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 145 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.216957\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 146 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.222202\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 147 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.224841\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 148 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.212866\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 149 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.221884\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 150 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.209108\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 151 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.209156\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 152 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.188871\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 153 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.199067\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 154 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.199094\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 155 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.198797\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 156 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.200464\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 157 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.195720\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 158 of 220 took 0.083s\n",
      "  training loss (in-iteration):\t\t1.205603\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 159 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.191387\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 160 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.178131\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 161 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.205156\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 162 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.187051\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 163 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.187836\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 164 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.170306\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 165 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.174957\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 166 of 220 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.181382\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 167 of 220 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.168359\n",
      "  validation loss:\t\t1.14\n",
      "Epoch 168 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.175556\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 169 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.175030\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 170 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.169581\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 171 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.161888\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 172 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.181721\n",
      "  validation loss:\t\t1.12\n",
      "Epoch 173 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.155320\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 174 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.172395\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 175 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.174538\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 176 of 220 took 0.089s\n",
      "  training loss (in-iteration):\t\t1.142789\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 177 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.149558\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 178 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.158746\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 179 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.176806\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 180 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.147924\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 181 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.152269\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 182 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.160931\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 183 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.161336\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 184 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.144137\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 185 of 220 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.134610\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 186 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.158488\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 187 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.147009\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 188 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.136207\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 189 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.161438\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 190 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.147121\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 191 of 220 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.133097\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 192 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.133138\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 193 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.161592\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 194 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.144088\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 195 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.132523\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 196 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.140153\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 197 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.145704\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 198 of 220 took 0.073s\n",
      "  training loss (in-iteration):\t\t1.142579\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 199 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.119478\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 200 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.132550\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 201 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.132212\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 202 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.126353\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 203 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.133950\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 204 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.130603\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 205 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.111705\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 206 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.113019\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 207 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.122766\n",
      "  validation loss:\t\t1.13\n",
      "Epoch 208 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.151484\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 209 of 220 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.112921\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 210 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.150457\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 211 of 220 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.121476\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 212 of 220 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.126766\n",
      "  validation loss:\t\t1.11\n",
      "Epoch 213 of 220 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.128578\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 214 of 220 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.117208\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 215 of 220 took 0.080s\n",
      "  training loss (in-iteration):\t\t1.111400\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 216 of 220 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.118465\n",
      "  validation loss:\t\t1.09\n",
      "Epoch 217 of 220 took 0.088s\n",
      "  training loss (in-iteration):\t\t1.119405\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 218 of 220 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.113553\n",
      "  validation loss:\t\t1.08\n",
      "Epoch 219 of 220 took 0.107s\n",
      "  training loss (in-iteration):\t\t1.111427\n",
      "  validation loss:\t\t1.07\n",
      "Epoch 220 of 220 took 0.113s\n",
      "  training loss (in-iteration):\t\t1.131748\n",
      "  validation loss:\t\t1.10\n"
     ]
    }
   ],
   "source": [
    "k = 5\n",
    "y = Y\n",
    "score = []\n",
    "n = X.shape[0]\n",
    "start_ind = 0\n",
    "step = int(n / k)\n",
    "end_ind = step\n",
    "input_shape = (None, X.shape[1])\n",
    "l_input = lasagne.layers.InputLayer(shape=input_shape, input_var=input_X)\n",
    "for j in xrange(k):\n",
    "    score_cur = np.zeros(y.shape[1])\n",
    "    test_ind = np.arange(start_ind,end_ind)\n",
    "    train_ind = np.concatenate((np.arange(0, start_ind), np.arange(end_ind, n)))\n",
    "    X_train = X[train_ind, :]\n",
    "    y_train = y[train_ind, :]\n",
    "    X_test = X[test_ind, :]\n",
    "    y_test = y[test_ind, :]\n",
    "    model = DNN(input_X, target, X_train, y_train, X_test, y_test)\n",
    "    #l_z, l_ae_out = model.build_ae(l_input=l_input, HU_enc=HU_enc, HU_dec=HU_dec, dimZ=dimZ, n_out=X.shape[1])\n",
    "    #ae_train, ae_test, ae_pred = model.build_ae_loss(l_ae_out)\n",
    "    #ae_train_loss_log, ae_val_loss_log = model.fit_ae(ae_train, ae_test, num_epochs=200, batch_size=1000)\n",
    "    l_nn_out = model.build_nn(l_input)#l_z)\n",
    "    nn_train, nn_test, nn_pred = model.build_nn_loss(l_nn_out, learning_rate=0.9)\n",
    "    nn_train_loss_log, nn_val_loss_log = model.fit_nn(nn_train, nn_test, num_epochs=220, batch_size=1000)\n",
    "    y_pred = nn_pred(X_test)\n",
    "    for i in range(y.shape[1]):\n",
    "        ind = np.where(y_test[:, i] != 999)\n",
    "        fpr, tpr, _ = roc_curve(y_test[ind, i][0], y_pred[ind, i][0])\n",
    "        score_cur[i] =  roc_auc_score(y_test[ind, i][0], y_pred[ind, i][0])\n",
    "    score.append(score_cur)\n",
    "    start_ind = end_ind\n",
    "    end_ind = end_ind + step\n",
    "    if end_ind > n:\n",
    "        end_ind = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11cfb0c50>]"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEACAYAAAC9Gb03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cfb0790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(ae_train_loss_log)\n",
    "plt.plot(ae_val_loss_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11ea54350>]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrCAu+mZmBXHRNzMryAVI2NvKKNbGCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ea54550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn_train_loss_log[-1100:])\n",
    "plt.plot(nn_val_loss_log[-1100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.86953071  0.90160075  0.90020315  0.85392749  0.80950116  0.85905227\n",
      "  0.85667776  0.81610442  0.83199256  0.82090954  0.8923199   0.83677706]\n"
     ]
    }
   ],
   "source": [
    "# nn training 220 epochs learning_rate = 0.9 batch_size=1000 + Dropout training dataset without AE\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.03099293  0.0254801   0.01075021  0.04021835  0.03546144  0.02887597\n",
      "  0.02402066  0.01301059  0.03014335  0.03630874  0.01375884  0.02049565]\n"
     ]
    }
   ],
   "source": [
    "print np.concatenate(score).reshape(k, 12).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.87068438  0.91570057  0.89772866  0.85847043  0.80464994  0.85577689\n",
      "  0.86018042  0.820201    0.83870378  0.82567656  0.89160762  0.84210853]\n"
     ]
    }
   ],
   "source": [
    "# nn training 200 epochs learning_rate = 0.9 batch_size=1000 + Dropout training dataset without AE\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.02900656  0.01446193  0.01404567  0.04676627  0.03460986  0.02476363\n",
      "  0.02880455  0.01153568  0.02029545  0.02846325  0.0112261   0.01401691]\n"
     ]
    }
   ],
   "source": [
    "print np.concatenate(score).reshape(k, 12).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.8636278   0.90339778  0.89504512  0.8640713   0.80175651  0.84792718\n",
      "  0.83753494  0.80935967  0.82660896  0.80979816  0.88693773  0.83053867]\n"
     ]
    }
   ],
   "source": [
    "# nn training 150 epochs learning_rate = 0.9 batch_size=1000 + Dropout training dataset without AE\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.86516691  0.90861804  0.89145878  0.85351253  0.79978538  0.84405781\n",
      "  0.83690813  0.80696934  0.83049858  0.80757925  0.88279966  0.82809377]\n"
     ]
    }
   ],
   "source": [
    "# nn training 130 epochs learning_rate = 0.9 batch_size=1000 + Dropout training dataset without AE\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.83703581  0.9152079   0.88601909  0.83893225  0.78931138  0.85525147\n",
      "  0.82457676  0.81139405  0.84012444  0.79550447  0.90791461  0.83230555]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1000 + Dropout\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.87462599  0.89596021  0.88407121  0.85324433  0.79752312  0.84796722\n",
      "  0.81507091  0.79178215  0.80138718  0.79151408  0.87662536  0.81355721]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1000 + Dropout training dataset without AE\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.85102919  0.92737596  0.8876233   0.8343021   0.79018184  0.87941438\n",
      "  0.8190472   0.81279547  0.8238491   0.79819615  0.9036068   0.82157536]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1000 + Dropout training dataset\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05268932  0.00882914  0.02448524  0.0274957   0.01513653  0.02168842\n",
      "  0.02977837  0.018434    0.01841829  0.02777371  0.02274042  0.01227818]\n"
     ]
    }
   ],
   "source": [
    "print np.concatenate(score).reshape(k, 12).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.84518694  0.90354037  0.89469477  0.84462808  0.79665199  0.87352588\n",
      "  0.81837713  0.82666847  0.84284203  0.80317784  0.90786948  0.84220141]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1000 + Dropout\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.83565061  0.89161145  0.88436898  0.81956398  0.78298847  0.86535874\n",
      "  0.81257925  0.81520452  0.83513207  0.79605056  0.90897787  0.8225995 ]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=700 + Dropout\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.84679478  0.8980354   0.88308412  0.82778917  0.78226066  0.85451022\n",
      "  0.83041309  0.80337948  0.83077171  0.79421221  0.9142426   0.83339232]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1024 + Dropout\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "scores = model.cross_val(X, Y, nn_train, nn_test, ae_train, ae_test, nn_pred, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.85162529  0.90913731  0.88020643  0.8260654   0.78442611  0.88064303\n",
      "  0.78583365  0.81526978  0.83225942  0.80579732  0.90828562  0.82130988]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1000 + Dropout + adamax training\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.84219333  0.88891283  0.88145815  0.83110027  0.79300138  0.86045075\n",
      "  0.79177637  0.79981872  0.81749692  0.77771706  0.89285423  0.81858416]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1000 + Dropout + adam training\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.84279311  0.90208356  0.89290969  0.81994371  0.79305954  0.8531954\n",
      "  0.82923574  0.81302911  0.84369567  0.80192078  0.9129823   0.82326059]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.819769    0.89807785  0.86831519  0.75441058  0.75388474  0.81537956\n",
      "  0.79032254  0.7730857   0.78771429  0.71208996  0.89325503  0.7612231 ]\n"
     ]
    }
   ],
   "source": [
    "# nn training 130 epochs learning_rate = 0.9 batch_size=1500 \n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.81781821  0.90298162  0.86867373  0.82131456  0.79052313  0.87038066\n",
      "  0.8296214   0.7984228   0.82625608  0.7931178   0.90741371  0.79383784]\n"
     ]
    }
   ],
   "source": [
    "# nn training 130 epochs learning_rate = 0.9 batch_size=1500 \n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.80706028  0.88977564  0.85063556  0.77800968  0.75598882  0.84115943\n",
      "  0.76621726  0.78251482  0.77315239  0.78606085  0.89592575  0.78399381]\n"
     ]
    }
   ],
   "source": [
    "# nn training 200 epochs learning_rate = 0.9 batch_size=1500 \n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.82048806  0.88943588  0.89764367  0.82727197  0.79887636  0.8596576\n",
      "  0.83479235  0.81152992  0.83859839  0.79242591  0.89499004  0.81374217]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.9 batch_size=1500\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.83088216  0.90468484  0.88792156  0.82579838  0.80286879  0.85986864\n",
      "  0.84374633  0.80933631  0.84128251  0.78218653  0.89544962  0.81379069]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.7 batch_size=1500\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.79876691  0.86265812  0.86950877  0.73835809  0.75363271  0.80124627\n",
      "  0.7771571   0.78339891  0.77084848  0.75497874  0.88863053  0.76973337]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.7 batch_size=100\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.83936838  0.85726583  0.86176175  0.81949881  0.7809152   0.82177492\n",
      "  0.73466854  0.76893584  0.75861858  0.71971002  0.86377527  0.77340386]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.7 full gradient learning\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.82695817  0.8934446   0.88560754  0.82763647  0.80154481  0.85575104\n",
      "  0.81871218  0.8165997   0.82263532  0.78945377  0.90610022  0.82133104]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 0.7\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.81238367  0.89645014  0.89234557  0.82156954  0.79197037  0.84182302\n",
      "  0.82477895  0.81034413  0.84478899  0.77569717  0.90631692  0.80940163]\n"
     ]
    }
   ],
   "source": [
    "# nn training 100 epochs learning_rate = 1.0\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.82288422  0.90172734  0.88884527  0.80882062  0.77586758  0.82562379\n",
      "  0.83325786  0.80675179  0.83110396  0.76772663  0.90942777  0.81277057]\n"
     ]
    }
   ],
   "source": [
    "# nn training 130 epochs learning_rate = 0.9\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.82148502  0.8985514   0.88839858  0.83548788  0.79701144  0.8486088\n",
      "  0.82518582  0.81919649  0.82983865  0.76408606  0.90766063  0.82966115]\n"
     ]
    }
   ],
   "source": [
    "# nn training 80 epochs learning_rate = 0.9\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR' 'NR-AR-LBD' 'NR-AhR' 'NR-Aromatase' 'NR-ER' 'NR-ER-LBD'\n",
      " 'NR-PPAR-gamma' 'SR-ARE' 'SR-ATAD5' 'SR-HSE' 'SR-MMP' 'SR-p53']\n",
      "[ 0.84487536  0.89964521  0.88906601  0.85220246  0.79079851  0.85792184\n",
      "  0.81893683  0.81953211  0.83055449  0.79954576  0.89594254  0.81503311]\n"
     ]
    }
   ],
   "source": [
    "# nn training 50 epochs learning_rate = 0.9\n",
    "print receptor_names\n",
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84413911  0.89006824  0.88150391  0.82144761  0.78189412  0.82863137\n",
      "  0.82144445  0.81943607  0.81360076  0.79415921  0.8997149   0.81410432]\n"
     ]
    }
   ],
   "source": [
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.83492957  0.89009362  0.88167622  0.82925638  0.79512983  0.84317272\n",
      "  0.78127753  0.80375417  0.80645902  0.76365098  0.89118801  0.80274714]\n"
     ]
    }
   ],
   "source": [
    "print np.concatenate(score).reshape(k, 12).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.04533623  0.02253478  0.01295715  0.02745194  0.03486713  0.02502491\n",
      "  0.04199225  0.01030281  0.01984736  0.01512168  0.01400416  0.01206108]\n"
     ]
    }
   ],
   "source": [
    "print np.concatenate(score).reshape(k, 12).std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dnn_class import Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval = Evaluator(input_X, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33324.1897148\n",
      "Epoch 1 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t32.747477\n",
      "  validation loss:\t\t50.15\n",
      "Epoch 2 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t32.976947\n",
      "  validation loss:\t\t49.64\n",
      "Epoch 3 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t32.369834\n",
      "  validation loss:\t\t49.13\n",
      "Epoch 4 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t32.462725\n",
      "  validation loss:\t\t49.25\n",
      "Epoch 5 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t31.932597\n",
      "  validation loss:\t\t48.57\n",
      "Epoch 6 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t31.418075\n",
      "  validation loss:\t\t47.65\n",
      "Epoch 7 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t31.293243\n",
      "  validation loss:\t\t45.94\n",
      "Epoch 8 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t28.947927\n",
      "  validation loss:\t\t38.50\n",
      "Epoch 9 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t19.869695\n",
      "  validation loss:\t\t17.98\n",
      "Epoch 10 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t6.567739\n",
      "  validation loss:\t\t4.72\n",
      "3382.94414157\n",
      "Epoch 11 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t3.436917\n",
      "  validation loss:\t\t2.98\n",
      "Epoch 12 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t2.320055\n",
      "  validation loss:\t\t2.89\n",
      "Epoch 13 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t2.570850\n",
      "  validation loss:\t\t2.74\n",
      "Epoch 14 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t2.105601\n",
      "  validation loss:\t\t2.96\n",
      "Epoch 15 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t2.138376\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 16 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t2.135352\n",
      "  validation loss:\t\t2.00\n",
      "Epoch 17 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t1.570085\n",
      "  validation loss:\t\t1.74\n",
      "Epoch 18 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t1.338691\n",
      "  validation loss:\t\t1.42\n",
      "Epoch 19 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t1.010713\n",
      "  validation loss:\t\t0.96\n",
      "Epoch 20 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.672019\n",
      "  validation loss:\t\t0.60\n",
      "532.232987172\n",
      "Epoch 21 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.482284\n",
      "  validation loss:\t\t0.47\n",
      "Epoch 22 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.388080\n",
      "  validation loss:\t\t0.42\n",
      "Epoch 23 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.357041\n",
      "  validation loss:\t\t0.47\n",
      "Epoch 24 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.392044\n",
      "  validation loss:\t\t0.47\n",
      "Epoch 25 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.371724\n",
      "  validation loss:\t\t0.46\n",
      "Epoch 26 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.416748\n",
      "  validation loss:\t\t0.35\n",
      "Epoch 27 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.310665\n",
      "  validation loss:\t\t0.35\n",
      "Epoch 28 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.310489\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 29 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.323307\n",
      "  validation loss:\t\t0.35\n",
      "Epoch 30 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.324558\n",
      "  validation loss:\t\t0.36\n",
      "319.988233018\n",
      "Epoch 31 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.318252\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 32 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.320655\n",
      "  validation loss:\t\t0.50\n",
      "Epoch 33 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.356787\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 34 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.295334\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 35 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.302337\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 36 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.293251\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 37 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.289821\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 38 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.294643\n",
      "  validation loss:\t\t0.35\n",
      "Epoch 39 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.308784\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 40 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.296438\n",
      "  validation loss:\t\t0.37\n",
      "330.311944993\n",
      "Epoch 41 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.297099\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 42 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.291167\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 43 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.296103\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 44 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.274810\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 45 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.284549\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 46 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.285865\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 47 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.283897\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 48 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.276794\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 49 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.268432\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 50 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.272100\n",
      "  validation loss:\t\t0.31\n",
      "281.986593866\n",
      "Epoch 51 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.281127\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 52 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.266710\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 53 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.262320\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 54 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.262404\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 55 of 500 took 0.223s\n",
      "  training loss (in-iteration):\t\t0.260036\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 56 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.260550\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 57 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.271838\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 58 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.259707\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 59 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.253854\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 60 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.254484\n",
      "  validation loss:\t\t0.28\n",
      "256.941215097\n",
      "Epoch 61 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.256482\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 62 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.255932\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 63 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.254894\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 64 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.255288\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 65 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.254930\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 66 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.250985\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 67 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.252886\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 68 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.250891\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 69 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.248883\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 70 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.243805\n",
      "  validation loss:\t\t0.27\n",
      "244.214562916\n",
      "Epoch 71 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.238481\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 72 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.243381\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 73 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.240608\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 74 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.223543\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 75 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.230196\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 76 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.222883\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 77 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.225181\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 78 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.220921\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 79 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.216041\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 80 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.218335\n",
      "  validation loss:\t\t0.22\n",
      "206.349657017\n",
      "Epoch 81 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.206388\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 82 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.211117\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 83 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.206409\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 84 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.201690\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 85 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.198607\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 86 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.201001\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 87 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.200860\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 88 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.193410\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 89 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.194847\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 90 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.186666\n",
      "  validation loss:\t\t0.22\n",
      "197.249230044\n",
      "Epoch 91 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.183380\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 92 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.177091\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 93 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.175834\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 94 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.180125\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 95 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.168855\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 96 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.174672\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 97 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.163063\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 98 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.164916\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 99 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.158391\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 100 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.160042\n",
      "  validation loss:\t\t0.17\n",
      "151.221071979\n",
      "Epoch 101 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.150086\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 102 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.153261\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 103 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.149425\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 104 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.143728\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 105 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.142744\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 106 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.146363\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 107 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.133917\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 108 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.133893\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 109 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.129399\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 110 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.130507\n",
      "  validation loss:\t\t0.15\n",
      "128.479631363\n",
      "Epoch 111 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.127628\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 112 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.126397\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 113 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.125986\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 114 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.123039\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 115 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.128599\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 116 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.125178\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 117 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.125090\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 118 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.124812\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 119 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.121519\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 120 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.119956\n",
      "  validation loss:\t\t0.14\n",
      "120.393272646\n",
      "Epoch 121 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.121251\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 122 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.117493\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 123 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.118023\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 124 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.113074\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 125 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.116887\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 126 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.118815\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 127 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.114533\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 128 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.115657\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 129 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.114673\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 130 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.114512\n",
      "  validation loss:\t\t0.13\n",
      "113.04364593\n",
      "Epoch 131 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.111266\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 132 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.112140\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 133 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.111718\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 134 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.112589\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 135 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.108453\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 136 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.110082\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 137 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.108248\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 138 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.111698\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 139 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.105748\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 140 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.108736\n",
      "  validation loss:\t\t0.12\n",
      "106.51146537\n",
      "Epoch 141 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.106368\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 142 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.107822\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 143 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.101460\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 144 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.106935\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 145 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.106495\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 146 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.104844\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 147 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.105843\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 148 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.103038\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 149 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.100933\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 150 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.100722\n",
      "  validation loss:\t\t0.12\n",
      "100.457656042\n",
      "Epoch 151 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.099817\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 152 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.104158\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 153 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.098632\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 154 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.100908\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 155 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.098425\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 156 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.100065\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 157 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.101009\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 158 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.097084\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 159 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.098188\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 160 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.095956\n",
      "  validation loss:\t\t0.12\n",
      "97.9751979382\n",
      "Epoch 161 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.099609\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 162 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.097199\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 163 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.095626\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 164 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.095147\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 165 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.093277\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 166 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.094508\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 167 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.095997\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 168 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.091706\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 169 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.091650\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 170 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.093358\n",
      "  validation loss:\t\t0.10\n",
      "88.9827010364\n",
      "Epoch 171 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.089679\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 172 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.093238\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 173 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.091195\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 174 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.090859\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 175 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.089116\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 176 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.091186\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 177 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.087201\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 178 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.089807\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 179 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.088937\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 180 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.088463\n",
      "  validation loss:\t\t0.10\n",
      "88.3735481242\n",
      "Epoch 181 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.088255\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 182 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.086929\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 183 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.087029\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 184 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.086822\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 185 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.085831\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 186 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.085306\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 187 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.084300\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 188 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.084415\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 189 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.086491\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 190 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.081804\n",
      "  validation loss:\t\t0.10\n",
      "82.8778510808\n",
      "Epoch 191 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.083868\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 192 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.084593\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 193 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.083294\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 194 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.082077\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 195 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.081956\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 196 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.081932\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 197 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.081602\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 198 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.081143\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 199 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.081598\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 200 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.080933\n",
      "  validation loss:\t\t0.10\n",
      "82.9407585159\n",
      "Epoch 201 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.081023\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 202 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.081608\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 203 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.081797\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 204 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.079912\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 205 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.077794\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 206 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.079874\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 207 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.079842\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 208 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.078783\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 209 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.079183\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 210 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.078672\n",
      "  validation loss:\t\t0.09\n",
      "78.5202896674\n",
      "Epoch 211 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.078266\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 212 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.077310\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 213 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.078302\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 214 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.078101\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 215 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.078379\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 216 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.076408\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 217 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.077894\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 218 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.077600\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 219 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.078127\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 220 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.076352\n",
      "  validation loss:\t\t0.09\n",
      "78.233733112\n",
      "Epoch 221 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.076848\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 222 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.077814\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 223 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.074933\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 224 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.075965\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 225 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.076316\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 226 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.075675\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 227 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.076238\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 228 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.074559\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 229 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.074050\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 230 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.074305\n",
      "  validation loss:\t\t0.09\n",
      "74.2423700791\n",
      "Epoch 231 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.074750\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 232 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.074995\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 233 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.073846\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 234 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.073781\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 235 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.074138\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 236 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.074523\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 237 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.073448\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 238 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.074111\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 239 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.072955\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 240 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.073042\n",
      "  validation loss:\t\t0.08\n",
      "72.1825099915\n",
      "Epoch 241 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.072958\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 242 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.071602\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 243 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.072389\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 244 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.071149\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 245 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.072541\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 246 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.070911\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 247 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.071602\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 248 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.071266\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 249 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.070477\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 250 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.071035\n",
      "  validation loss:\t\t0.08\n",
      "70.1549036004\n",
      "Epoch 251 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.071965\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 252 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.070486\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 253 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.070962\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 254 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.070481\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 255 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.069238\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 256 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.069556\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 257 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.068668\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 258 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.069471\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 259 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.070026\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 260 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.069798\n",
      "  validation loss:\t\t0.08\n",
      "68.6463586625\n",
      "Epoch 261 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.068787\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 262 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.069024\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 263 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.068067\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 264 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.069042\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 265 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.067126\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 266 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.066956\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 267 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.067607\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 268 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.066836\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 269 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.067690\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 270 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.065879\n",
      "  validation loss:\t\t0.08\n",
      "65.7554830702\n",
      "Epoch 271 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.066776\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 272 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.067237\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 273 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.067116\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 274 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.066948\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 275 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.065641\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 276 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.065744\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 277 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.066189\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 278 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.063888\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 279 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.065806\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 280 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.065298\n",
      "  validation loss:\t\t0.08\n",
      "65.607110365\n",
      "Epoch 281 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.064886\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 282 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.065565\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 283 of 500 took 0.250s\n",
      "  training loss (in-iteration):\t\t0.063834\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 284 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.063997\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 285 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.063585\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 286 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.064038\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 287 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.063349\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 288 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.063091\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 289 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.063596\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 290 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.063499\n",
      "  validation loss:\t\t0.07\n",
      "62.3410195174\n",
      "Epoch 291 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.061524\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 292 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.062915\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 293 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.062508\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 294 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.062799\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 295 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.061165\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 296 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.062320\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 297 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.062140\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 298 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.060800\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 299 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.061587\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 300 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.061284\n",
      "  validation loss:\t\t0.07\n",
      "61.1934336534\n",
      "Epoch 301 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.061641\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 302 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.060681\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 303 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.059649\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 304 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.060685\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 305 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.060493\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 306 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.059351\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 307 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.059382\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 308 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.059253\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 309 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.058391\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 310 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.058955\n",
      "  validation loss:\t\t0.07\n",
      "57.7750613488\n",
      "Epoch 311 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.058600\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 312 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.059018\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 313 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.058463\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 314 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.058179\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 315 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.057757\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 316 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.057478\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 317 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.056384\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 318 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.057971\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 319 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.055711\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 320 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.056943\n",
      "  validation loss:\t\t0.06\n",
      "55.2110764683\n",
      "Epoch 321 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.057482\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 322 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.056994\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 323 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.056911\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 324 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.056451\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 325 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.055342\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 326 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.055442\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 327 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.054703\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 328 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.055238\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 329 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.055391\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 330 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.055459\n",
      "  validation loss:\t\t0.06\n",
      "55.4128378659\n",
      "Epoch 331 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.054947\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 332 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.055160\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 333 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.054709\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 334 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.055410\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 335 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.054459\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 336 of 500 took 0.242s\n",
      "  training loss (in-iteration):\t\t0.054156\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 337 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.054353\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 338 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.054247\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 339 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.053147\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 340 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.053225\n",
      "  validation loss:\t\t0.06\n",
      "52.9186807088\n",
      "Epoch 341 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.053266\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 342 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.052540\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 343 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.053474\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 344 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.053568\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 345 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.051945\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 346 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.053105\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 347 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.050315\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 348 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.051510\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 349 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.051684\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 350 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.052335\n",
      "  validation loss:\t\t0.06\n",
      "50.8473407246\n",
      "Epoch 351 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.051123\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 352 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.051036\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 353 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.050599\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 354 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.050821\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 355 of 500 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.051156\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 356 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.050977\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 357 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.050195\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 358 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.050188\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 359 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.050161\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 360 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.050659\n",
      "  validation loss:\t\t0.06\n",
      "49.1004661092\n",
      "Epoch 361 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.049187\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 362 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.050014\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 363 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.050278\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 364 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.049584\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 365 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.048150\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 366 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.048957\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 367 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.049397\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 368 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.049846\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 369 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.048839\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 370 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.047399\n",
      "  validation loss:\t\t0.05\n",
      "47.7103246087\n",
      "Epoch 371 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.048025\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 372 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.047927\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 373 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.047322\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 374 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.048974\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 375 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.048249\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 376 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.047154\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 377 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.047882\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 378 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.047273\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 379 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.046641\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 380 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.046980\n",
      "  validation loss:\t\t0.05\n",
      "46.8079121237\n",
      "Epoch 381 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.047192\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 382 of 500 took 0.214s\n",
      "  training loss (in-iteration):\t\t0.047781\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 383 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.046245\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 384 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.047188\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 385 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.046689\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 386 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.046757\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 387 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.046181\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 388 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.046353\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 389 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.046566\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 390 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.045751\n",
      "  validation loss:\t\t0.05\n",
      "45.617000241\n",
      "Epoch 391 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.045769\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 392 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.046261\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 393 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.044751\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 394 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.046173\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 395 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.046070\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 396 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.045154\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 397 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.044747\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 398 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.045724\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 399 of 500 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.045751\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 400 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.044547\n",
      "  validation loss:\t\t0.05\n",
      "44.2794222251\n",
      "Epoch 401 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.044238\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 402 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.045374\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 403 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.045981\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 404 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.045593\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 405 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.044609\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 406 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.044692\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 407 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.044909\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 408 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.045273\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 409 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.044464\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 410 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.045370\n",
      "  validation loss:\t\t0.05\n",
      "44.4907779107\n",
      "Epoch 411 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.044410\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 412 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.044997\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 413 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.043303\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 414 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.043963\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 415 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.044348\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 416 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.043212\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 417 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.043231\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 418 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.043847\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 419 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.044001\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 420 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.043307\n",
      "  validation loss:\t\t0.05\n",
      "43.5993712921\n",
      "Epoch 421 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.043914\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 422 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.044406\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 423 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.043820\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 424 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.042718\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 425 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.042649\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 426 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.043901\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 427 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.043072\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 428 of 500 took 0.254s\n",
      "  training loss (in-iteration):\t\t0.042036\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 429 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.042253\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 430 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.042384\n",
      "  validation loss:\t\t0.05\n",
      "42.8209896925\n",
      "Epoch 431 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.043138\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 432 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.041920\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 433 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.042011\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 434 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.042260\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 435 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.041929\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 436 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.041858\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 437 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.042840\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 438 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.042699\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 439 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.040862\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 440 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.041223\n",
      "  validation loss:\t\t0.05\n",
      "41.5759211234\n",
      "Epoch 441 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.041912\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 442 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.041598\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 443 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.041537\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 444 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.041097\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 445 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.041163\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 446 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.041705\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 447 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.041270\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 448 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.041437\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 449 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.041415\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 450 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.041773\n",
      "  validation loss:\t\t0.05\n",
      "42.8684910442\n",
      "Epoch 451 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.042105\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 452 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.041763\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 453 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.041651\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 454 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.041925\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 455 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.041268\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 456 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.041542\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 457 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.039456\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 458 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.039682\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 459 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.039931\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 460 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.040258\n",
      "  validation loss:\t\t0.05\n",
      "40.1195170296\n",
      "Epoch 461 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.040317\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 462 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.040382\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 463 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.039863\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 464 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.040199\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 465 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.039625\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 466 of 500 took 0.208s\n",
      "  training loss (in-iteration):\t\t0.039366\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 467 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.039922\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 468 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.039895\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 469 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.039008\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 470 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.039559\n",
      "  validation loss:\t\t0.05\n",
      "39.7466863717\n",
      "Epoch 471 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.039296\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 472 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.039001\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 473 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.039764\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 474 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.039285\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 475 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.039444\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 476 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.039120\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 477 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.039200\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 478 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.038387\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 479 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.038986\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 480 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.037906\n",
      "  validation loss:\t\t0.04\n",
      "38.6084626348\n",
      "Epoch 481 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.038316\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 482 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.038477\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 483 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.038403\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 484 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.037956\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 485 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.038837\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 486 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.038119\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 487 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.038002\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 488 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.038699\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 489 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.038544\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 490 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.037942\n",
      "  validation loss:\t\t0.04\n",
      "37.6531152081\n",
      "Epoch 491 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.037529\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 492 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.037706\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 493 of 500 took 0.190s\n",
      "  training loss (in-iteration):\t\t0.038284\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 494 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.037405\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 495 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.038285\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 496 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.037138\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 497 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.037637\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 498 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.037257\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 499 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.038534\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 500 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.036816\n",
      "  validation loss:\t\t0.04\n",
      "49692.7380869\n",
      "Epoch 1 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t5.874695\n",
      "  validation loss:\t\t4.08\n",
      "Epoch 2 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t5.530644\n",
      "  validation loss:\t\t4.01\n",
      "Epoch 3 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t5.187123\n",
      "  validation loss:\t\t3.93\n",
      "Epoch 4 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t5.095205\n",
      "  validation loss:\t\t3.89\n",
      "Epoch 5 of 120 took 0.073s\n",
      "  training loss (in-iteration):\t\t5.035795\n",
      "  validation loss:\t\t3.79\n",
      "Epoch 6 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t5.010640\n",
      "  validation loss:\t\t3.83\n",
      "Epoch 7 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t4.930841\n",
      "  validation loss:\t\t3.73\n",
      "Epoch 8 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.937340\n",
      "  validation loss:\t\t3.71\n",
      "Epoch 9 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t4.821358\n",
      "  validation loss:\t\t3.68\n",
      "Epoch 10 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t4.753500\n",
      "  validation loss:\t\t3.59\n",
      "37565.6006027\n",
      "Epoch 11 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t4.796118\n",
      "  validation loss:\t\t3.56\n",
      "Epoch 12 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t4.668138\n",
      "  validation loss:\t\t3.59\n",
      "Epoch 13 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t4.609821\n",
      "  validation loss:\t\t3.47\n",
      "Epoch 14 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t4.584130\n",
      "  validation loss:\t\t3.43\n",
      "Epoch 15 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t4.513727\n",
      "  validation loss:\t\t3.41\n",
      "Epoch 16 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t4.467557\n",
      "  validation loss:\t\t3.38\n",
      "Epoch 17 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t4.430433\n",
      "  validation loss:\t\t3.36\n",
      "Epoch 18 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t4.375562\n",
      "  validation loss:\t\t3.28\n",
      "Epoch 19 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t4.346921\n",
      "  validation loss:\t\t3.25\n",
      "Epoch 20 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t4.299462\n",
      "  validation loss:\t\t3.22\n",
      "33950.5656042\n",
      "Epoch 21 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t4.400794\n",
      "  validation loss:\t\t3.19\n",
      "Epoch 22 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t4.215148\n",
      "  validation loss:\t\t3.16\n",
      "Epoch 23 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t4.153896\n",
      "  validation loss:\t\t3.13\n",
      "Epoch 24 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.118510\n",
      "  validation loss:\t\t3.11\n",
      "Epoch 25 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t4.086881\n",
      "  validation loss:\t\t3.08\n",
      "Epoch 26 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t4.049073\n",
      "  validation loss:\t\t3.08\n",
      "Epoch 27 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t4.023460\n",
      "  validation loss:\t\t3.00\n",
      "Epoch 28 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t3.989390\n",
      "  validation loss:\t\t3.00\n",
      "Epoch 29 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.919891\n",
      "  validation loss:\t\t2.95\n",
      "Epoch 30 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.905118\n",
      "  validation loss:\t\t2.93\n",
      "30801.7037876\n",
      "Epoch 31 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t3.940634\n",
      "  validation loss:\t\t2.92\n",
      "Epoch 32 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.829813\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 33 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.780755\n",
      "  validation loss:\t\t2.85\n",
      "Epoch 34 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t3.754512\n",
      "  validation loss:\t\t2.83\n",
      "Epoch 35 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t3.718091\n",
      "  validation loss:\t\t2.81\n",
      "Epoch 36 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.688516\n",
      "  validation loss:\t\t2.80\n",
      "Epoch 37 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t3.669319\n",
      "  validation loss:\t\t2.78\n",
      "Epoch 38 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t3.624544\n",
      "  validation loss:\t\t2.72\n",
      "Epoch 39 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.591821\n",
      "  validation loss:\t\t2.71\n",
      "Epoch 40 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t3.566883\n",
      "  validation loss:\t\t2.69\n",
      "28108.5828323\n",
      "Epoch 41 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.686316\n",
      "  validation loss:\t\t2.65\n",
      "Epoch 42 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t3.494465\n",
      "  validation loss:\t\t2.62\n",
      "Epoch 43 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t3.451316\n",
      "  validation loss:\t\t2.62\n",
      "Epoch 44 of 120 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.404102\n",
      "  validation loss:\t\t2.60\n",
      "Epoch 45 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t3.389802\n",
      "  validation loss:\t\t2.59\n",
      "Epoch 46 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t3.371994\n",
      "  validation loss:\t\t2.53\n",
      "Epoch 47 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.337079\n",
      "  validation loss:\t\t2.52\n",
      "Epoch 48 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t3.308892\n",
      "  validation loss:\t\t2.49\n",
      "Epoch 49 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t3.269091\n",
      "  validation loss:\t\t2.50\n",
      "Epoch 50 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.238493\n",
      "  validation loss:\t\t2.46\n",
      "25558.6528026\n",
      "Epoch 51 of 120 took 0.103s\n",
      "  training loss (in-iteration):\t\t3.335576\n",
      "  validation loss:\t\t2.43\n",
      "Epoch 52 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.188502\n",
      "  validation loss:\t\t2.40\n",
      "Epoch 53 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.151501\n",
      "  validation loss:\t\t2.39\n",
      "Epoch 54 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t3.136279\n",
      "  validation loss:\t\t2.37\n",
      "Epoch 55 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.106392\n",
      "  validation loss:\t\t2.36\n",
      "Epoch 56 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.068682\n",
      "  validation loss:\t\t2.34\n",
      "Epoch 57 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t3.061450\n",
      "  validation loss:\t\t2.30\n",
      "Epoch 58 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t3.029977\n",
      "  validation loss:\t\t2.29\n",
      "Epoch 59 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.988975\n",
      "  validation loss:\t\t2.28\n",
      "Epoch 60 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.975384\n",
      "  validation loss:\t\t2.25\n",
      "23376.1427442\n",
      "Epoch 61 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.058465\n",
      "  validation loss:\t\t2.26\n",
      "Epoch 62 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t2.911024\n",
      "  validation loss:\t\t2.21\n",
      "Epoch 63 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.876254\n",
      "  validation loss:\t\t2.19\n",
      "Epoch 64 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.877497\n",
      "  validation loss:\t\t2.17\n",
      "Epoch 65 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.840967\n",
      "  validation loss:\t\t2.15\n",
      "Epoch 66 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.819749\n",
      "  validation loss:\t\t2.15\n",
      "Epoch 67 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.824574\n",
      "  validation loss:\t\t2.15\n",
      "Epoch 68 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.783660\n",
      "  validation loss:\t\t2.12\n",
      "Epoch 69 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.765094\n",
      "  validation loss:\t\t2.10\n",
      "Epoch 70 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.718271\n",
      "  validation loss:\t\t2.08\n",
      "21616.5396854\n",
      "Epoch 71 of 120 took 0.103s\n",
      "  training loss (in-iteration):\t\t2.845455\n",
      "  validation loss:\t\t2.09\n",
      "Epoch 72 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.690069\n",
      "  validation loss:\t\t2.04\n",
      "Epoch 73 of 120 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.659678\n",
      "  validation loss:\t\t2.03\n",
      "Epoch 74 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.630246\n",
      "  validation loss:\t\t2.03\n",
      "Epoch 75 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.605181\n",
      "  validation loss:\t\t2.01\n",
      "Epoch 76 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.600970\n",
      "  validation loss:\t\t2.00\n",
      "Epoch 77 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t2.579797\n",
      "  validation loss:\t\t2.00\n",
      "Epoch 78 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t2.541193\n",
      "  validation loss:\t\t1.96\n",
      "Epoch 79 of 120 took 0.074s\n",
      "  training loss (in-iteration):\t\t2.528189\n",
      "  validation loss:\t\t1.96\n",
      "Epoch 80 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.508619\n",
      "  validation loss:\t\t1.93\n",
      "19824.8111879\n",
      "Epoch 81 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.588347\n",
      "  validation loss:\t\t1.91\n",
      "Epoch 82 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.460873\n",
      "  validation loss:\t\t1.89\n",
      "Epoch 83 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t2.443896\n",
      "  validation loss:\t\t1.89\n",
      "Epoch 84 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.412686\n",
      "  validation loss:\t\t1.87\n",
      "Epoch 85 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t2.397986\n",
      "  validation loss:\t\t1.88\n",
      "Epoch 86 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.385593\n",
      "  validation loss:\t\t1.86\n",
      "Epoch 87 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.385341\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 88 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.370956\n",
      "  validation loss:\t\t1.82\n",
      "Epoch 89 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.326067\n",
      "  validation loss:\t\t1.82\n",
      "Epoch 90 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.303845\n",
      "  validation loss:\t\t1.80\n",
      "18139.608596\n",
      "Epoch 91 of 120 took 0.101s\n",
      "  training loss (in-iteration):\t\t2.431961\n",
      "  validation loss:\t\t1.81\n",
      "Epoch 92 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.272528\n",
      "  validation loss:\t\t1.76\n",
      "Epoch 93 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.229740\n",
      "  validation loss:\t\t1.76\n",
      "Epoch 94 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t2.238870\n",
      "  validation loss:\t\t1.76\n",
      "Epoch 95 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.213796\n",
      "  validation loss:\t\t1.74\n",
      "Epoch 96 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.198117\n",
      "  validation loss:\t\t1.72\n",
      "Epoch 97 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.170763\n",
      "  validation loss:\t\t1.71\n",
      "Epoch 98 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.175723\n",
      "  validation loss:\t\t1.71\n",
      "Epoch 99 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.151397\n",
      "  validation loss:\t\t1.69\n",
      "Epoch 100 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.125428\n",
      "  validation loss:\t\t1.67\n",
      "16657.287555\n",
      "Epoch 101 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.171525\n",
      "  validation loss:\t\t1.68\n",
      "Epoch 102 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t2.109189\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 103 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.070352\n",
      "  validation loss:\t\t1.64\n",
      "Epoch 104 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.076763\n",
      "  validation loss:\t\t1.64\n",
      "Epoch 105 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t2.039826\n",
      "  validation loss:\t\t1.63\n",
      "Epoch 106 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.057523\n",
      "  validation loss:\t\t1.62\n",
      "Epoch 107 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.033991\n",
      "  validation loss:\t\t1.61\n",
      "Epoch 108 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.006976\n",
      "  validation loss:\t\t1.60\n",
      "Epoch 109 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.001545\n",
      "  validation loss:\t\t1.57\n",
      "Epoch 110 of 120 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.974157\n",
      "  validation loss:\t\t1.59\n",
      "15587.3802982\n",
      "Epoch 111 of 120 took 0.120s\n",
      "  training loss (in-iteration):\t\t2.108200\n",
      "  validation loss:\t\t1.59\n",
      "Epoch 112 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.953016\n",
      "  validation loss:\t\t1.55\n",
      "Epoch 113 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t1.912608\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 114 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.910812\n",
      "  validation loss:\t\t1.54\n",
      "Epoch 115 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t1.910918\n",
      "  validation loss:\t\t1.53\n",
      "Epoch 116 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.882973\n",
      "  validation loss:\t\t1.52\n",
      "Epoch 117 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t1.880337\n",
      "  validation loss:\t\t1.51\n",
      "Epoch 118 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.866488\n",
      "  validation loss:\t\t1.50\n",
      "Epoch 119 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.855539\n",
      "  validation loss:\t\t1.48\n",
      "Epoch 120 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t1.839327\n",
      "  validation loss:\t\t1.48\n",
      "30783.9263246\n",
      "Epoch 1 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t30.677795\n",
      "  validation loss:\t\t93.52\n",
      "Epoch 2 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t29.733255\n",
      "  validation loss:\t\t91.44\n",
      "Epoch 3 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t29.513673\n",
      "  validation loss:\t\t90.19\n",
      "Epoch 4 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t29.666122\n",
      "  validation loss:\t\t89.02\n",
      "Epoch 5 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t28.508530\n",
      "  validation loss:\t\t86.07\n",
      "Epoch 6 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t27.117957\n",
      "  validation loss:\t\t84.92\n",
      "Epoch 7 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t26.710184\n",
      "  validation loss:\t\t80.67\n",
      "Epoch 8 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t24.978583\n",
      "  validation loss:\t\t76.23\n",
      "Epoch 9 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t22.937574\n",
      "  validation loss:\t\t64.66\n",
      "Epoch 10 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t17.619845\n",
      "  validation loss:\t\t42.64\n",
      "13075.6171021\n",
      "Epoch 11 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t7.871598\n",
      "  validation loss:\t\t12.19\n",
      "Epoch 12 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t3.284556\n",
      "  validation loss:\t\t7.94\n",
      "Epoch 13 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t2.618784\n",
      "  validation loss:\t\t4.38\n",
      "Epoch 14 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t1.980649\n",
      "  validation loss:\t\t3.96\n",
      "Epoch 15 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t1.703594\n",
      "  validation loss:\t\t3.20\n",
      "Epoch 16 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t1.341353\n",
      "  validation loss:\t\t2.07\n",
      "Epoch 17 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.940941\n",
      "  validation loss:\t\t1.44\n",
      "Epoch 18 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.715413\n",
      "  validation loss:\t\t1.02\n",
      "Epoch 19 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.475139\n",
      "  validation loss:\t\t1.38\n",
      "Epoch 20 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.620832\n",
      "  validation loss:\t\t1.23\n",
      "586.875678129\n",
      "Epoch 21 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.601100\n",
      "  validation loss:\t\t0.71\n",
      "Epoch 22 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.364467\n",
      "  validation loss:\t\t0.77\n",
      "Epoch 23 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.445654\n",
      "  validation loss:\t\t0.49\n",
      "Epoch 24 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.320825\n",
      "  validation loss:\t\t0.46\n",
      "Epoch 25 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.323457\n",
      "  validation loss:\t\t0.47\n",
      "Epoch 26 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.321024\n",
      "  validation loss:\t\t0.50\n",
      "Epoch 27 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.333636\n",
      "  validation loss:\t\t0.54\n",
      "Epoch 28 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.381643\n",
      "  validation loss:\t\t0.41\n",
      "Epoch 29 of 500 took 0.247s\n",
      "  training loss (in-iteration):\t\t0.288903\n",
      "  validation loss:\t\t0.40\n",
      "Epoch 30 of 500 took 0.249s\n",
      "  training loss (in-iteration):\t\t0.293206\n",
      "  validation loss:\t\t0.44\n",
      "303.212534041\n",
      "Epoch 31 of 500 took 0.241s\n",
      "  training loss (in-iteration):\t\t0.298286\n",
      "  validation loss:\t\t0.41\n",
      "Epoch 32 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.300086\n",
      "  validation loss:\t\t0.39\n",
      "Epoch 33 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.286939\n",
      "  validation loss:\t\t0.39\n",
      "Epoch 34 of 500 took 0.220s\n",
      "  training loss (in-iteration):\t\t0.287883\n",
      "  validation loss:\t\t0.37\n",
      "Epoch 35 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.278139\n",
      "  validation loss:\t\t0.39\n",
      "Epoch 36 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.284981\n",
      "  validation loss:\t\t0.37\n",
      "Epoch 37 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.275098\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 38 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.270296\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 39 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.271194\n",
      "  validation loss:\t\t0.37\n",
      "Epoch 40 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.269809\n",
      "  validation loss:\t\t0.36\n",
      "267.852449314\n",
      "Epoch 41 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.266468\n",
      "  validation loss:\t\t0.37\n",
      "Epoch 42 of 500 took 0.228s\n",
      "  training loss (in-iteration):\t\t0.265553\n",
      "  validation loss:\t\t0.38\n",
      "Epoch 43 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.268525\n",
      "  validation loss:\t\t0.35\n",
      "Epoch 44 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.261314\n",
      "  validation loss:\t\t0.35\n",
      "Epoch 45 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.259822\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 46 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.257807\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 47 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.255139\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 48 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.254220\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 49 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.254554\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 50 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.251048\n",
      "  validation loss:\t\t0.33\n",
      "249.423603017\n",
      "Epoch 51 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.250102\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 52 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.246106\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 53 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.245581\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 54 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.241694\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 55 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.243339\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 56 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.238531\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 57 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.239272\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 58 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.238570\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 59 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.234282\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 60 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.232410\n",
      "  validation loss:\t\t0.31\n",
      "231.2855999\n",
      "Epoch 61 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.230055\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 62 of 500 took 0.209s\n",
      "  training loss (in-iteration):\t\t0.227886\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 63 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.226126\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 64 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.224010\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 65 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.221990\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 66 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.220600\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 67 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.218667\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 68 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.216523\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 69 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.215357\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 70 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.212615\n",
      "  validation loss:\t\t0.28\n",
      "210.970257424\n",
      "Epoch 71 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.209872\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 72 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.207283\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 73 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.205523\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 74 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.204510\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 75 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.201600\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 76 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.199747\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 77 of 500 took 0.216s\n",
      "  training loss (in-iteration):\t\t0.198443\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 78 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.196511\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 79 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.196106\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 80 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.195495\n",
      "  validation loss:\t\t0.26\n",
      "191.412814917\n",
      "Epoch 81 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.191188\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 82 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.188601\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 83 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.186408\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 84 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.186501\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 85 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.183878\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 86 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.182794\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 87 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.181247\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 88 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.177790\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 89 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.176144\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 90 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.172504\n",
      "  validation loss:\t\t0.23\n",
      "172.432842805\n",
      "Epoch 91 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.170577\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 92 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.169775\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 93 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.165298\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 94 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.163440\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 95 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.161167\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 96 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.156761\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 97 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.154415\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 98 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.151251\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 99 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.147676\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 100 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.143879\n",
      "  validation loss:\t\t0.21\n",
      "145.76946994\n",
      "Epoch 101 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.140848\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 102 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.138331\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 103 of 500 took 0.237s\n",
      "  training loss (in-iteration):\t\t0.136057\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 104 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.130688\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 105 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.129227\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 106 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.130682\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 107 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.126491\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 108 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.125245\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 109 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.123378\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 110 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.118206\n",
      "  validation loss:\t\t0.17\n",
      "118.101618701\n",
      "Epoch 111 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.117854\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 112 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.114979\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 113 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.114853\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 114 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.115232\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 115 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.114320\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 116 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.106775\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 117 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.104861\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 118 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.106682\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 119 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.108417\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 120 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.107493\n",
      "  validation loss:\t\t0.15\n",
      "106.465976946\n",
      "Epoch 121 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.104043\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 122 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.102578\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 123 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.102397\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 124 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.102646\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 125 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.100823\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 126 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.099798\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 127 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.097959\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 128 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.094735\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 129 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.094246\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 130 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.096642\n",
      "  validation loss:\t\t0.14\n",
      "96.5505544291\n",
      "Epoch 131 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.097184\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 132 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.095286\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 133 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.094370\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 134 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.092575\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 135 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.090031\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 136 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.089793\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 137 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.091388\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 138 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.090326\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 139 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.090466\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 140 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.091072\n",
      "  validation loss:\t\t0.12\n",
      "88.5926032581\n",
      "Epoch 141 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.088072\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 142 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.088070\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 143 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.087821\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 144 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.087207\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 145 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.085232\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 146 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.085254\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 147 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.084957\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 148 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.084469\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 149 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.082304\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 150 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.082430\n",
      "  validation loss:\t\t0.11\n",
      "82.4434992457\n",
      "Epoch 151 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.082671\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 152 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.081714\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 153 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.083236\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 154 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.080625\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 155 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.080815\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 156 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.080450\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 157 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.079436\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 158 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.078570\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 159 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.078214\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 160 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.078637\n",
      "  validation loss:\t\t0.11\n",
      "78.7990905266\n",
      "Epoch 161 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.077692\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 162 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.075790\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 163 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.075615\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 164 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.075118\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 165 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.074612\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 166 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.075176\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 167 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.073627\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 168 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.074416\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 169 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.073359\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 170 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.073932\n",
      "  validation loss:\t\t0.10\n",
      "71.5660653136\n",
      "Epoch 171 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.071873\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 172 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.072368\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 173 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.072543\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 174 of 500 took 0.128s\n",
      "  training loss (in-iteration):\t\t0.071125\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 175 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.071409\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 176 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.070578\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 177 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.069969\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 178 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.069241\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 179 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.069274\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 180 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.069135\n",
      "  validation loss:\t\t0.10\n",
      "69.7804140672\n",
      "Epoch 181 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.068952\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 182 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.068613\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 183 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.069698\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 184 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.067370\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 185 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.067630\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 186 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.066983\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 187 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.067070\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 188 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.066238\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 189 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.066137\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 190 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.065709\n",
      "  validation loss:\t\t0.09\n",
      "65.3369287687\n",
      "Epoch 191 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.065523\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 192 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.065593\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 193 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.064517\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 194 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.065073\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 195 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.064115\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 196 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.064085\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 197 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.064114\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 198 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.062557\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 199 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.063087\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 200 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.063131\n",
      "  validation loss:\t\t0.09\n",
      "62.7012883588\n",
      "Epoch 201 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.062325\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 202 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.062795\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 203 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.062128\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 204 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.061220\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 205 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.060799\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 206 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.061704\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 207 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.060662\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 208 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.060991\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 209 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.061208\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 210 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.059146\n",
      "  validation loss:\t\t0.08\n",
      "59.5722519964\n",
      "Epoch 211 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.059950\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 212 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.060450\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 213 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.059903\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 214 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.058342\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 215 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.058807\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 216 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.058641\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 217 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.058711\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 218 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.057674\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 219 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.058176\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 220 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.057940\n",
      "  validation loss:\t\t0.08\n",
      "57.51031175\n",
      "Epoch 221 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.057018\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 222 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.057359\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 223 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.056394\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 224 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.057345\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 225 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.056682\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 226 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.056600\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 227 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.055891\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 228 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.055586\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 229 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.055393\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 230 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.055123\n",
      "  validation loss:\t\t0.08\n",
      "55.8389631154\n",
      "Epoch 231 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.055288\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 232 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.055374\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 233 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.055589\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 234 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.055400\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 235 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.054278\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 236 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.053358\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 237 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.054549\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 238 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.053359\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 239 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.054273\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 240 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.054272\n",
      "  validation loss:\t\t0.07\n",
      "53.9367341221\n",
      "Epoch 241 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.053440\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 242 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.053052\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 243 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.052900\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 244 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.052768\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 245 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.052233\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 246 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.052454\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 247 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.052757\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 248 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.052079\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 249 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.051403\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 250 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.051985\n",
      "  validation loss:\t\t0.07\n",
      "51.2253112655\n",
      "Epoch 251 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.052200\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 252 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.051659\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 253 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.051857\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 254 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.050495\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 255 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.050839\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 256 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.051242\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 257 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.051182\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 258 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.050195\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 259 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.050437\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 260 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.050388\n",
      "  validation loss:\t\t0.07\n",
      "50.6578301667\n",
      "Epoch 261 of 500 took 0.190s\n",
      "  training loss (in-iteration):\t\t0.049955\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 262 of 500 took 0.213s\n",
      "  training loss (in-iteration):\t\t0.049974\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 263 of 500 took 0.220s\n",
      "  training loss (in-iteration):\t\t0.049586\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 264 of 500 took 0.234s\n",
      "  training loss (in-iteration):\t\t0.048862\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 265 of 500 took 0.220s\n",
      "  training loss (in-iteration):\t\t0.049742\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 266 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.049314\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 267 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.048795\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 268 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.048831\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 269 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.048796\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 270 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.048484\n",
      "  validation loss:\t\t0.07\n",
      "49.3178997758\n",
      "Epoch 271 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.048110\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 272 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.048217\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 273 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.048065\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 274 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.047877\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 275 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.047927\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 276 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.047779\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 277 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.047865\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 278 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.047905\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 279 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.047436\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 280 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.047603\n",
      "  validation loss:\t\t0.06\n",
      "46.6180644419\n",
      "Epoch 281 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.046706\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 282 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.047160\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 283 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.046888\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 284 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.047304\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 285 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.046301\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 286 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.046385\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 287 of 500 took 0.218s\n",
      "  training loss (in-iteration):\t\t0.046166\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 288 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.045997\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 289 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.046189\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 290 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.045810\n",
      "  validation loss:\t\t0.06\n",
      "46.3960929615\n",
      "Epoch 291 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.046156\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 292 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.046544\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 293 of 500 took 0.259s\n",
      "  training loss (in-iteration):\t\t0.046002\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 294 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.045671\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 295 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.046410\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 296 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.045678\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 297 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.045529\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 298 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.044947\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 299 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.045045\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 300 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.045090\n",
      "  validation loss:\t\t0.06\n",
      "44.0568536208\n",
      "Epoch 301 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.044928\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 302 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.045090\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 303 of 500 took 0.207s\n",
      "  training loss (in-iteration):\t\t0.044291\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 304 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.044095\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 305 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.044944\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 306 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.044764\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 307 of 500 took 0.216s\n",
      "  training loss (in-iteration):\t\t0.044125\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 308 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.043875\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 309 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.044225\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 310 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.043269\n",
      "  validation loss:\t\t0.06\n",
      "43.7162680679\n",
      "Epoch 311 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.043401\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 312 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.043584\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 313 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.043894\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 314 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.043314\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 315 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.043203\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 316 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.043219\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 317 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.042477\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 318 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.042982\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 319 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.043255\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 320 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.042367\n",
      "  validation loss:\t\t0.06\n",
      "42.8154824097\n",
      "Epoch 321 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.042397\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 322 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.042689\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 323 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.042415\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 324 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.042529\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 325 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.042196\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 326 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.042297\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 327 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.041635\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 328 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.041743\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 329 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.041997\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 330 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.042508\n",
      "  validation loss:\t\t0.06\n",
      "42.2328799106\n",
      "Epoch 331 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.041687\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 332 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.041774\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 333 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.041804\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 334 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.041540\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 335 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.041976\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 336 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.041020\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 337 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.041101\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 338 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.040871\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 339 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.041112\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 340 of 500 took 0.225s\n",
      "  training loss (in-iteration):\t\t0.041312\n",
      "  validation loss:\t\t0.06\n",
      "40.630632916\n",
      "Epoch 341 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.040506\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 342 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.040698\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 343 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.040509\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 344 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.040747\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 345 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.040683\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 346 of 500 took 0.270s\n",
      "  training loss (in-iteration):\t\t0.040638\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 347 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.040525\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 348 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.040235\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 349 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.040367\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 350 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.040305\n",
      "  validation loss:\t\t0.06\n",
      "41.0329873493\n",
      "Epoch 351 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.040562\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 352 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.040040\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 353 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.039894\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 354 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.040351\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 355 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.039844\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 356 of 500 took 0.223s\n",
      "  training loss (in-iteration):\t\t0.039319\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 357 of 500 took 0.129s\n",
      "  training loss (in-iteration):\t\t0.039765\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 358 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.039619\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 359 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.039594\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 360 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.039503\n",
      "  validation loss:\t\t0.05\n",
      "38.7560132826\n",
      "Epoch 361 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.039090\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 362 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.039371\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 363 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.038985\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 364 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.039438\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 365 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.038981\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 366 of 500 took 0.266s\n",
      "  training loss (in-iteration):\t\t0.038909\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 367 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.038693\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 368 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.038996\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 369 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.038650\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 370 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.038385\n",
      "  validation loss:\t\t0.05\n",
      "39.218439334\n",
      "Epoch 371 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.038538\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 372 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.038733\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 373 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.039270\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 374 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.038045\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 375 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.038420\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 376 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.037889\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 377 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.038139\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 378 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.038006\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 379 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.037835\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 380 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.037282\n",
      "  validation loss:\t\t0.05\n",
      "37.1313742533\n",
      "Epoch 381 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.037670\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 382 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.038005\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 383 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.037652\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 384 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.037423\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 385 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.036988\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 386 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.036987\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 387 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.037451\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 388 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.037155\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 389 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.037181\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 390 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.037052\n",
      "  validation loss:\t\t0.05\n",
      "36.8978404978\n",
      "Epoch 391 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.036928\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 392 of 500 took 0.222s\n",
      "  training loss (in-iteration):\t\t0.037136\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 393 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.036775\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 394 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.036499\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 395 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.037081\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 396 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.036150\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 397 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.036325\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 398 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.035954\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 399 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.036380\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 400 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.036253\n",
      "  validation loss:\t\t0.05\n",
      "35.6728785606\n",
      "Epoch 401 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.036155\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 402 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.036089\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 403 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.035821\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 404 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.036555\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 405 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.035625\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 406 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.036048\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 407 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.035646\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 408 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.035840\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 409 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.035609\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 410 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.035601\n",
      "  validation loss:\t\t0.05\n",
      "36.0003451371\n",
      "Epoch 411 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.036046\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 412 of 500 took 0.130s\n",
      "  training loss (in-iteration):\t\t0.035136\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 413 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.035436\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 414 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.035181\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 415 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.035360\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 416 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.034268\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 417 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.034943\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 418 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.034750\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 419 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.034549\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 420 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.034996\n",
      "  validation loss:\t\t0.05\n",
      "34.4498352489\n",
      "Epoch 421 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.034553\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 422 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.034676\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 423 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.034832\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 424 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.034328\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 425 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.033913\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 426 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.034489\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 427 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.034731\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 428 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.034053\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 429 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.034569\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 430 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.033779\n",
      "  validation loss:\t\t0.05\n",
      "33.5956162784\n",
      "Epoch 431 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.033767\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 432 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.033959\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 433 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.033816\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 434 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.033153\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 435 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.033304\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 436 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.033903\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 437 of 500 took 0.218s\n",
      "  training loss (in-iteration):\t\t0.033615\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 438 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.033454\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 439 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.033284\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 440 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.033825\n",
      "  validation loss:\t\t0.05\n",
      "33.2752399702\n",
      "Epoch 441 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.033233\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 442 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.033223\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 443 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.033325\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 444 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.033554\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 445 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.033478\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 446 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.033150\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 447 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.032577\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 448 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.033290\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 449 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.032644\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 450 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.032613\n",
      "  validation loss:\t\t0.05\n",
      "32.8982003018\n",
      "Epoch 451 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.032812\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 452 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.032731\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 453 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.032491\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 454 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.032554\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 455 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.032356\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 456 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.032877\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 457 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.032151\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 458 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.032471\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 459 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.032286\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 460 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.032753\n",
      "  validation loss:\t\t0.05\n",
      "33.5344989978\n",
      "Epoch 461 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.032539\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 462 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.032288\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 463 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.031952\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 464 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.031868\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 465 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.032150\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 466 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.031562\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 467 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.031720\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 468 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.032026\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 469 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.031957\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 470 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.031234\n",
      "  validation loss:\t\t0.05\n",
      "31.7122672443\n",
      "Epoch 471 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.031667\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 472 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.031310\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 473 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.031500\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 474 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.031533\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 475 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.031559\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 476 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.031481\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 477 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.031163\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 478 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.030957\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 479 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.031083\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 480 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.031859\n",
      "  validation loss:\t\t0.04\n",
      "30.6467385645\n",
      "Epoch 481 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.030465\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 482 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.030383\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 483 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.030508\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 484 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.030592\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 485 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.030665\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 486 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.030315\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 487 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.030591\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 488 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.029987\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 489 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.030011\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 490 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.030256\n",
      "  validation loss:\t\t0.04\n",
      "30.4264389363\n",
      "Epoch 491 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.030315\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 492 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.030206\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 493 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.030233\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 494 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.030407\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 495 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.030060\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 496 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.029833\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 497 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.030105\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 498 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.029749\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 499 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.030003\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 500 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.029296\n",
      "  validation loss:\t\t0.04\n",
      "46945.1010386\n",
      "Epoch 1 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t5.497984\n",
      "  validation loss:\t\t4.07\n",
      "Epoch 2 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t5.336228\n",
      "  validation loss:\t\t4.00\n",
      "Epoch 3 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t5.255882\n",
      "  validation loss:\t\t3.94\n",
      "Epoch 4 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t5.166673\n",
      "  validation loss:\t\t3.90\n",
      "Epoch 5 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t5.114868\n",
      "  validation loss:\t\t3.88\n",
      "Epoch 6 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t5.000091\n",
      "  validation loss:\t\t3.80\n",
      "Epoch 7 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t4.933624\n",
      "  validation loss:\t\t3.74\n",
      "Epoch 8 of 120 took 0.072s\n",
      "  training loss (in-iteration):\t\t4.900543\n",
      "  validation loss:\t\t3.74\n",
      "Epoch 9 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t4.824481\n",
      "  validation loss:\t\t3.66\n",
      "Epoch 10 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t4.783248\n",
      "  validation loss:\t\t3.64\n",
      "37779.5430169\n",
      "Epoch 11 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t4.780533\n",
      "  validation loss:\t\t3.61\n",
      "Epoch 12 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t4.658871\n",
      "  validation loss:\t\t3.53\n",
      "Epoch 13 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t4.639095\n",
      "  validation loss:\t\t3.52\n",
      "Epoch 14 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t4.556369\n",
      "  validation loss:\t\t3.46\n",
      "Epoch 15 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t4.507168\n",
      "  validation loss:\t\t3.46\n",
      "Epoch 16 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t4.446443\n",
      "  validation loss:\t\t3.40\n",
      "Epoch 17 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t4.416431\n",
      "  validation loss:\t\t3.36\n",
      "Epoch 18 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t4.367061\n",
      "  validation loss:\t\t3.33\n",
      "Epoch 19 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t4.322862\n",
      "  validation loss:\t\t3.30\n",
      "Epoch 20 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t4.274679\n",
      "  validation loss:\t\t3.25\n",
      "33694.2684259\n",
      "Epoch 21 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t4.285306\n",
      "  validation loss:\t\t3.20\n",
      "Epoch 22 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t4.178823\n",
      "  validation loss:\t\t3.19\n",
      "Epoch 23 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t4.138224\n",
      "  validation loss:\t\t3.17\n",
      "Epoch 24 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t4.101209\n",
      "  validation loss:\t\t3.17\n",
      "Epoch 25 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t4.056577\n",
      "  validation loss:\t\t3.10\n",
      "Epoch 26 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t4.042724\n",
      "  validation loss:\t\t3.10\n",
      "Epoch 27 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.017617\n",
      "  validation loss:\t\t3.05\n",
      "Epoch 28 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t3.945180\n",
      "  validation loss:\t\t3.02\n",
      "Epoch 29 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t3.938359\n",
      "  validation loss:\t\t3.02\n",
      "Epoch 30 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.902159\n",
      "  validation loss:\t\t2.98\n",
      "30601.6123587\n",
      "Epoch 31 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t3.958922\n",
      "  validation loss:\t\t2.92\n",
      "Epoch 32 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.781433\n",
      "  validation loss:\t\t2.91\n",
      "Epoch 33 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.762684\n",
      "  validation loss:\t\t2.89\n",
      "Epoch 34 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t3.732843\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 35 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t3.698785\n",
      "  validation loss:\t\t2.84\n",
      "Epoch 36 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.655383\n",
      "  validation loss:\t\t2.83\n",
      "Epoch 37 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t3.627895\n",
      "  validation loss:\t\t2.80\n",
      "Epoch 38 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t3.606773\n",
      "  validation loss:\t\t2.78\n",
      "Epoch 39 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.569507\n",
      "  validation loss:\t\t2.78\n",
      "Epoch 40 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t3.542064\n",
      "  validation loss:\t\t2.72\n",
      "27807.801791\n",
      "Epoch 41 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t3.557053\n",
      "  validation loss:\t\t2.71\n",
      "Epoch 42 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t3.459441\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 43 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.426916\n",
      "  validation loss:\t\t2.66\n",
      "Epoch 44 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.399107\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 45 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t3.376923\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 46 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t3.348778\n",
      "  validation loss:\t\t2.61\n",
      "Epoch 47 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.322364\n",
      "  validation loss:\t\t2.58\n",
      "Epoch 48 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.283454\n",
      "  validation loss:\t\t2.56\n",
      "Epoch 49 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t3.265088\n",
      "  validation loss:\t\t2.52\n",
      "Epoch 50 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.233866\n",
      "  validation loss:\t\t2.53\n",
      "25458.2690717\n",
      "Epoch 51 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t3.306094\n",
      "  validation loss:\t\t2.51\n",
      "Epoch 52 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.192655\n",
      "  validation loss:\t\t2.48\n",
      "Epoch 53 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.127341\n",
      "  validation loss:\t\t2.46\n",
      "Epoch 54 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.102779\n",
      "  validation loss:\t\t2.43\n",
      "Epoch 55 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t3.097056\n",
      "  validation loss:\t\t2.41\n",
      "Epoch 56 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.054918\n",
      "  validation loss:\t\t2.40\n",
      "Epoch 57 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t3.054724\n",
      "  validation loss:\t\t2.38\n",
      "Epoch 58 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t3.003142\n",
      "  validation loss:\t\t2.37\n",
      "Epoch 59 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.979137\n",
      "  validation loss:\t\t2.36\n",
      "Epoch 60 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t2.949533\n",
      "  validation loss:\t\t2.32\n",
      "23222.5115575\n",
      "Epoch 61 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.004334\n",
      "  validation loss:\t\t2.30\n",
      "Epoch 62 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.901002\n",
      "  validation loss:\t\t2.29\n",
      "Epoch 63 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t2.854133\n",
      "  validation loss:\t\t2.28\n",
      "Epoch 64 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t2.866401\n",
      "  validation loss:\t\t2.27\n",
      "Epoch 65 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.851257\n",
      "  validation loss:\t\t2.25\n",
      "Epoch 66 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.803132\n",
      "  validation loss:\t\t2.23\n",
      "Epoch 67 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t2.790736\n",
      "  validation loss:\t\t2.21\n",
      "Epoch 68 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.757926\n",
      "  validation loss:\t\t2.21\n",
      "Epoch 69 of 120 took 0.102s\n",
      "  training loss (in-iteration):\t\t2.726172\n",
      "  validation loss:\t\t2.18\n",
      "Epoch 70 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.705233\n",
      "  validation loss:\t\t2.16\n",
      "21386.077815\n",
      "Epoch 71 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t2.771752\n",
      "  validation loss:\t\t2.16\n",
      "Epoch 72 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t2.660698\n",
      "  validation loss:\t\t2.13\n",
      "Epoch 73 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.624807\n",
      "  validation loss:\t\t2.13\n",
      "Epoch 74 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.623253\n",
      "  validation loss:\t\t2.10\n",
      "Epoch 75 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.584964\n",
      "  validation loss:\t\t2.10\n",
      "Epoch 76 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.566584\n",
      "  validation loss:\t\t2.07\n",
      "Epoch 77 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t2.550701\n",
      "  validation loss:\t\t2.07\n",
      "Epoch 78 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.514926\n",
      "  validation loss:\t\t2.06\n",
      "Epoch 79 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.509812\n",
      "  validation loss:\t\t2.03\n",
      "Epoch 80 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.486293\n",
      "  validation loss:\t\t2.02\n",
      "19498.3317827\n",
      "Epoch 81 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.539577\n",
      "  validation loss:\t\t2.00\n",
      "Epoch 82 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.430883\n",
      "  validation loss:\t\t2.01\n",
      "Epoch 83 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.422068\n",
      "  validation loss:\t\t1.99\n",
      "Epoch 84 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.404803\n",
      "  validation loss:\t\t1.97\n",
      "Epoch 85 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t2.402235\n",
      "  validation loss:\t\t1.97\n",
      "Epoch 86 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.366908\n",
      "  validation loss:\t\t1.96\n",
      "Epoch 87 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.353587\n",
      "  validation loss:\t\t1.94\n",
      "Epoch 88 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t2.351217\n",
      "  validation loss:\t\t1.93\n",
      "Epoch 89 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.310836\n",
      "  validation loss:\t\t1.91\n",
      "Epoch 90 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.290719\n",
      "  validation loss:\t\t1.91\n",
      "17980.5177987\n",
      "Epoch 91 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t2.430392\n",
      "  validation loss:\t\t1.90\n",
      "Epoch 92 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t2.253847\n",
      "  validation loss:\t\t1.88\n",
      "Epoch 93 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.229742\n",
      "  validation loss:\t\t1.88\n",
      "Epoch 94 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t2.223694\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 95 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.192465\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 96 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t2.176334\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 97 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t2.149154\n",
      "  validation loss:\t\t1.84\n",
      "Epoch 98 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.141323\n",
      "  validation loss:\t\t1.84\n",
      "Epoch 99 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.123581\n",
      "  validation loss:\t\t1.83\n",
      "Epoch 100 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t2.118468\n",
      "  validation loss:\t\t1.81\n",
      "16594.9850622\n",
      "Epoch 101 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.216128\n",
      "  validation loss:\t\t1.78\n",
      "Epoch 102 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.066060\n",
      "  validation loss:\t\t1.78\n",
      "Epoch 103 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t2.046806\n",
      "  validation loss:\t\t1.77\n",
      "Epoch 104 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.030172\n",
      "  validation loss:\t\t1.76\n",
      "Epoch 105 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.020410\n",
      "  validation loss:\t\t1.75\n",
      "Epoch 106 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t2.024672\n",
      "  validation loss:\t\t1.74\n",
      "Epoch 107 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t2.001227\n",
      "  validation loss:\t\t1.74\n",
      "Epoch 108 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.979285\n",
      "  validation loss:\t\t1.73\n",
      "Epoch 109 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t1.964577\n",
      "  validation loss:\t\t1.72\n",
      "Epoch 110 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.969863\n",
      "  validation loss:\t\t1.70\n",
      "15263.9176436\n",
      "Epoch 111 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t2.013018\n",
      "  validation loss:\t\t1.68\n",
      "Epoch 112 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t1.906671\n",
      "  validation loss:\t\t1.68\n",
      "Epoch 113 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t1.893895\n",
      "  validation loss:\t\t1.69\n",
      "Epoch 114 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t1.876815\n",
      "  validation loss:\t\t1.67\n",
      "Epoch 115 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t1.892639\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 116 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t1.858427\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 117 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t1.843645\n",
      "  validation loss:\t\t1.65\n",
      "Epoch 118 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.838522\n",
      "  validation loss:\t\t1.64\n",
      "Epoch 119 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.821355\n",
      "  validation loss:\t\t1.64\n",
      "Epoch 120 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t1.807164\n",
      "  validation loss:\t\t1.63\n",
      "50225.0700958\n",
      "Epoch 1 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t49.714001\n",
      "  validation loss:\t\t17.22\n",
      "Epoch 2 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t48.383576\n",
      "  validation loss:\t\t17.15\n",
      "Epoch 3 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t47.474739\n",
      "  validation loss:\t\t16.40\n",
      "Epoch 4 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t47.208288\n",
      "  validation loss:\t\t16.21\n",
      "Epoch 5 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t47.084977\n",
      "  validation loss:\t\t15.98\n",
      "Epoch 6 of 500 took 0.216s\n",
      "  training loss (in-iteration):\t\t44.889729\n",
      "  validation loss:\t\t15.32\n",
      "Epoch 7 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t42.742158\n",
      "  validation loss:\t\t14.67\n",
      "Epoch 8 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t40.835069\n",
      "  validation loss:\t\t13.05\n",
      "Epoch 9 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t33.104165\n",
      "  validation loss:\t\t8.13\n",
      "Epoch 10 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t15.650954\n",
      "  validation loss:\t\t2.89\n",
      "7355.54051003\n",
      "Epoch 11 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t7.335411\n",
      "  validation loss:\t\t2.71\n",
      "Epoch 12 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t5.448942\n",
      "  validation loss:\t\t1.85\n",
      "Epoch 13 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t3.815358\n",
      "  validation loss:\t\t4.01\n",
      "Epoch 14 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t3.784394\n",
      "  validation loss:\t\t1.89\n",
      "Epoch 15 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t2.494127\n",
      "  validation loss:\t\t1.98\n",
      "Epoch 16 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t2.381707\n",
      "  validation loss:\t\t1.81\n",
      "Epoch 17 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t2.227335\n",
      "  validation loss:\t\t1.92\n",
      "Epoch 18 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t2.270201\n",
      "  validation loss:\t\t1.78\n",
      "Epoch 19 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t2.171255\n",
      "  validation loss:\t\t1.80\n",
      "Epoch 20 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t2.104174\n",
      "  validation loss:\t\t1.74\n",
      "2043.43385299\n",
      "Epoch 21 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t2.061968\n",
      "  validation loss:\t\t1.61\n",
      "Epoch 22 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t2.021597\n",
      "  validation loss:\t\t1.58\n",
      "Epoch 23 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t1.926246\n",
      "  validation loss:\t\t1.60\n",
      "Epoch 24 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t1.912780\n",
      "  validation loss:\t\t1.52\n",
      "Epoch 25 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t1.823629\n",
      "  validation loss:\t\t1.64\n",
      "Epoch 26 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t1.730834\n",
      "  validation loss:\t\t1.35\n",
      "Epoch 27 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t1.554614\n",
      "  validation loss:\t\t1.10\n",
      "Epoch 28 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t1.358086\n",
      "  validation loss:\t\t0.98\n",
      "Epoch 29 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t1.138381\n",
      "  validation loss:\t\t0.74\n",
      "Epoch 30 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.879485\n",
      "  validation loss:\t\t0.58\n",
      "762.001708146\n",
      "Epoch 31 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.670620\n",
      "  validation loss:\t\t0.45\n",
      "Epoch 32 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.532521\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 33 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.447293\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 34 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.422270\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 35 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.361755\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 36 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.380034\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 37 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.406199\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 38 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.396399\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 39 of 500 took 0.216s\n",
      "  training loss (in-iteration):\t\t0.420577\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 40 of 500 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.326383\n",
      "  validation loss:\t\t0.29\n",
      "328.177218536\n",
      "Epoch 41 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.334287\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 42 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.322148\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 43 of 500 took 0.131s\n",
      "  training loss (in-iteration):\t\t0.333768\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 44 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.325409\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 45 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.337994\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 46 of 500 took 0.277s\n",
      "  training loss (in-iteration):\t\t0.327231\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 47 of 500 took 0.133s\n",
      "  training loss (in-iteration):\t\t0.327177\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 48 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.315545\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 49 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.302335\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 50 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.320186\n",
      "  validation loss:\t\t0.28\n",
      "323.451946312\n",
      "Epoch 51 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.317660\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 52 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.305281\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 53 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.302671\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 54 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.294479\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 55 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.308621\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 56 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.311244\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 57 of 500 took 0.127s\n",
      "  training loss (in-iteration):\t\t0.313328\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 58 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.286619\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 59 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.282490\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 60 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.280660\n",
      "  validation loss:\t\t0.26\n",
      "283.765142371\n",
      "Epoch 61 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.279120\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 62 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.275890\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 63 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.278267\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 64 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.277996\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 65 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.283382\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 66 of 500 took 0.238s\n",
      "  training loss (in-iteration):\t\t0.274441\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 67 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.277612\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 68 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.271405\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 69 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.268513\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 70 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.264867\n",
      "  validation loss:\t\t0.25\n",
      "264.82009868\n",
      "Epoch 71 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.262059\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 72 of 500 took 0.220s\n",
      "  training loss (in-iteration):\t\t0.261670\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 73 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.260993\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 74 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.258256\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 75 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.259072\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 76 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.256732\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 77 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.257343\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 78 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.254200\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 79 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.251394\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 80 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.249646\n",
      "  validation loss:\t\t0.23\n",
      "248.406508553\n",
      "Epoch 81 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.250668\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 82 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.246065\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 83 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.244841\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 84 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.240122\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 85 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.239519\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 86 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.235879\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 87 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.235721\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 88 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.235170\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 89 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.234749\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 90 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.227387\n",
      "  validation loss:\t\t0.22\n",
      "226.585202381\n",
      "Epoch 91 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.222825\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 92 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.222032\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 93 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.218664\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 94 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.218621\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 95 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.210699\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 96 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.210855\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 97 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.208214\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 98 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.213487\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 99 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.201922\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 100 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.199407\n",
      "  validation loss:\t\t0.19\n",
      "200.12749185\n",
      "Epoch 101 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.203173\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 102 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.192953\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 103 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.190305\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 104 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.194730\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 105 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.192989\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 106 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.191272\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 107 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.180380\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 108 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.180093\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 109 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.183207\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 110 of 500 took 0.219s\n",
      "  training loss (in-iteration):\t\t0.175302\n",
      "  validation loss:\t\t0.17\n",
      "177.814121755\n",
      "Epoch 111 of 500 took 0.222s\n",
      "  training loss (in-iteration):\t\t0.174941\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 112 of 500 took 0.268s\n",
      "  training loss (in-iteration):\t\t0.175346\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 113 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.167956\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 114 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.166505\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 115 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.165215\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 116 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.163796\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 117 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.162719\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 118 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.159188\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 119 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.158386\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 120 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.160147\n",
      "  validation loss:\t\t0.15\n",
      "151.075526393\n",
      "Epoch 121 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.157909\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 122 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.149947\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 123 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.152060\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 124 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.151012\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 125 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.150739\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 126 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.146040\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 127 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.146242\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 128 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.146105\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 129 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.141903\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 130 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.147154\n",
      "  validation loss:\t\t0.14\n",
      "148.724196288\n",
      "Epoch 131 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.141131\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 132 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.143354\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 133 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.145228\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 134 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.139006\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 135 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.139575\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 136 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.140014\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 137 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.142113\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 138 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.139146\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 139 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.132421\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 140 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.136089\n",
      "  validation loss:\t\t0.13\n",
      "133.105477909\n",
      "Epoch 141 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.133940\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 142 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.134055\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 143 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.134808\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 144 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.129360\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 145 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.128342\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 146 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.129007\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 147 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.127843\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 148 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.126336\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 149 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.129501\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 150 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.125532\n",
      "  validation loss:\t\t0.12\n",
      "127.633779527\n",
      "Epoch 151 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.127537\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 152 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.125403\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 153 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.120471\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 154 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.123770\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 155 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.119619\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 156 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.122257\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 157 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.118693\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 158 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.122285\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 159 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.117443\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 160 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.117620\n",
      "  validation loss:\t\t0.11\n",
      "116.995600954\n",
      "Epoch 161 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.118516\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 162 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.117472\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 163 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.113610\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 164 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.114493\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 165 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.115912\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 166 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.115200\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 167 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.111399\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 168 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.110751\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 169 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.111398\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 170 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.111044\n",
      "  validation loss:\t\t0.11\n",
      "113.224681519\n",
      "Epoch 171 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.112669\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 172 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.110516\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 173 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.108388\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 174 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.110928\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 175 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.109757\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 176 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.108672\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 177 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.107537\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 178 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.108879\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 179 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.106241\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 180 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.107319\n",
      "  validation loss:\t\t0.10\n",
      "105.401501282\n",
      "Epoch 181 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.104022\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 182 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.106128\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 183 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.104469\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 184 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.107173\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 185 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.105040\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 186 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.108613\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 187 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.100178\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 188 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.103143\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 189 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.103782\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 190 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.105165\n",
      "  validation loss:\t\t0.10\n",
      "103.557015804\n",
      "Epoch 191 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.104284\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 192 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.098874\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 193 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.102992\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 194 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.100738\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 195 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.099627\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 196 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.101129\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 197 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.100548\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 198 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.099972\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 199 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.098143\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 200 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.098624\n",
      "  validation loss:\t\t0.09\n",
      "100.327520965\n",
      "Epoch 201 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.098722\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 202 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.097006\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 203 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.098741\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 204 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.098980\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 205 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.096671\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 206 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.098582\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 207 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.095916\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 208 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.095944\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 209 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.096070\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 210 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.096107\n",
      "  validation loss:\t\t0.09\n",
      "94.7014180147\n",
      "Epoch 211 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.097415\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 212 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.096271\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 213 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.094520\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 214 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.094787\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 215 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.094944\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 216 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.095181\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 217 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.093175\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 218 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.093856\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 219 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.094365\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 220 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.092261\n",
      "  validation loss:\t\t0.09\n",
      "91.4434801949\n",
      "Epoch 221 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.093700\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 222 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.094107\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 223 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.090110\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 224 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.091042\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 225 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.094470\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 226 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.091995\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 227 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.092308\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 228 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.091122\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 229 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.091430\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 230 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.091166\n",
      "  validation loss:\t\t0.09\n",
      "90.7970734332\n",
      "Epoch 231 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.091847\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 232 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.088260\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 233 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.091002\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 234 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.089156\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 235 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.089300\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 236 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.086952\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 237 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.088607\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 238 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.087275\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 239 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.086121\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 240 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.087011\n",
      "  validation loss:\t\t0.08\n",
      "85.9231875414\n",
      "Epoch 241 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.086362\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 242 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.085545\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 243 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.086285\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 244 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.087364\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 245 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.088255\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 246 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.082252\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 247 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.083582\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 248 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.083958\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 249 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.082881\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 250 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.081428\n",
      "  validation loss:\t\t0.08\n",
      "82.4440008405\n",
      "Epoch 251 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.084206\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 252 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.082083\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 253 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.081795\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 254 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.082338\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 255 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.081821\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 256 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.079428\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 257 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.082317\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 258 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.080226\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 259 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.079675\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 260 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.079202\n",
      "  validation loss:\t\t0.08\n",
      "81.0014921067\n",
      "Epoch 261 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.080243\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 262 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.076230\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 263 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.078952\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 264 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.075501\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 265 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.076328\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 266 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.077599\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 267 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.076232\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 268 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.075723\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 269 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.075292\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 270 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.075655\n",
      "  validation loss:\t\t0.07\n",
      "74.0253846435\n",
      "Epoch 271 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.074379\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 272 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.074422\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 273 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.075031\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 274 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.072394\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 275 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.073973\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 276 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.074900\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 277 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.073420\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 278 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.073523\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 279 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.071574\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 280 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.071028\n",
      "  validation loss:\t\t0.07\n",
      "70.8308914237\n",
      "Epoch 281 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.070641\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 282 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.070800\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 283 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.070893\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 284 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.071375\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 285 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.068647\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 286 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.068987\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 287 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.070583\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 288 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.068476\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 289 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.069150\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 290 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.070290\n",
      "  validation loss:\t\t0.07\n",
      "68.2334637915\n",
      "Epoch 291 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.067723\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 292 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.065853\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 293 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.066263\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 294 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.067272\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 295 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.065881\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 296 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.065209\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 297 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.066249\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 298 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.064566\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 299 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.065389\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 300 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.064973\n",
      "  validation loss:\t\t0.06\n",
      "63.6926812298\n",
      "Epoch 301 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.064950\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 302 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.063787\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 303 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.064217\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 304 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.064023\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 305 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.062646\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 306 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.064343\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 307 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.061729\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 308 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.061452\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 309 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.062695\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 310 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.060921\n",
      "  validation loss:\t\t0.06\n",
      "60.4173626134\n",
      "Epoch 311 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.061073\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 312 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.061967\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 313 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.059589\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 314 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.060459\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 315 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.060566\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 316 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.060647\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 317 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.059169\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 318 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.059745\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 319 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.060035\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 320 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.058936\n",
      "  validation loss:\t\t0.06\n",
      "58.5982270356\n",
      "Epoch 321 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.059236\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 322 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.058220\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 323 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.060441\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 324 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.058310\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 325 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.058647\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 326 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.057469\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 327 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.056989\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 328 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.058259\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 329 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.056657\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 330 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.057257\n",
      "  validation loss:\t\t0.06\n",
      "56.6519247025\n",
      "Epoch 331 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.057283\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 332 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.056643\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 333 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.056540\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 334 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.057719\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 335 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.055593\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 336 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.056324\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 337 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.055750\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 338 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.056264\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 339 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.056745\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 340 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.056200\n",
      "  validation loss:\t\t0.06\n",
      "55.7339751119\n",
      "Epoch 341 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.054870\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 342 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.055128\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 343 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.054823\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 344 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.054592\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 345 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.054327\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 346 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.054464\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 347 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.055856\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 348 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.053605\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 349 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.054682\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 350 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.054216\n",
      "  validation loss:\t\t0.05\n",
      "53.0437174818\n",
      "Epoch 351 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.053179\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 352 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.053963\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 353 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.055360\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 354 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.054342\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 355 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.054333\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 356 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.053182\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 357 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.052318\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 358 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.052383\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 359 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.053184\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 360 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.052193\n",
      "  validation loss:\t\t0.05\n",
      "54.3525661612\n",
      "Epoch 361 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.052020\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 362 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.052020\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 363 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.052302\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 364 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.051318\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 365 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.051601\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 366 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.052649\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 367 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.051752\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 368 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.050918\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 369 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.051112\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 370 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.051195\n",
      "  validation loss:\t\t0.05\n",
      "49.438095982\n",
      "Epoch 371 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.049709\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 372 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.051471\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 373 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.050588\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 374 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.050928\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 375 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.051944\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 376 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.048912\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 377 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.050884\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 378 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.049928\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 379 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.050397\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 380 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.049851\n",
      "  validation loss:\t\t0.05\n",
      "50.4150678475\n",
      "Epoch 381 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.050221\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 382 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.050137\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 383 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.050511\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 384 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.049407\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 385 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.049163\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 386 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.049590\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 387 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.050304\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 388 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.049404\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 389 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.050886\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 390 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.047521\n",
      "  validation loss:\t\t0.05\n",
      "48.8510046116\n",
      "Epoch 391 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.049549\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 392 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.048410\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 393 of 500 took 0.209s\n",
      "  training loss (in-iteration):\t\t0.048473\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 394 of 500 took 0.204s\n",
      "  training loss (in-iteration):\t\t0.048827\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 395 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.047100\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 396 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.048951\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 397 of 500 took 0.204s\n",
      "  training loss (in-iteration):\t\t0.047264\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 398 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.048260\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 399 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.048302\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 400 of 500 took 0.190s\n",
      "  training loss (in-iteration):\t\t0.048142\n",
      "  validation loss:\t\t0.05\n",
      "46.6065738666\n",
      "Epoch 401 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.047486\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 402 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.046619\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 403 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.048564\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 404 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.046484\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 405 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.047246\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 406 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.046748\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 407 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.048492\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 408 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.046277\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 409 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.047172\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 410 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.047251\n",
      "  validation loss:\t\t0.05\n",
      "46.3375435193\n",
      "Epoch 411 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.046314\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 412 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.047013\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 413 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.047702\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 414 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.047444\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 415 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.047005\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 416 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.046585\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 417 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.046078\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 418 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.046471\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 419 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.047032\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 420 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.045685\n",
      "  validation loss:\t\t0.05\n",
      "45.7377629371\n",
      "Epoch 421 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.045466\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 422 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.046893\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 423 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.044742\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 424 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.045359\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 425 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.046378\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 426 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.046841\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 427 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.045256\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 428 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.046009\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 429 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.046159\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 430 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.045643\n",
      "  validation loss:\t\t0.05\n",
      "46.116032401\n",
      "Epoch 431 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.044993\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 432 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.045851\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 433 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.045791\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 434 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.047230\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 435 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.044842\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 436 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.043887\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 437 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.044355\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 438 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.044945\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 439 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.044085\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 440 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.045582\n",
      "  validation loss:\t\t0.05\n",
      "44.1084383118\n",
      "Epoch 441 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.044131\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 442 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.045200\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 443 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.044990\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 444 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.044978\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 445 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.042997\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 446 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.043205\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 447 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.043155\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 448 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.043325\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 449 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.043198\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 450 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.043918\n",
      "  validation loss:\t\t0.05\n",
      "43.4618116913\n",
      "Epoch 451 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.044335\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 452 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.043658\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 453 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.043971\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 454 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.043642\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 455 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.043081\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 456 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.044312\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 457 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.044436\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 458 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.045159\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 459 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.044790\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 460 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.042986\n",
      "  validation loss:\t\t0.05\n",
      "43.4948752543\n",
      "Epoch 461 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.042982\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 462 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.046475\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 463 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.042409\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 464 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.042041\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 465 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.042282\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 466 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.042935\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 467 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.043672\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 468 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.042797\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 469 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.041886\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 470 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.042840\n",
      "  validation loss:\t\t0.04\n",
      "41.6307844265\n",
      "Epoch 471 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.041810\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 472 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.042628\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 473 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.041480\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 474 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.041393\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 475 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.041666\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 476 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.041477\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 477 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.042205\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 478 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.042134\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 479 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.042304\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 480 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.043237\n",
      "  validation loss:\t\t0.04\n",
      "44.0706071467\n",
      "Epoch 481 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.042602\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 482 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.044205\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 483 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.041315\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 484 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.041929\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 485 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.042410\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 486 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.044337\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 487 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.040803\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 488 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.040522\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 489 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.041007\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 490 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.042037\n",
      "  validation loss:\t\t0.04\n",
      "41.257361175\n",
      "Epoch 491 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.042012\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 492 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.040681\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 493 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.040493\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 494 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.040745\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 495 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.041144\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 496 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.040449\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 497 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.041164\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 498 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.040684\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 499 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.039957\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 500 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.040646\n",
      "  validation loss:\t\t0.04\n",
      "43934.5866563\n",
      "Epoch 1 of 120 took 0.074s\n",
      "  training loss (in-iteration):\t\t5.131009\n",
      "  validation loss:\t\t6.11\n",
      "Epoch 2 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t4.738425\n",
      "  validation loss:\t\t5.89\n",
      "Epoch 3 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t4.643027\n",
      "  validation loss:\t\t5.82\n",
      "Epoch 4 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t4.566347\n",
      "  validation loss:\t\t5.75\n",
      "Epoch 5 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.516287\n",
      "  validation loss:\t\t5.73\n",
      "Epoch 6 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t4.460960\n",
      "  validation loss:\t\t5.64\n",
      "Epoch 7 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t4.399301\n",
      "  validation loss:\t\t5.64\n",
      "Epoch 8 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t4.385087\n",
      "  validation loss:\t\t5.54\n",
      "Epoch 9 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t4.321853\n",
      "  validation loss:\t\t5.53\n",
      "Epoch 10 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t4.251686\n",
      "  validation loss:\t\t5.46\n",
      "33435.0092485\n",
      "Epoch 11 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t4.224909\n",
      "  validation loss:\t\t5.39\n",
      "Epoch 12 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t4.139010\n",
      "  validation loss:\t\t5.32\n",
      "Epoch 13 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t4.099524\n",
      "  validation loss:\t\t5.32\n",
      "Epoch 14 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t4.074660\n",
      "  validation loss:\t\t5.25\n",
      "Epoch 15 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t4.015876\n",
      "  validation loss:\t\t5.24\n",
      "Epoch 16 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.999487\n",
      "  validation loss:\t\t5.17\n",
      "Epoch 17 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t3.948097\n",
      "  validation loss:\t\t5.15\n",
      "Epoch 18 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t3.931458\n",
      "  validation loss:\t\t5.07\n",
      "Epoch 19 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.879109\n",
      "  validation loss:\t\t5.03\n",
      "Epoch 20 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.835598\n",
      "  validation loss:\t\t4.93\n",
      "30239.8668302\n",
      "Epoch 21 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t3.910317\n",
      "  validation loss:\t\t4.88\n",
      "Epoch 22 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t3.763347\n",
      "  validation loss:\t\t4.84\n",
      "Epoch 23 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t3.710780\n",
      "  validation loss:\t\t4.80\n",
      "Epoch 24 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.691842\n",
      "  validation loss:\t\t4.74\n",
      "Epoch 25 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t3.645551\n",
      "  validation loss:\t\t4.73\n",
      "Epoch 26 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t3.627396\n",
      "  validation loss:\t\t4.67\n",
      "Epoch 27 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t3.587230\n",
      "  validation loss:\t\t4.62\n",
      "Epoch 28 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t3.558545\n",
      "  validation loss:\t\t4.58\n",
      "Epoch 29 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t3.542218\n",
      "  validation loss:\t\t4.56\n",
      "Epoch 30 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.485622\n",
      "  validation loss:\t\t4.47\n",
      "27530.3758243\n",
      "Epoch 31 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.536274\n",
      "  validation loss:\t\t4.49\n",
      "Epoch 32 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.400006\n",
      "  validation loss:\t\t4.44\n",
      "Epoch 33 of 120 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.390793\n",
      "  validation loss:\t\t4.37\n",
      "Epoch 34 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t3.349870\n",
      "  validation loss:\t\t4.35\n",
      "Epoch 35 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t3.342202\n",
      "  validation loss:\t\t4.29\n",
      "Epoch 36 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.307401\n",
      "  validation loss:\t\t4.29\n",
      "Epoch 37 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t3.255064\n",
      "  validation loss:\t\t4.23\n",
      "Epoch 38 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t3.255148\n",
      "  validation loss:\t\t4.21\n",
      "Epoch 39 of 120 took 0.072s\n",
      "  training loss (in-iteration):\t\t3.223079\n",
      "  validation loss:\t\t4.13\n",
      "Epoch 40 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t3.184750\n",
      "  validation loss:\t\t4.12\n",
      "25235.0217084\n",
      "Epoch 41 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t3.301787\n",
      "  validation loss:\t\t4.18\n",
      "Epoch 42 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t3.176413\n",
      "  validation loss:\t\t4.14\n",
      "Epoch 43 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t3.133836\n",
      "  validation loss:\t\t4.08\n",
      "Epoch 44 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.102453\n",
      "  validation loss:\t\t4.06\n",
      "Epoch 45 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t3.074904\n",
      "  validation loss:\t\t4.00\n",
      "Epoch 46 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t3.062868\n",
      "  validation loss:\t\t4.01\n",
      "Epoch 47 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t3.015229\n",
      "  validation loss:\t\t3.99\n",
      "Epoch 48 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.994896\n",
      "  validation loss:\t\t3.88\n",
      "Epoch 49 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t2.964845\n",
      "  validation loss:\t\t3.83\n",
      "Epoch 50 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.913737\n",
      "  validation loss:\t\t3.78\n",
      "22971.3422988\n",
      "Epoch 51 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t2.927418\n",
      "  validation loss:\t\t3.76\n",
      "Epoch 52 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.850790\n",
      "  validation loss:\t\t3.71\n",
      "Epoch 53 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.837494\n",
      "  validation loss:\t\t3.69\n",
      "Epoch 54 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t2.805173\n",
      "  validation loss:\t\t3.65\n",
      "Epoch 55 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t2.783332\n",
      "  validation loss:\t\t3.68\n",
      "Epoch 56 of 120 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.775270\n",
      "  validation loss:\t\t3.62\n",
      "Epoch 57 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.762391\n",
      "  validation loss:\t\t3.60\n",
      "Epoch 58 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.729175\n",
      "  validation loss:\t\t3.55\n",
      "Epoch 59 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.712111\n",
      "  validation loss:\t\t3.51\n",
      "Epoch 60 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.690660\n",
      "  validation loss:\t\t3.48\n",
      "21136.5221771\n",
      "Epoch 61 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.734629\n",
      "  validation loss:\t\t3.47\n",
      "Epoch 62 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t2.610914\n",
      "  validation loss:\t\t3.41\n",
      "Epoch 63 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.590956\n",
      "  validation loss:\t\t3.43\n",
      "Epoch 64 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.594238\n",
      "  validation loss:\t\t3.38\n",
      "Epoch 65 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.560614\n",
      "  validation loss:\t\t3.37\n",
      "Epoch 66 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t2.551475\n",
      "  validation loss:\t\t3.31\n",
      "Epoch 67 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.528834\n",
      "  validation loss:\t\t3.29\n",
      "Epoch 68 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t2.508575\n",
      "  validation loss:\t\t3.26\n",
      "Epoch 69 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.494045\n",
      "  validation loss:\t\t3.26\n",
      "Epoch 70 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t2.449110\n",
      "  validation loss:\t\t3.20\n",
      "19398.2728328\n",
      "Epoch 71 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t2.512777\n",
      "  validation loss:\t\t3.17\n",
      "Epoch 72 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.404187\n",
      "  validation loss:\t\t3.18\n",
      "Epoch 73 of 120 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.396317\n",
      "  validation loss:\t\t3.15\n",
      "Epoch 74 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.376972\n",
      "  validation loss:\t\t3.14\n",
      "Epoch 75 of 120 took 0.103s\n",
      "  training loss (in-iteration):\t\t2.364730\n",
      "  validation loss:\t\t3.10\n",
      "Epoch 76 of 120 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.344946\n",
      "  validation loss:\t\t3.10\n",
      "Epoch 77 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.311278\n",
      "  validation loss:\t\t3.06\n",
      "Epoch 78 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t2.310819\n",
      "  validation loss:\t\t3.05\n",
      "Epoch 79 of 120 took 0.072s\n",
      "  training loss (in-iteration):\t\t2.279723\n",
      "  validation loss:\t\t3.01\n",
      "Epoch 80 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.285767\n",
      "  validation loss:\t\t3.00\n",
      "18094.5424368\n",
      "Epoch 81 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.404328\n",
      "  validation loss:\t\t2.99\n",
      "Epoch 82 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.242250\n",
      "  validation loss:\t\t2.95\n",
      "Epoch 83 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t2.205804\n",
      "  validation loss:\t\t2.93\n",
      "Epoch 84 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.184506\n",
      "  validation loss:\t\t2.90\n",
      "Epoch 85 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t2.168708\n",
      "  validation loss:\t\t2.94\n",
      "Epoch 86 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t2.155096\n",
      "  validation loss:\t\t2.86\n",
      "Epoch 87 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t2.140047\n",
      "  validation loss:\t\t2.85\n",
      "Epoch 88 of 120 took 0.103s\n",
      "  training loss (in-iteration):\t\t2.119148\n",
      "  validation loss:\t\t2.84\n",
      "Epoch 89 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t2.125006\n",
      "  validation loss:\t\t2.81\n",
      "Epoch 90 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.096683\n",
      "  validation loss:\t\t2.80\n",
      "16387.8991568\n",
      "Epoch 91 of 120 took 0.111s\n",
      "  training loss (in-iteration):\t\t2.125763\n",
      "  validation loss:\t\t2.75\n",
      "Epoch 92 of 120 took 0.077s\n",
      "  training loss (in-iteration):\t\t2.058689\n",
      "  validation loss:\t\t2.75\n",
      "Epoch 93 of 120 took 0.073s\n",
      "  training loss (in-iteration):\t\t2.036963\n",
      "  validation loss:\t\t2.72\n",
      "Epoch 94 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t2.027975\n",
      "  validation loss:\t\t2.72\n",
      "Epoch 95 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t2.009744\n",
      "  validation loss:\t\t2.69\n",
      "Epoch 96 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t1.988318\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 97 of 120 took 0.089s\n",
      "  training loss (in-iteration):\t\t2.001162\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 98 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t1.968516\n",
      "  validation loss:\t\t2.63\n",
      "Epoch 99 of 120 took 0.074s\n",
      "  training loss (in-iteration):\t\t1.948796\n",
      "  validation loss:\t\t2.65\n",
      "Epoch 100 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t1.937577\n",
      "  validation loss:\t\t2.58\n",
      "15292.3036127\n",
      "Epoch 101 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t2.015355\n",
      "  validation loss:\t\t2.57\n",
      "Epoch 102 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t1.892159\n",
      "  validation loss:\t\t2.53\n",
      "Epoch 103 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t1.889620\n",
      "  validation loss:\t\t2.54\n",
      "Epoch 104 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.875719\n",
      "  validation loss:\t\t2.55\n",
      "Epoch 105 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t1.863689\n",
      "  validation loss:\t\t2.55\n",
      "Epoch 106 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t1.849478\n",
      "  validation loss:\t\t2.53\n",
      "Epoch 107 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.837606\n",
      "  validation loss:\t\t2.50\n",
      "Epoch 108 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t1.835916\n",
      "  validation loss:\t\t2.47\n",
      "Epoch 109 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t1.800036\n",
      "  validation loss:\t\t2.43\n",
      "Epoch 110 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t1.791375\n",
      "  validation loss:\t\t2.44\n",
      "14132.3080807\n",
      "Epoch 111 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t1.934126\n",
      "  validation loss:\t\t2.48\n",
      "Epoch 112 of 120 took 0.088s\n",
      "  training loss (in-iteration):\t\t1.779971\n",
      "  validation loss:\t\t2.39\n",
      "Epoch 113 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.751493\n",
      "  validation loss:\t\t2.42\n",
      "Epoch 114 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.740378\n",
      "  validation loss:\t\t2.37\n",
      "Epoch 115 of 120 took 0.128s\n",
      "  training loss (in-iteration):\t\t1.727663\n",
      "  validation loss:\t\t2.37\n",
      "Epoch 116 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t1.722863\n",
      "  validation loss:\t\t2.37\n",
      "Epoch 117 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t1.709437\n",
      "  validation loss:\t\t2.35\n",
      "Epoch 118 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.705338\n",
      "  validation loss:\t\t2.32\n",
      "Epoch 119 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t1.693151\n",
      "  validation loss:\t\t2.28\n",
      "Epoch 120 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t1.683477\n",
      "  validation loss:\t\t2.34\n",
      "42792.6628681\n",
      "Epoch 1 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t42.933374\n",
      "  validation loss:\t\t15.00\n",
      "Epoch 2 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t42.307558\n",
      "  validation loss:\t\t14.94\n",
      "Epoch 3 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t41.816569\n",
      "  validation loss:\t\t15.00\n",
      "Epoch 4 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t41.643922\n",
      "  validation loss:\t\t14.52\n",
      "Epoch 5 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t40.589479\n",
      "  validation loss:\t\t14.48\n",
      "Epoch 6 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t40.475231\n",
      "  validation loss:\t\t14.47\n",
      "Epoch 7 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t42.028853\n",
      "  validation loss:\t\t14.32\n",
      "Epoch 8 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t41.001030\n",
      "  validation loss:\t\t13.87\n",
      "Epoch 9 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t38.870381\n",
      "  validation loss:\t\t13.51\n",
      "Epoch 10 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t36.860390\n",
      "  validation loss:\t\t12.12\n",
      "34971.6788563\n",
      "Epoch 11 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t30.074164\n",
      "  validation loss:\t\t7.66\n",
      "Epoch 12 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t15.859163\n",
      "  validation loss:\t\t3.82\n",
      "Epoch 13 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t8.254354\n",
      "  validation loss:\t\t3.31\n",
      "Epoch 14 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t5.750555\n",
      "  validation loss:\t\t1.96\n",
      "Epoch 15 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t3.941276\n",
      "  validation loss:\t\t1.84\n",
      "Epoch 16 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t3.323194\n",
      "  validation loss:\t\t0.92\n",
      "Epoch 17 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t2.201180\n",
      "  validation loss:\t\t0.48\n",
      "Epoch 18 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.862140\n",
      "  validation loss:\t\t0.79\n",
      "Epoch 19 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t1.816094\n",
      "  validation loss:\t\t0.83\n",
      "Epoch 20 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t1.290624\n",
      "  validation loss:\t\t0.44\n",
      "812.061826368\n",
      "Epoch 21 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.875267\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 22 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.623802\n",
      "  validation loss:\t\t0.41\n",
      "Epoch 23 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.550229\n",
      "  validation loss:\t\t0.46\n",
      "Epoch 24 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.647957\n",
      "  validation loss:\t\t0.41\n",
      "Epoch 25 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.584696\n",
      "  validation loss:\t\t0.38\n",
      "Epoch 26 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.496320\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 27 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.435185\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 28 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.424146\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 29 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.673114\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 30 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.347602\n",
      "  validation loss:\t\t0.26\n",
      "354.831106065\n",
      "Epoch 31 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.364177\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 32 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.348090\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 33 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.369577\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 34 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.350420\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 35 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.324693\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 36 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.331290\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 37 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.384652\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 38 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.328601\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 39 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.330102\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 40 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.340528\n",
      "  validation loss:\t\t0.26\n",
      "334.195972605\n",
      "Epoch 41 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.337096\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 42 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.319985\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 43 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.313606\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 44 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.362575\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 45 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.306544\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 46 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.295874\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 47 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.292732\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 48 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.290580\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 49 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.287729\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 50 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.288491\n",
      "  validation loss:\t\t0.23\n",
      "295.020110075\n",
      "Epoch 51 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.288447\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 52 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.288763\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 53 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.286025\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 54 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.284908\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 55 of 500 took 0.216s\n",
      "  training loss (in-iteration):\t\t0.287358\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 56 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.282099\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 57 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.276795\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 58 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.277162\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 59 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.276182\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 60 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.274632\n",
      "  validation loss:\t\t0.22\n",
      "277.79489712\n",
      "Epoch 61 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.277944\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 62 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.277506\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 63 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.277079\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 64 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.272167\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 65 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.280605\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 66 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.273371\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 67 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.273357\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 68 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.272898\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 69 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.271012\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 70 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.269282\n",
      "  validation loss:\t\t0.21\n",
      "267.755943186\n",
      "Epoch 71 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.268070\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 72 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.265705\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 73 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.266882\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 74 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.263072\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 75 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.262294\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 76 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.258229\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 77 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.257832\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 78 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.256158\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 79 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.252527\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 80 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.250938\n",
      "  validation loss:\t\t0.20\n",
      "249.819836778\n",
      "Epoch 81 of 500 took 0.212s\n",
      "  training loss (in-iteration):\t\t0.249629\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 82 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.250637\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 83 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.249697\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 84 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.248622\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 85 of 500 took 0.205s\n",
      "  training loss (in-iteration):\t\t0.244455\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 86 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.244799\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 87 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.242148\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 88 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.238710\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 89 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.236243\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 90 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.233674\n",
      "  validation loss:\t\t0.18\n",
      "231.329076882\n",
      "Epoch 91 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.228947\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 92 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.224622\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 93 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.223254\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 94 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.220074\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 95 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.218677\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 96 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.210249\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 97 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.209763\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 98 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.206976\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 99 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.203755\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 100 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.202606\n",
      "  validation loss:\t\t0.15\n",
      "195.303151303\n",
      "Epoch 101 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.198831\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 102 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.197568\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 103 of 500 took 0.213s\n",
      "  training loss (in-iteration):\t\t0.194588\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 104 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.193153\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 105 of 500 took 0.205s\n",
      "  training loss (in-iteration):\t\t0.192139\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 106 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.191160\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 107 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.186541\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 108 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.185100\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 109 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.186543\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 110 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.183303\n",
      "  validation loss:\t\t0.14\n",
      "181.234095275\n",
      "Epoch 111 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.181027\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 112 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.177296\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 113 of 500 took 0.207s\n",
      "  training loss (in-iteration):\t\t0.173579\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 114 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.174714\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 115 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.168187\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 116 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.168869\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 117 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.168009\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 118 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.163083\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 119 of 500 took 0.204s\n",
      "  training loss (in-iteration):\t\t0.162699\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 120 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.158599\n",
      "  validation loss:\t\t0.12\n",
      "156.960088932\n",
      "Epoch 121 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.161386\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 122 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.153712\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 123 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.153776\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 124 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.154209\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 125 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.152399\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 126 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.151039\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 127 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.154110\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 128 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.149437\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 129 of 500 took 0.223s\n",
      "  training loss (in-iteration):\t\t0.146317\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 130 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.145057\n",
      "  validation loss:\t\t0.11\n",
      "140.221970025\n",
      "Epoch 131 of 500 took 0.204s\n",
      "  training loss (in-iteration):\t\t0.144464\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 132 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.143121\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 133 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.141949\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 134 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.145804\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 135 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.138731\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 136 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.136700\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 137 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.138884\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 138 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.137749\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 139 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.137981\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 140 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.132169\n",
      "  validation loss:\t\t0.10\n",
      "133.479133254\n",
      "Epoch 141 of 500 took 0.311s\n",
      "  training loss (in-iteration):\t\t0.133185\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 142 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.135100\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 143 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.131823\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 144 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.130740\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 145 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.129315\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 146 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.127473\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 147 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.125761\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 148 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.127212\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 149 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.123150\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 150 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.127858\n",
      "  validation loss:\t\t0.09\n",
      "122.406230928\n",
      "Epoch 151 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.122930\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 152 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.124600\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 153 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.123012\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 154 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.121691\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 155 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.120037\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 156 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.120024\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 157 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.119095\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 158 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.117947\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 159 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.117289\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 160 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.117300\n",
      "  validation loss:\t\t0.09\n",
      "116.577751879\n",
      "Epoch 161 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.112862\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 162 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.114230\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 163 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.112725\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 164 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.113427\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 165 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.111227\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 166 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.112806\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 167 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.108264\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 168 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.110063\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 169 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.109979\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 170 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.108272\n",
      "  validation loss:\t\t0.08\n",
      "106.288026462\n",
      "Epoch 171 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.106933\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 172 of 500 took 0.219s\n",
      "  training loss (in-iteration):\t\t0.107258\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 173 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.105891\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 174 of 500 took 0.231s\n",
      "  training loss (in-iteration):\t\t0.106659\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 175 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.104022\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 176 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.103930\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 177 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.105353\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 178 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.105199\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 179 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.104645\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 180 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.102705\n",
      "  validation loss:\t\t0.08\n",
      "103.250453995\n",
      "Epoch 181 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.102916\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 182 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.100319\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 183 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.103179\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 184 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.100977\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 185 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.100675\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 186 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.099764\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 187 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.098945\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 188 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.098369\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 189 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.099090\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 190 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.099843\n",
      "  validation loss:\t\t0.07\n",
      "95.8230166889\n",
      "Epoch 191 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.095910\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 192 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.097837\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 193 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.095513\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 194 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.095331\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 195 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.096207\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 196 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.096674\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 197 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.097506\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 198 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.095648\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 199 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.094735\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 200 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.095294\n",
      "  validation loss:\t\t0.07\n",
      "94.2662721055\n",
      "Epoch 201 of 500 took 0.255s\n",
      "  training loss (in-iteration):\t\t0.094573\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 202 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.093083\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 203 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.093619\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 204 of 500 took 0.216s\n",
      "  training loss (in-iteration):\t\t0.092405\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 205 of 500 took 0.268s\n",
      "  training loss (in-iteration):\t\t0.092691\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 206 of 500 took 0.225s\n",
      "  training loss (in-iteration):\t\t0.094190\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 207 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.092694\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 208 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.091704\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 209 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.092087\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 210 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.091084\n",
      "  validation loss:\t\t0.07\n",
      "89.5912060804\n",
      "Epoch 211 of 500 took 0.243s\n",
      "  training loss (in-iteration):\t\t0.092024\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 212 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.090909\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 213 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.088501\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 214 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.088605\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 215 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.091447\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 216 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.088902\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 217 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.087905\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 218 of 500 took 0.232s\n",
      "  training loss (in-iteration):\t\t0.089672\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 219 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.088581\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 220 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.087489\n",
      "  validation loss:\t\t0.06\n",
      "88.0540297965\n",
      "Epoch 221 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.087295\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 222 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.086395\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 223 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.087130\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 224 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.086614\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 225 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.085847\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 226 of 500 took 0.229s\n",
      "  training loss (in-iteration):\t\t0.087301\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 227 of 500 took 0.324s\n",
      "  training loss (in-iteration):\t\t0.085130\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 228 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.087191\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 229 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.087126\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 230 of 500 took 0.265s\n",
      "  training loss (in-iteration):\t\t0.083374\n",
      "  validation loss:\t\t0.06\n",
      "83.1637256331\n",
      "Epoch 231 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.083024\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 232 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.084276\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 233 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.084460\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 234 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.083671\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 235 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.083586\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 236 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.082505\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 237 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.083222\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 238 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.083266\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 239 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.081656\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 240 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.081552\n",
      "  validation loss:\t\t0.06\n",
      "80.3559685321\n",
      "Epoch 241 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.081513\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 242 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.080961\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 243 of 500 took 0.219s\n",
      "  training loss (in-iteration):\t\t0.081926\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 244 of 500 took 0.281s\n",
      "  training loss (in-iteration):\t\t0.080067\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 245 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.080694\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 246 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.079848\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 247 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.081222\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 248 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.082461\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 249 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.081410\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 250 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.080629\n",
      "  validation loss:\t\t0.06\n",
      "79.4129395079\n",
      "Epoch 251 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.080170\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 252 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.080216\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 253 of 500 took 0.221s\n",
      "  training loss (in-iteration):\t\t0.081124\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 254 of 500 took 0.255s\n",
      "  training loss (in-iteration):\t\t0.077112\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 255 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.077918\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 256 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.076429\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 257 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.076898\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 258 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.077228\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 259 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.078034\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 260 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.076657\n",
      "  validation loss:\t\t0.06\n",
      "75.2866529229\n",
      "Epoch 261 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.075613\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 262 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.075915\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 263 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.075625\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 264 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.076136\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 265 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.076112\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 266 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.075135\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 267 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.076002\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 268 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.075923\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 269 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.075329\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 270 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.076074\n",
      "  validation loss:\t\t0.05\n",
      "73.6183760606\n",
      "Epoch 271 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.074958\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 272 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.074393\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 273 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.074803\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 274 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.073463\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 275 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.074146\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 276 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.074237\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 277 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.074703\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 278 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.074540\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 279 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.073493\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 280 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.073348\n",
      "  validation loss:\t\t0.05\n",
      "73.772352259\n",
      "Epoch 281 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.074584\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 282 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.074645\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 283 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.073438\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 284 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.071415\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 285 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.071660\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 286 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.070732\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 287 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.071919\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 288 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.071860\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 289 of 500 took 0.263s\n",
      "  training loss (in-iteration):\t\t0.071522\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 290 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.073438\n",
      "  validation loss:\t\t0.05\n",
      "72.3724022009\n",
      "Epoch 291 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.071137\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 292 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.070597\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 293 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.070898\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 294 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.070135\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 295 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.068967\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 296 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.069107\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 297 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.068620\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 298 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.068924\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 299 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.068177\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 300 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.068318\n",
      "  validation loss:\t\t0.05\n",
      "67.1561655083\n",
      "Epoch 301 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.068012\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 302 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.069363\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 303 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.067689\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 304 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.068863\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 305 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.066763\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 306 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.067117\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 307 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.067069\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 308 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.066551\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 309 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.068293\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 310 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.068659\n",
      "  validation loss:\t\t0.05\n",
      "69.792015166\n",
      "Epoch 311 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.068581\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 312 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.067774\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 313 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.067747\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 314 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.065797\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 315 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.066476\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 316 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.066016\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 317 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.068361\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 318 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.065609\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 319 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.065279\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 320 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.065538\n",
      "  validation loss:\t\t0.05\n",
      "66.0366139683\n",
      "Epoch 321 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.065949\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 322 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.066652\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 323 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.064842\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 324 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.065828\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 325 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.065295\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 326 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.063702\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 327 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.065244\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 328 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.064752\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 329 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.064249\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 330 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.064184\n",
      "  validation loss:\t\t0.05\n",
      "63.5605972253\n",
      "Epoch 331 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.063505\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 332 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.064046\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 333 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.064094\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 334 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.064193\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 335 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.065255\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 336 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.063981\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 337 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.063443\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 338 of 500 took 0.243s\n",
      "  training loss (in-iteration):\t\t0.063856\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 339 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.064812\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 340 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.064754\n",
      "  validation loss:\t\t0.05\n",
      "64.8002004144\n",
      "Epoch 341 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.064531\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 342 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.064786\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 343 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.062760\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 344 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.063315\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 345 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.063739\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 346 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.062904\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 347 of 500 took 0.308s\n",
      "  training loss (in-iteration):\t\t0.063175\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 348 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.062742\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 349 of 500 took 0.338s\n",
      "  training loss (in-iteration):\t\t0.062781\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 350 of 500 took 0.231s\n",
      "  training loss (in-iteration):\t\t0.061079\n",
      "  validation loss:\t\t0.04\n",
      "61.6062326889\n",
      "Epoch 351 of 500 took 0.227s\n",
      "  training loss (in-iteration):\t\t0.061538\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 352 of 500 took 0.302s\n",
      "  training loss (in-iteration):\t\t0.061967\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 353 of 500 took 0.257s\n",
      "  training loss (in-iteration):\t\t0.061814\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 354 of 500 took 0.273s\n",
      "  training loss (in-iteration):\t\t0.061676\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 355 of 500 took 0.365s\n",
      "  training loss (in-iteration):\t\t0.060405\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 356 of 500 took 0.433s\n",
      "  training loss (in-iteration):\t\t0.061275\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 357 of 500 took 0.233s\n",
      "  training loss (in-iteration):\t\t0.061140\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 358 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.061192\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 359 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.061320\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 360 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.060981\n",
      "  validation loss:\t\t0.04\n",
      "61.3099950859\n",
      "Epoch 361 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.060330\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 362 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.060241\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 363 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.060726\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 364 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.059324\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 365 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.060158\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 366 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.061180\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 367 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.060586\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 368 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.059211\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 369 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.060070\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 370 of 500 took 0.226s\n",
      "  training loss (in-iteration):\t\t0.059274\n",
      "  validation loss:\t\t0.04\n",
      "61.036151299\n",
      "Epoch 371 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.060307\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 372 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.059105\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 373 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.058934\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 374 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.059529\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 375 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.059902\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 376 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.059334\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 377 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.058409\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 378 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.058060\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 379 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.058019\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 380 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.058182\n",
      "  validation loss:\t\t0.04\n",
      "59.0604475017\n",
      "Epoch 381 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.057299\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 382 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.056887\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 383 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.056763\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 384 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.056909\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 385 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.057216\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 386 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.056827\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 387 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.057910\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 388 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.057243\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 389 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.057334\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 390 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.056663\n",
      "  validation loss:\t\t0.04\n",
      "56.1848084444\n",
      "Epoch 391 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.056806\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 392 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.056020\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 393 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.057829\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 394 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.056314\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 395 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.055129\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 396 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.055981\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 397 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.055775\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 398 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.055328\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 399 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.056317\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 400 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.055545\n",
      "  validation loss:\t\t0.04\n",
      "56.696960208\n",
      "Epoch 401 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.056871\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 402 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.054797\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 403 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.055426\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 404 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.055275\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 405 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.055301\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 406 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.054756\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 407 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.055649\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 408 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.055734\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 409 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.054976\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 410 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.056614\n",
      "  validation loss:\t\t0.04\n",
      "56.7667035962\n",
      "Epoch 411 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.056351\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 412 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.055108\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 413 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.054802\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 414 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.055246\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 415 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.055030\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 416 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.053514\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 417 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.054635\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 418 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.058035\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 419 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.054997\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 420 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.053423\n",
      "  validation loss:\t\t0.04\n",
      "51.6332080103\n",
      "Epoch 421 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.051866\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 422 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.053345\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 423 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.053936\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 424 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.052417\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 425 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.052697\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 426 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.052623\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 427 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.051969\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 428 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.052252\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 429 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.052241\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 430 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.051108\n",
      "  validation loss:\t\t0.04\n",
      "52.3124949708\n",
      "Epoch 431 of 500 took 0.225s\n",
      "  training loss (in-iteration):\t\t0.051898\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 432 of 500 took 0.205s\n",
      "  training loss (in-iteration):\t\t0.052235\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 433 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.052066\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 434 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.052250\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 435 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.050775\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 436 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.051669\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 437 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.051775\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 438 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.051870\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 439 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.052743\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 440 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.052570\n",
      "  validation loss:\t\t0.04\n",
      "50.9467178017\n",
      "Epoch 441 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.051643\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 442 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.052568\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 443 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.050349\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 444 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.053904\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 445 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.050618\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 446 of 500 took 0.135s\n",
      "  training loss (in-iteration):\t\t0.051833\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 447 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.050427\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 448 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.049911\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 449 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.050179\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 450 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.048957\n",
      "  validation loss:\t\t0.04\n",
      "49.6699994233\n",
      "Epoch 451 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.049334\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 452 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.048585\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 453 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.048722\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 454 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.049959\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 455 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.050548\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 456 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.049438\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 457 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.049806\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 458 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.048680\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 459 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.049834\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 460 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.050287\n",
      "  validation loss:\t\t0.04\n",
      "49.2809342743\n",
      "Epoch 461 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.049936\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 462 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.049632\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 463 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.049186\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 464 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.050885\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 465 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.048275\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 466 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.048803\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 467 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.051278\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 468 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.048075\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 469 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.048531\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 470 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.048560\n",
      "  validation loss:\t\t0.03\n",
      "47.6517197849\n",
      "Epoch 471 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.047738\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 472 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.048851\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 473 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.048515\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 474 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.046879\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 475 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.048965\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 476 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.048298\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 477 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.048085\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 478 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.049469\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 479 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.047387\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 480 of 500 took 0.136s\n",
      "  training loss (in-iteration):\t\t0.047892\n",
      "  validation loss:\t\t0.03\n",
      "49.2934476423\n",
      "Epoch 481 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.047916\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 482 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.047895\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 483 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.047682\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 484 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.049380\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 485 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.046707\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 486 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.048387\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 487 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.047445\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 488 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.047794\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 489 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.049330\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 490 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.046893\n",
      "  validation loss:\t\t0.03\n",
      "47.4221136016\n",
      "Epoch 491 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.048064\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 492 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.047027\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 493 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.046577\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 494 of 500 took 0.132s\n",
      "  training loss (in-iteration):\t\t0.047104\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 495 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.045831\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 496 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.047203\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 497 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.046041\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 498 of 500 took 0.134s\n",
      "  training loss (in-iteration):\t\t0.046318\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 499 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.046233\n",
      "  validation loss:\t\t0.03\n",
      "Epoch 500 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.045994\n",
      "  validation loss:\t\t0.03\n",
      "44269.1218696\n",
      "Epoch 1 of 120 took 0.111s\n",
      "  training loss (in-iteration):\t\t5.232360\n",
      "  validation loss:\t\t5.96\n",
      "Epoch 2 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t5.070068\n",
      "  validation loss:\t\t5.82\n",
      "Epoch 3 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t4.903647\n",
      "  validation loss:\t\t5.67\n",
      "Epoch 4 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t4.744448\n",
      "  validation loss:\t\t5.55\n",
      "Epoch 5 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t4.611584\n",
      "  validation loss:\t\t5.46\n",
      "Epoch 6 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t4.506310\n",
      "  validation loss:\t\t5.35\n",
      "Epoch 7 of 120 took 0.102s\n",
      "  training loss (in-iteration):\t\t4.469208\n",
      "  validation loss:\t\t5.31\n",
      "Epoch 8 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t4.414712\n",
      "  validation loss:\t\t5.24\n",
      "Epoch 9 of 120 took 0.101s\n",
      "  training loss (in-iteration):\t\t4.374322\n",
      "  validation loss:\t\t5.21\n",
      "Epoch 10 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t4.317557\n",
      "  validation loss:\t\t5.17\n",
      "34353.0921778\n",
      "Epoch 11 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t4.375952\n",
      "  validation loss:\t\t5.23\n",
      "Epoch 12 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t4.235774\n",
      "  validation loss:\t\t5.12\n",
      "Epoch 13 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t4.181158\n",
      "  validation loss:\t\t5.04\n",
      "Epoch 14 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t4.172158\n",
      "  validation loss:\t\t5.04\n",
      "Epoch 15 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t4.112083\n",
      "  validation loss:\t\t4.97\n",
      "Epoch 16 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t4.063809\n",
      "  validation loss:\t\t4.94\n",
      "Epoch 17 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t4.036573\n",
      "  validation loss:\t\t4.85\n",
      "Epoch 18 of 120 took 0.102s\n",
      "  training loss (in-iteration):\t\t3.998970\n",
      "  validation loss:\t\t4.83\n",
      "Epoch 19 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t3.946968\n",
      "  validation loss:\t\t4.82\n",
      "Epoch 20 of 120 took 0.101s\n",
      "  training loss (in-iteration):\t\t3.914099\n",
      "  validation loss:\t\t4.74\n",
      "30861.5599194\n",
      "Epoch 21 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t3.925549\n",
      "  validation loss:\t\t4.71\n",
      "Epoch 22 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t3.826390\n",
      "  validation loss:\t\t4.67\n",
      "Epoch 23 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t3.791894\n",
      "  validation loss:\t\t4.60\n",
      "Epoch 24 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.757905\n",
      "  validation loss:\t\t4.58\n",
      "Epoch 25 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.753615\n",
      "  validation loss:\t\t4.51\n",
      "Epoch 26 of 120 took 0.102s\n",
      "  training loss (in-iteration):\t\t3.710142\n",
      "  validation loss:\t\t4.50\n",
      "Epoch 27 of 120 took 0.075s\n",
      "  training loss (in-iteration):\t\t3.656990\n",
      "  validation loss:\t\t4.48\n",
      "Epoch 28 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t3.622177\n",
      "  validation loss:\t\t4.43\n",
      "Epoch 29 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t3.589683\n",
      "  validation loss:\t\t4.34\n",
      "Epoch 30 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t3.551491\n",
      "  validation loss:\t\t4.36\n",
      "28029.6941479\n",
      "Epoch 31 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t3.597180\n",
      "  validation loss:\t\t4.27\n",
      "Epoch 32 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t3.474325\n",
      "  validation loss:\t\t4.27\n",
      "Epoch 33 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t3.458821\n",
      "  validation loss:\t\t4.23\n",
      "Epoch 34 of 120 took 0.112s\n",
      "  training loss (in-iteration):\t\t3.421158\n",
      "  validation loss:\t\t4.22\n",
      "Epoch 35 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t3.389462\n",
      "  validation loss:\t\t4.13\n",
      "Epoch 36 of 120 took 0.131s\n",
      "  training loss (in-iteration):\t\t3.363409\n",
      "  validation loss:\t\t4.16\n",
      "Epoch 37 of 120 took 0.119s\n",
      "  training loss (in-iteration):\t\t3.329387\n",
      "  validation loss:\t\t4.07\n",
      "Epoch 38 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.297199\n",
      "  validation loss:\t\t4.09\n",
      "Epoch 39 of 120 took 0.111s\n",
      "  training loss (in-iteration):\t\t3.291524\n",
      "  validation loss:\t\t4.04\n",
      "Epoch 40 of 120 took 0.113s\n",
      "  training loss (in-iteration):\t\t3.250953\n",
      "  validation loss:\t\t3.99\n",
      "25505.2285823\n",
      "Epoch 41 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.270911\n",
      "  validation loss:\t\t3.92\n",
      "Epoch 42 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t3.170108\n",
      "  validation loss:\t\t3.92\n",
      "Epoch 43 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.142725\n",
      "  validation loss:\t\t3.86\n",
      "Epoch 44 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t3.116255\n",
      "  validation loss:\t\t3.83\n",
      "Epoch 45 of 120 took 0.111s\n",
      "  training loss (in-iteration):\t\t3.094455\n",
      "  validation loss:\t\t3.79\n",
      "Epoch 46 of 120 took 0.108s\n",
      "  training loss (in-iteration):\t\t3.062143\n",
      "  validation loss:\t\t3.80\n",
      "Epoch 47 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t3.059562\n",
      "  validation loss:\t\t3.73\n",
      "Epoch 48 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t3.047706\n",
      "  validation loss:\t\t3.71\n",
      "Epoch 49 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.993851\n",
      "  validation loss:\t\t3.67\n",
      "Epoch 50 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t2.962718\n",
      "  validation loss:\t\t3.65\n",
      "23365.0548106\n",
      "Epoch 51 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t3.024292\n",
      "  validation loss:\t\t3.61\n",
      "Epoch 52 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t2.888397\n",
      "  validation loss:\t\t3.63\n",
      "Epoch 53 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t2.875995\n",
      "  validation loss:\t\t3.58\n",
      "Epoch 54 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t2.849535\n",
      "  validation loss:\t\t3.57\n",
      "Epoch 55 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.827558\n",
      "  validation loss:\t\t3.55\n",
      "Epoch 56 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t2.818930\n",
      "  validation loss:\t\t3.45\n",
      "Epoch 57 of 120 took 0.101s\n",
      "  training loss (in-iteration):\t\t2.782201\n",
      "  validation loss:\t\t3.48\n",
      "Epoch 58 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t2.749918\n",
      "  validation loss:\t\t3.45\n",
      "Epoch 59 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t2.747698\n",
      "  validation loss:\t\t3.43\n",
      "Epoch 60 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t2.719277\n",
      "  validation loss:\t\t3.37\n",
      "21469.8889542\n",
      "Epoch 61 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t2.807716\n",
      "  validation loss:\t\t3.34\n",
      "Epoch 62 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t2.648422\n",
      "  validation loss:\t\t3.30\n",
      "Epoch 63 of 120 took 0.081s\n",
      "  training loss (in-iteration):\t\t2.630296\n",
      "  validation loss:\t\t3.29\n",
      "Epoch 64 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t2.622332\n",
      "  validation loss:\t\t3.27\n",
      "Epoch 65 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t2.587373\n",
      "  validation loss:\t\t3.25\n",
      "Epoch 66 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t2.572617\n",
      "  validation loss:\t\t3.22\n",
      "Epoch 67 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t2.551869\n",
      "  validation loss:\t\t3.20\n",
      "Epoch 68 of 120 took 0.101s\n",
      "  training loss (in-iteration):\t\t2.541655\n",
      "  validation loss:\t\t3.18\n",
      "Epoch 69 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t2.513196\n",
      "  validation loss:\t\t3.19\n",
      "Epoch 70 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t2.494161\n",
      "  validation loss:\t\t3.12\n",
      "19612.5048995\n",
      "Epoch 71 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t2.550794\n",
      "  validation loss:\t\t3.10\n",
      "Epoch 72 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t2.431893\n",
      "  validation loss:\t\t3.04\n",
      "Epoch 73 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.424576\n",
      "  validation loss:\t\t3.04\n",
      "Epoch 74 of 120 took 0.114s\n",
      "  training loss (in-iteration):\t\t2.400774\n",
      "  validation loss:\t\t3.03\n",
      "Epoch 75 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t2.399759\n",
      "  validation loss:\t\t3.07\n",
      "Epoch 76 of 120 took 0.113s\n",
      "  training loss (in-iteration):\t\t2.374523\n",
      "  validation loss:\t\t2.98\n",
      "Epoch 77 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t2.348558\n",
      "  validation loss:\t\t2.95\n",
      "Epoch 78 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.331115\n",
      "  validation loss:\t\t2.95\n",
      "Epoch 79 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.320712\n",
      "  validation loss:\t\t2.92\n",
      "Epoch 80 of 120 took 0.114s\n",
      "  training loss (in-iteration):\t\t2.282683\n",
      "  validation loss:\t\t2.89\n",
      "17993.4852376\n",
      "Epoch 81 of 120 took 0.125s\n",
      "  training loss (in-iteration):\t\t2.439836\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 82 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t2.247587\n",
      "  validation loss:\t\t2.83\n",
      "Epoch 83 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.224625\n",
      "  validation loss:\t\t2.84\n",
      "Epoch 84 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.207465\n",
      "  validation loss:\t\t2.85\n",
      "Epoch 85 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.195747\n",
      "  validation loss:\t\t2.81\n",
      "Epoch 86 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.173432\n",
      "  validation loss:\t\t2.83\n",
      "Epoch 87 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.150890\n",
      "  validation loss:\t\t2.75\n",
      "Epoch 88 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.177008\n",
      "  validation loss:\t\t2.76\n",
      "Epoch 89 of 120 took 0.119s\n",
      "  training loss (in-iteration):\t\t2.130551\n",
      "  validation loss:\t\t2.72\n",
      "Epoch 90 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.125215\n",
      "  validation loss:\t\t2.68\n",
      "16656.8512044\n",
      "Epoch 91 of 120 took 0.126s\n",
      "  training loss (in-iteration):\t\t2.185176\n",
      "  validation loss:\t\t2.72\n",
      "Epoch 92 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t2.058559\n",
      "  validation loss:\t\t2.65\n",
      "Epoch 93 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.063203\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 94 of 120 took 0.108s\n",
      "  training loss (in-iteration):\t\t2.035258\n",
      "  validation loss:\t\t2.65\n",
      "Epoch 95 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.026858\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 96 of 120 took 0.119s\n",
      "  training loss (in-iteration):\t\t2.026972\n",
      "  validation loss:\t\t2.60\n",
      "Epoch 97 of 120 took 0.120s\n",
      "  training loss (in-iteration):\t\t2.002103\n",
      "  validation loss:\t\t2.59\n",
      "Epoch 98 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t1.981493\n",
      "  validation loss:\t\t2.57\n",
      "Epoch 99 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t1.966832\n",
      "  validation loss:\t\t2.54\n",
      "Epoch 100 of 120 took 0.114s\n",
      "  training loss (in-iteration):\t\t1.949498\n",
      "  validation loss:\t\t2.58\n",
      "15273.5937175\n",
      "Epoch 101 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t2.029574\n",
      "  validation loss:\t\t2.52\n",
      "Epoch 102 of 120 took 0.111s\n",
      "  training loss (in-iteration):\t\t1.917511\n",
      "  validation loss:\t\t2.51\n",
      "Epoch 103 of 120 took 0.114s\n",
      "  training loss (in-iteration):\t\t1.887495\n",
      "  validation loss:\t\t2.50\n",
      "Epoch 104 of 120 took 0.131s\n",
      "  training loss (in-iteration):\t\t1.897013\n",
      "  validation loss:\t\t2.46\n",
      "Epoch 105 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t1.877825\n",
      "  validation loss:\t\t2.49\n",
      "Epoch 106 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t1.868363\n",
      "  validation loss:\t\t2.47\n",
      "Epoch 107 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t1.840898\n",
      "  validation loss:\t\t2.46\n",
      "Epoch 108 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t1.835219\n",
      "  validation loss:\t\t2.42\n",
      "Epoch 109 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t1.827413\n",
      "  validation loss:\t\t2.43\n",
      "Epoch 110 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.826299\n",
      "  validation loss:\t\t2.42\n",
      "14116.5992879\n",
      "Epoch 111 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t1.891406\n",
      "  validation loss:\t\t2.38\n",
      "Epoch 112 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t1.760776\n",
      "  validation loss:\t\t2.44\n",
      "Epoch 113 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t1.764365\n",
      "  validation loss:\t\t2.37\n",
      "Epoch 114 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t1.758106\n",
      "  validation loss:\t\t2.40\n",
      "Epoch 115 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t1.757910\n",
      "  validation loss:\t\t2.31\n",
      "Epoch 116 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t1.725022\n",
      "  validation loss:\t\t2.33\n",
      "Epoch 117 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t1.712677\n",
      "  validation loss:\t\t2.31\n",
      "Epoch 118 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t1.712078\n",
      "  validation loss:\t\t2.28\n",
      "Epoch 119 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t1.687602\n",
      "  validation loss:\t\t2.29\n",
      "Epoch 120 of 120 took 0.093s\n",
      "  training loss (in-iteration):\t\t1.681216\n",
      "  validation loss:\t\t2.29\n",
      "41201.4459264\n",
      "Epoch 1 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t41.292990\n",
      "  validation loss:\t\t24.28\n",
      "Epoch 2 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t40.674745\n",
      "  validation loss:\t\t24.11\n",
      "Epoch 3 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t39.926072\n",
      "  validation loss:\t\t23.89\n",
      "Epoch 4 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t39.653328\n",
      "  validation loss:\t\t23.70\n",
      "Epoch 5 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t39.493553\n",
      "  validation loss:\t\t23.48\n",
      "Epoch 6 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t38.380341\n",
      "  validation loss:\t\t22.78\n",
      "Epoch 7 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t37.489706\n",
      "  validation loss:\t\t20.66\n",
      "Epoch 8 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t30.271272\n",
      "  validation loss:\t\t13.99\n",
      "Epoch 9 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t17.246990\n",
      "  validation loss:\t\t4.43\n",
      "Epoch 10 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t8.537717\n",
      "  validation loss:\t\t16.58\n",
      "26538.0613412\n",
      "Epoch 11 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t4.479997\n",
      "  validation loss:\t\t2.93\n",
      "Epoch 12 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t4.480704\n",
      "  validation loss:\t\t4.45\n",
      "Epoch 13 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t3.785495\n",
      "  validation loss:\t\t3.55\n",
      "Epoch 14 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t2.712265\n",
      "  validation loss:\t\t0.96\n",
      "Epoch 15 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t1.123359\n",
      "  validation loss:\t\t1.05\n",
      "Epoch 16 of 500 took 0.207s\n",
      "  training loss (in-iteration):\t\t1.128491\n",
      "  validation loss:\t\t0.74\n",
      "Epoch 17 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t1.160668\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 18 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.449016\n",
      "  validation loss:\t\t0.67\n",
      "Epoch 19 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.753447\n",
      "  validation loss:\t\t0.40\n",
      "Epoch 20 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.460600\n",
      "  validation loss:\t\t0.43\n",
      "492.897880523\n",
      "Epoch 21 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.585315\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 22 of 500 took 0.137s\n",
      "  training loss (in-iteration):\t\t0.398442\n",
      "  validation loss:\t\t0.34\n",
      "Epoch 23 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.340125\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 24 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.393463\n",
      "  validation loss:\t\t0.33\n",
      "Epoch 25 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.347310\n",
      "  validation loss:\t\t0.36\n",
      "Epoch 26 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.339480\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 27 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.354940\n",
      "  validation loss:\t\t0.37\n",
      "Epoch 28 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.412219\n",
      "  validation loss:\t\t0.42\n",
      "Epoch 29 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.382220\n",
      "  validation loss:\t\t0.38\n",
      "Epoch 30 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.357660\n",
      "  validation loss:\t\t0.37\n",
      "398.805577027\n",
      "Epoch 31 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.409507\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 32 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.299230\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 33 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.310919\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 34 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.298770\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 35 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.299952\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 36 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.306643\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 37 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.318929\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 38 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.306596\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 39 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.303708\n",
      "  validation loss:\t\t0.32\n",
      "Epoch 40 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.319021\n",
      "  validation loss:\t\t0.31\n",
      "315.604098332\n",
      "Epoch 41 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.312758\n",
      "  validation loss:\t\t0.31\n",
      "Epoch 42 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.302729\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 43 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.292300\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 44 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.288923\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 45 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.296885\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 46 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.298262\n",
      "  validation loss:\t\t0.30\n",
      "Epoch 47 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.303079\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 48 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.286447\n",
      "  validation loss:\t\t0.29\n",
      "Epoch 49 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.279882\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 50 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.277394\n",
      "  validation loss:\t\t0.28\n",
      "276.902713044\n",
      "Epoch 51 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.275855\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 52 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.277935\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 53 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.277951\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 54 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.278072\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 55 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.274404\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 56 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.271874\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 57 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.273425\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 58 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.271237\n",
      "  validation loss:\t\t0.28\n",
      "Epoch 59 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.268113\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 60 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.271626\n",
      "  validation loss:\t\t0.27\n",
      "267.279867196\n",
      "Epoch 61 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.269381\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 62 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.270224\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 63 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.264708\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 64 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.264588\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 65 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.262867\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 66 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.261902\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 67 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.259861\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 68 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.259625\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 69 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.259302\n",
      "  validation loss:\t\t0.27\n",
      "Epoch 70 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.256550\n",
      "  validation loss:\t\t0.26\n",
      "258.046134453\n",
      "Epoch 71 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.255795\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 72 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.256807\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 73 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.256139\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 74 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.253183\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 75 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.253054\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 76 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.250461\n",
      "  validation loss:\t\t0.26\n",
      "Epoch 77 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.251418\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 78 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.247756\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 79 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.247091\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 80 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.248146\n",
      "  validation loss:\t\t0.25\n",
      "244.784757241\n",
      "Epoch 81 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.243294\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 82 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.244732\n",
      "  validation loss:\t\t0.25\n",
      "Epoch 83 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.240770\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 84 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.238158\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 85 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.237394\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 86 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.234318\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 87 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.231984\n",
      "  validation loss:\t\t0.24\n",
      "Epoch 88 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.230224\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 89 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.228795\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 90 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.226978\n",
      "  validation loss:\t\t0.23\n",
      "230.058784267\n",
      "Epoch 91 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.222142\n",
      "  validation loss:\t\t0.23\n",
      "Epoch 92 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.222245\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 93 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.217944\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 94 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.214451\n",
      "  validation loss:\t\t0.22\n",
      "Epoch 95 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.210004\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 96 of 500 took 0.217s\n",
      "  training loss (in-iteration):\t\t0.208245\n",
      "  validation loss:\t\t0.21\n",
      "Epoch 97 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.204103\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 98 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.201725\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 99 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.200285\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 100 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.198703\n",
      "  validation loss:\t\t0.20\n",
      "197.0972661\n",
      "Epoch 101 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.196597\n",
      "  validation loss:\t\t0.20\n",
      "Epoch 102 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.193715\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 103 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.189002\n",
      "  validation loss:\t\t0.19\n",
      "Epoch 104 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.193610\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 105 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.185598\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 106 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.182155\n",
      "  validation loss:\t\t0.18\n",
      "Epoch 107 of 500 took 0.213s\n",
      "  training loss (in-iteration):\t\t0.177889\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 108 of 500 took 0.229s\n",
      "  training loss (in-iteration):\t\t0.179129\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 109 of 500 took 0.346s\n",
      "  training loss (in-iteration):\t\t0.177180\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 110 of 500 took 0.246s\n",
      "  training loss (in-iteration):\t\t0.174394\n",
      "  validation loss:\t\t0.17\n",
      "174.741631922\n",
      "Epoch 111 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.174334\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 112 of 500 took 0.190s\n",
      "  training loss (in-iteration):\t\t0.167052\n",
      "  validation loss:\t\t0.17\n",
      "Epoch 113 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.166435\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 114 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.171471\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 115 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.159381\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 116 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.160706\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 117 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.158957\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 118 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.154625\n",
      "  validation loss:\t\t0.15\n",
      "Epoch 119 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.149117\n",
      "  validation loss:\t\t0.16\n",
      "Epoch 120 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.152700\n",
      "  validation loss:\t\t0.14\n",
      "143.92443787\n",
      "Epoch 121 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.150352\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 122 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.148433\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 123 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.137465\n",
      "  validation loss:\t\t0.14\n",
      "Epoch 124 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.148890\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 125 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.137248\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 126 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.141499\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 127 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.132134\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 128 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.139998\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 129 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.130677\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 130 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.135508\n",
      "  validation loss:\t\t0.12\n",
      "127.13838282\n",
      "Epoch 131 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.136220\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 132 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.127950\n",
      "  validation loss:\t\t0.13\n",
      "Epoch 133 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.123330\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 134 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.125438\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 135 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.123616\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 136 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.127163\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 137 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.121434\n",
      "  validation loss:\t\t0.12\n",
      "Epoch 138 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.124120\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 139 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.118427\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 140 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.120170\n",
      "  validation loss:\t\t0.11\n",
      "113.038923699\n",
      "Epoch 141 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.116649\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 142 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.120880\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 143 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.115474\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 144 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.117289\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 145 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.109427\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 146 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.112813\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 147 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.109113\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 148 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.106576\n",
      "  validation loss:\t\t0.11\n",
      "Epoch 149 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.110264\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 150 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.108348\n",
      "  validation loss:\t\t0.10\n",
      "102.864264896\n",
      "Epoch 151 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.104584\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 152 of 500 took 0.190s\n",
      "  training loss (in-iteration):\t\t0.105059\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 153 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.101998\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 154 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.101340\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 155 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.100526\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 156 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.101528\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 157 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.101882\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 158 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.101439\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 159 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.102998\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 160 of 500 took 0.190s\n",
      "  training loss (in-iteration):\t\t0.096186\n",
      "  validation loss:\t\t0.09\n",
      "99.3486282164\n",
      "Epoch 161 of 500 took 0.216s\n",
      "  training loss (in-iteration):\t\t0.095958\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 162 of 500 took 0.213s\n",
      "  training loss (in-iteration):\t\t0.097793\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 163 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.095475\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 164 of 500 took 0.207s\n",
      "  training loss (in-iteration):\t\t0.094696\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 165 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.095765\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 166 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.095608\n",
      "  validation loss:\t\t0.10\n",
      "Epoch 167 of 500 took 0.207s\n",
      "  training loss (in-iteration):\t\t0.097005\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 168 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.092196\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 169 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.092731\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 170 of 500 took 0.209s\n",
      "  training loss (in-iteration):\t\t0.092620\n",
      "  validation loss:\t\t0.09\n",
      "90.6973478318\n",
      "Epoch 171 of 500 took 0.240s\n",
      "  training loss (in-iteration):\t\t0.091070\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 172 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.093090\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 173 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.092421\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 174 of 500 took 0.230s\n",
      "  training loss (in-iteration):\t\t0.089707\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 175 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.089943\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 176 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.090271\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 177 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.088161\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 178 of 500 took 0.226s\n",
      "  training loss (in-iteration):\t\t0.088396\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 179 of 500 took 0.212s\n",
      "  training loss (in-iteration):\t\t0.088473\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 180 of 500 took 0.213s\n",
      "  training loss (in-iteration):\t\t0.088244\n",
      "  validation loss:\t\t0.08\n",
      "84.9685382357\n",
      "Epoch 181 of 500 took 0.217s\n",
      "  training loss (in-iteration):\t\t0.087667\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 182 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.085891\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 183 of 500 took 0.208s\n",
      "  training loss (in-iteration):\t\t0.085745\n",
      "  validation loss:\t\t0.09\n",
      "Epoch 184 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.086390\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 185 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.084699\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 186 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.086008\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 187 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.082867\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 188 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.083295\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 189 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.085203\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 190 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.081518\n",
      "  validation loss:\t\t0.08\n",
      "85.403004646\n",
      "Epoch 191 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.080694\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 192 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.081939\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 193 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.083748\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 194 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.081564\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 195 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.082305\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 196 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.081124\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 197 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.080623\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 198 of 500 took 0.208s\n",
      "  training loss (in-iteration):\t\t0.080752\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 199 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.080201\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 200 of 500 took 0.204s\n",
      "  training loss (in-iteration):\t\t0.078331\n",
      "  validation loss:\t\t0.07\n",
      "77.1658861482\n",
      "Epoch 201 of 500 took 0.214s\n",
      "  training loss (in-iteration):\t\t0.078971\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 202 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.078585\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 203 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.078502\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 204 of 500 took 0.214s\n",
      "  training loss (in-iteration):\t\t0.078879\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 205 of 500 took 0.215s\n",
      "  training loss (in-iteration):\t\t0.077708\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 206 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.078020\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 207 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.076641\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 208 of 500 took 0.224s\n",
      "  training loss (in-iteration):\t\t0.077605\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 209 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.076637\n",
      "  validation loss:\t\t0.08\n",
      "Epoch 210 of 500 took 0.204s\n",
      "  training loss (in-iteration):\t\t0.077490\n",
      "  validation loss:\t\t0.07\n",
      "76.7997719871\n",
      "Epoch 211 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.075481\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 212 of 500 took 0.224s\n",
      "  training loss (in-iteration):\t\t0.075179\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 213 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.075519\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 214 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.074665\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 215 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.075016\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 216 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.075204\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 217 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.075221\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 218 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.074161\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 219 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.073735\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 220 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.073633\n",
      "  validation loss:\t\t0.07\n",
      "71.2396602964\n",
      "Epoch 221 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.074086\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 222 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.072130\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 223 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.072804\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 224 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.071631\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 225 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.072041\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 226 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.071432\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 227 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.072468\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 228 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.071074\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 229 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.071016\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 230 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.071691\n",
      "  validation loss:\t\t0.07\n",
      "72.194274786\n",
      "Epoch 231 of 500 took 0.138s\n",
      "  training loss (in-iteration):\t\t0.070112\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 232 of 500 took 0.165s\n",
      "  training loss (in-iteration):\t\t0.069098\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 233 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.070262\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 234 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.070597\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 235 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.070873\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 236 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.070981\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 237 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.070164\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 238 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.069160\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 239 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.070272\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 240 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.068022\n",
      "  validation loss:\t\t0.06\n",
      "67.2103711418\n",
      "Epoch 241 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.068558\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 242 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.068931\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 243 of 500 took 0.208s\n",
      "  training loss (in-iteration):\t\t0.068790\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 244 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.066735\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 245 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.067799\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 246 of 500 took 0.207s\n",
      "  training loss (in-iteration):\t\t0.066781\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 247 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.067858\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 248 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.066692\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 249 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.067467\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 250 of 500 took 0.209s\n",
      "  training loss (in-iteration):\t\t0.066718\n",
      "  validation loss:\t\t0.06\n",
      "64.9892746999\n",
      "Epoch 251 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.066063\n",
      "  validation loss:\t\t0.07\n",
      "Epoch 252 of 500 took 0.226s\n",
      "  training loss (in-iteration):\t\t0.067267\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 253 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.067124\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 254 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.066014\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 255 of 500 took 0.213s\n",
      "  training loss (in-iteration):\t\t0.066778\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 256 of 500 took 0.213s\n",
      "  training loss (in-iteration):\t\t0.066806\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 257 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.065035\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 258 of 500 took 0.214s\n",
      "  training loss (in-iteration):\t\t0.064857\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 259 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.066253\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 260 of 500 took 0.204s\n",
      "  training loss (in-iteration):\t\t0.063879\n",
      "  validation loss:\t\t0.07\n",
      "68.8002986575\n",
      "Epoch 261 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.064824\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 262 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.064876\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 263 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.064652\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 264 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.064539\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 265 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.064769\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 266 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.064578\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 267 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.063475\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 268 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.064135\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 269 of 500 took 0.192s\n",
      "  training loss (in-iteration):\t\t0.063656\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 270 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.063788\n",
      "  validation loss:\t\t0.06\n",
      "63.7702182768\n",
      "Epoch 271 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.063298\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 272 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.063848\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 273 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.063515\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 274 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.063689\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 275 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.062952\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 276 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.062164\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 277 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.062581\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 278 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.062718\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 279 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.062710\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 280 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.062425\n",
      "  validation loss:\t\t0.06\n",
      "62.1421561564\n",
      "Epoch 281 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.061797\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 282 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.062415\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 283 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.062063\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 284 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.061749\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 285 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.061691\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 286 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.061558\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 287 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.060678\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 288 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.060666\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 289 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.061122\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 290 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.060347\n",
      "  validation loss:\t\t0.06\n",
      "60.0079440801\n",
      "Epoch 291 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.059905\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 292 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.061251\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 293 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.060576\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 294 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.060151\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 295 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.059651\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 296 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.060370\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 297 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.059760\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 298 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.060726\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 299 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.058822\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 300 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.060858\n",
      "  validation loss:\t\t0.06\n",
      "59.762956741\n",
      "Epoch 301 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.059028\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 302 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.059246\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 303 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.059547\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 304 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.059512\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 305 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.059922\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 306 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.058105\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 307 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.059339\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 308 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.057961\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 309 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.058759\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 310 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.058057\n",
      "  validation loss:\t\t0.06\n",
      "57.5504520665\n",
      "Epoch 311 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.057938\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 312 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.058884\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 313 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.058154\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 314 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.057409\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 315 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.057905\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 316 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.057506\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 317 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.057203\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 318 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.058296\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 319 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.057346\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 320 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.056934\n",
      "  validation loss:\t\t0.06\n",
      "56.8345403353\n",
      "Epoch 321 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.057062\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 322 of 500 took 0.187s\n",
      "  training loss (in-iteration):\t\t0.057197\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 323 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.057000\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 324 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.056724\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 325 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.056745\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 326 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.056497\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 327 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.056154\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 328 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.056569\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 329 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.055583\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 330 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.055586\n",
      "  validation loss:\t\t0.06\n",
      "58.0440867516\n",
      "Epoch 331 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.056373\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 332 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.054954\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 333 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.056079\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 334 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.054771\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 335 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.055813\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 336 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.055009\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 337 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.055424\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 338 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.054572\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 339 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.055295\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 340 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.054069\n",
      "  validation loss:\t\t0.05\n",
      "54.8357377677\n",
      "Epoch 341 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.055200\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 342 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.054600\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 343 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.054902\n",
      "  validation loss:\t\t0.06\n",
      "Epoch 344 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.055447\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 345 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.053142\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 346 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.054249\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 347 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.054085\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 348 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.052792\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 349 of 500 took 0.164s\n",
      "  training loss (in-iteration):\t\t0.054314\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 350 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.053036\n",
      "  validation loss:\t\t0.05\n",
      "52.3586305131\n",
      "Epoch 351 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.052758\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 352 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.052319\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 353 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.054148\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 354 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.052830\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 355 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.053162\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 356 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.052389\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 357 of 500 took 0.149s\n",
      "  training loss (in-iteration):\t\t0.053373\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 358 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.052305\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 359 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.052746\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 360 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.051720\n",
      "  validation loss:\t\t0.05\n",
      "54.487311984\n",
      "Epoch 361 of 500 took 0.146s\n",
      "  training loss (in-iteration):\t\t0.052316\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 362 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.052175\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 363 of 500 took 0.186s\n",
      "  training loss (in-iteration):\t\t0.052503\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 364 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.052383\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 365 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.051144\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 366 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.051308\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 367 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.051342\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 368 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.050838\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 369 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.051641\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 370 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.050239\n",
      "  validation loss:\t\t0.05\n",
      "50.301388336\n",
      "Epoch 371 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.051153\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 372 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.052187\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 373 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.050800\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 374 of 500 took 0.169s\n",
      "  training loss (in-iteration):\t\t0.051138\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 375 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.049650\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 376 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.050813\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 377 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.050657\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 378 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.049877\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 379 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.051133\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 380 of 500 took 0.205s\n",
      "  training loss (in-iteration):\t\t0.050730\n",
      "  validation loss:\t\t0.05\n",
      "50.6205616408\n",
      "Epoch 381 of 500 took 0.217s\n",
      "  training loss (in-iteration):\t\t0.050465\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 382 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.050569\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 383 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.050166\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 384 of 500 took 0.210s\n",
      "  training loss (in-iteration):\t\t0.048795\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 385 of 500 took 0.211s\n",
      "  training loss (in-iteration):\t\t0.049693\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 386 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.049171\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 387 of 500 took 0.197s\n",
      "  training loss (in-iteration):\t\t0.049884\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 388 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.049310\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 389 of 500 took 0.152s\n",
      "  training loss (in-iteration):\t\t0.048765\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 390 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.049204\n",
      "  validation loss:\t\t0.05\n",
      "50.0742046742\n",
      "Epoch 391 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.049103\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 392 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.048779\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 393 of 500 took 0.139s\n",
      "  training loss (in-iteration):\t\t0.048812\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 394 of 500 took 0.161s\n",
      "  training loss (in-iteration):\t\t0.048750\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 395 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.048659\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 396 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.048419\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 397 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.048405\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 398 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.048861\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 399 of 500 took 0.174s\n",
      "  training loss (in-iteration):\t\t0.048881\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 400 of 500 took 0.194s\n",
      "  training loss (in-iteration):\t\t0.048343\n",
      "  validation loss:\t\t0.05\n",
      "47.3989745609\n",
      "Epoch 401 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.047207\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 402 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.048023\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 403 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.048385\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 404 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.047589\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 405 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.048561\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 406 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.047601\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 407 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.047827\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 408 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.047902\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 409 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.046650\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 410 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.046344\n",
      "  validation loss:\t\t0.05\n",
      "45.6750445458\n",
      "Epoch 411 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.046441\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 412 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.046976\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 413 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.048297\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 414 of 500 took 0.197s\n",
      "  training loss (in-iteration):\t\t0.046464\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 415 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.046612\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 416 of 500 took 0.159s\n",
      "  training loss (in-iteration):\t\t0.046458\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 417 of 500 took 0.176s\n",
      "  training loss (in-iteration):\t\t0.046323\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 418 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.045812\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 419 of 500 took 0.199s\n",
      "  training loss (in-iteration):\t\t0.046619\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 420 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.046187\n",
      "  validation loss:\t\t0.05\n",
      "46.8034831233\n",
      "Epoch 421 of 500 took 0.212s\n",
      "  training loss (in-iteration):\t\t0.046001\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 422 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.045373\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 423 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.047047\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 424 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.045917\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 425 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.045730\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 426 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.045926\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 427 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.044430\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 428 of 500 took 0.167s\n",
      "  training loss (in-iteration):\t\t0.045238\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 429 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.044156\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 430 of 500 took 0.147s\n",
      "  training loss (in-iteration):\t\t0.045574\n",
      "  validation loss:\t\t0.04\n",
      "45.5152391613\n",
      "Epoch 431 of 500 took 0.197s\n",
      "  training loss (in-iteration):\t\t0.046406\n",
      "  validation loss:\t\t0.05\n",
      "Epoch 432 of 500 took 0.148s\n",
      "  training loss (in-iteration):\t\t0.046306\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 433 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.043802\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 434 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.044468\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 435 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.044801\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 436 of 500 took 0.151s\n",
      "  training loss (in-iteration):\t\t0.044700\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 437 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.045325\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 438 of 500 took 0.156s\n",
      "  training loss (in-iteration):\t\t0.044003\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 439 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.043655\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 440 of 500 took 0.162s\n",
      "  training loss (in-iteration):\t\t0.044379\n",
      "  validation loss:\t\t0.04\n",
      "43.3628267296\n",
      "Epoch 441 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.044194\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 442 of 500 took 0.144s\n",
      "  training loss (in-iteration):\t\t0.043655\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 443 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.043554\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 444 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.044175\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 445 of 500 took 0.182s\n",
      "  training loss (in-iteration):\t\t0.044283\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 446 of 500 took 0.160s\n",
      "  training loss (in-iteration):\t\t0.044491\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 447 of 500 took 0.177s\n",
      "  training loss (in-iteration):\t\t0.042816\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 448 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.044889\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 449 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.042811\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 450 of 500 took 0.157s\n",
      "  training loss (in-iteration):\t\t0.043819\n",
      "  validation loss:\t\t0.04\n",
      "42.2470037787\n",
      "Epoch 451 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.042259\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 452 of 500 took 0.141s\n",
      "  training loss (in-iteration):\t\t0.043496\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 453 of 500 took 0.170s\n",
      "  training loss (in-iteration):\t\t0.042884\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 454 of 500 took 0.163s\n",
      "  training loss (in-iteration):\t\t0.042897\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 455 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.042837\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 456 of 500 took 0.166s\n",
      "  training loss (in-iteration):\t\t0.042465\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 457 of 500 took 0.189s\n",
      "  training loss (in-iteration):\t\t0.042609\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 458 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.043591\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 459 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.042109\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 460 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.042628\n",
      "  validation loss:\t\t0.04\n",
      "43.223149806\n",
      "Epoch 461 of 500 took 0.202s\n",
      "  training loss (in-iteration):\t\t0.043045\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 462 of 500 took 0.196s\n",
      "  training loss (in-iteration):\t\t0.043117\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 463 of 500 took 0.190s\n",
      "  training loss (in-iteration):\t\t0.041854\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 464 of 500 took 0.200s\n",
      "  training loss (in-iteration):\t\t0.042363\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 465 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.041501\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 466 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.041411\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 467 of 500 took 0.188s\n",
      "  training loss (in-iteration):\t\t0.041564\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 468 of 500 took 0.206s\n",
      "  training loss (in-iteration):\t\t0.041764\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 469 of 500 took 0.150s\n",
      "  training loss (in-iteration):\t\t0.041918\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 470 of 500 took 0.195s\n",
      "  training loss (in-iteration):\t\t0.042212\n",
      "  validation loss:\t\t0.04\n",
      "41.0440878654\n",
      "Epoch 471 of 500 took 0.145s\n",
      "  training loss (in-iteration):\t\t0.041144\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 472 of 500 took 0.168s\n",
      "  training loss (in-iteration):\t\t0.041401\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 473 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.041051\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 474 of 500 took 0.191s\n",
      "  training loss (in-iteration):\t\t0.043070\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 475 of 500 took 0.140s\n",
      "  training loss (in-iteration):\t\t0.040590\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 476 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.041141\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 477 of 500 took 0.198s\n",
      "  training loss (in-iteration):\t\t0.041176\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 478 of 500 took 0.205s\n",
      "  training loss (in-iteration):\t\t0.042038\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 479 of 500 took 0.142s\n",
      "  training loss (in-iteration):\t\t0.041545\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 480 of 500 took 0.173s\n",
      "  training loss (in-iteration):\t\t0.041374\n",
      "  validation loss:\t\t0.04\n",
      "41.4050966846\n",
      "Epoch 481 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.040680\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 482 of 500 took 0.184s\n",
      "  training loss (in-iteration):\t\t0.040757\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 483 of 500 took 0.153s\n",
      "  training loss (in-iteration):\t\t0.040465\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 484 of 500 took 0.178s\n",
      "  training loss (in-iteration):\t\t0.040803\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 485 of 500 took 0.155s\n",
      "  training loss (in-iteration):\t\t0.040561\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 486 of 500 took 0.180s\n",
      "  training loss (in-iteration):\t\t0.040512\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 487 of 500 took 0.183s\n",
      "  training loss (in-iteration):\t\t0.041101\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 488 of 500 took 0.201s\n",
      "  training loss (in-iteration):\t\t0.039812\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 489 of 500 took 0.143s\n",
      "  training loss (in-iteration):\t\t0.040809\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 490 of 500 took 0.172s\n",
      "  training loss (in-iteration):\t\t0.040428\n",
      "  validation loss:\t\t0.04\n",
      "40.5672775508\n",
      "Epoch 491 of 500 took 0.185s\n",
      "  training loss (in-iteration):\t\t0.040429\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 492 of 500 took 0.203s\n",
      "  training loss (in-iteration):\t\t0.040910\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 493 of 500 took 0.175s\n",
      "  training loss (in-iteration):\t\t0.040324\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 494 of 500 took 0.197s\n",
      "  training loss (in-iteration):\t\t0.039811\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 495 of 500 took 0.171s\n",
      "  training loss (in-iteration):\t\t0.039382\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 496 of 500 took 0.193s\n",
      "  training loss (in-iteration):\t\t0.040371\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 497 of 500 took 0.154s\n",
      "  training loss (in-iteration):\t\t0.039592\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 498 of 500 took 0.179s\n",
      "  training loss (in-iteration):\t\t0.039160\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 499 of 500 took 0.158s\n",
      "  training loss (in-iteration):\t\t0.039821\n",
      "  validation loss:\t\t0.04\n",
      "Epoch 500 of 500 took 0.181s\n",
      "  training loss (in-iteration):\t\t0.038903\n",
      "  validation loss:\t\t0.04\n",
      "44404.2307889\n",
      "Epoch 1 of 120 took 0.090s\n",
      "  training loss (in-iteration):\t\t5.059515\n",
      "  validation loss:\t\t6.12\n",
      "Epoch 2 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t4.798449\n",
      "  validation loss:\t\t6.02\n",
      "Epoch 3 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t4.675326\n",
      "  validation loss:\t\t5.94\n",
      "Epoch 4 of 120 took 0.108s\n",
      "  training loss (in-iteration):\t\t4.567365\n",
      "  validation loss:\t\t5.81\n",
      "Epoch 5 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t4.466591\n",
      "  validation loss:\t\t5.79\n",
      "Epoch 6 of 120 took 0.102s\n",
      "  training loss (in-iteration):\t\t4.434791\n",
      "  validation loss:\t\t5.70\n",
      "Epoch 7 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t4.348166\n",
      "  validation loss:\t\t5.67\n",
      "Epoch 8 of 120 took 0.087s\n",
      "  training loss (in-iteration):\t\t4.300234\n",
      "  validation loss:\t\t5.60\n",
      "Epoch 9 of 120 took 0.108s\n",
      "  training loss (in-iteration):\t\t4.252210\n",
      "  validation loss:\t\t5.51\n",
      "Epoch 10 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t4.202299\n",
      "  validation loss:\t\t5.42\n",
      "33071.8837291\n",
      "Epoch 11 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t4.146817\n",
      "  validation loss:\t\t5.34\n",
      "Epoch 12 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t4.078273\n",
      "  validation loss:\t\t5.32\n",
      "Epoch 13 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t4.075765\n",
      "  validation loss:\t\t5.25\n",
      "Epoch 14 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t4.027201\n",
      "  validation loss:\t\t5.21\n",
      "Epoch 15 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t3.996262\n",
      "  validation loss:\t\t5.15\n",
      "Epoch 16 of 120 took 0.094s\n",
      "  training loss (in-iteration):\t\t3.949303\n",
      "  validation loss:\t\t5.13\n",
      "Epoch 17 of 120 took 0.102s\n",
      "  training loss (in-iteration):\t\t3.916226\n",
      "  validation loss:\t\t5.09\n",
      "Epoch 18 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.888980\n",
      "  validation loss:\t\t5.05\n",
      "Epoch 19 of 120 took 0.084s\n",
      "  training loss (in-iteration):\t\t3.824280\n",
      "  validation loss:\t\t4.96\n",
      "Epoch 20 of 120 took 0.103s\n",
      "  training loss (in-iteration):\t\t3.819953\n",
      "  validation loss:\t\t4.95\n",
      "30103.6730808\n",
      "Epoch 21 of 120 took 0.103s\n",
      "  training loss (in-iteration):\t\t3.929327\n",
      "  validation loss:\t\t4.91\n",
      "Epoch 22 of 120 took 0.120s\n",
      "  training loss (in-iteration):\t\t3.727868\n",
      "  validation loss:\t\t4.88\n",
      "Epoch 23 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t3.703914\n",
      "  validation loss:\t\t4.86\n",
      "Epoch 24 of 120 took 0.083s\n",
      "  training loss (in-iteration):\t\t3.678184\n",
      "  validation loss:\t\t4.78\n",
      "Epoch 25 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t3.629951\n",
      "  validation loss:\t\t4.76\n",
      "Epoch 26 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t3.611042\n",
      "  validation loss:\t\t4.69\n",
      "Epoch 27 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.573898\n",
      "  validation loss:\t\t4.64\n",
      "Epoch 28 of 120 took 0.096s\n",
      "  training loss (in-iteration):\t\t3.546712\n",
      "  validation loss:\t\t4.62\n",
      "Epoch 29 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.492994\n",
      "  validation loss:\t\t4.57\n",
      "Epoch 30 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t3.461308\n",
      "  validation loss:\t\t4.55\n",
      "27555.3664146\n",
      "Epoch 31 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t3.608620\n",
      "  validation loss:\t\t4.55\n",
      "Epoch 32 of 120 took 0.091s\n",
      "  training loss (in-iteration):\t\t3.434708\n",
      "  validation loss:\t\t4.49\n",
      "Epoch 33 of 120 took 0.074s\n",
      "  training loss (in-iteration):\t\t3.385614\n",
      "  validation loss:\t\t4.43\n",
      "Epoch 34 of 120 took 0.082s\n",
      "  training loss (in-iteration):\t\t3.368989\n",
      "  validation loss:\t\t4.40\n",
      "Epoch 35 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t3.337202\n",
      "  validation loss:\t\t4.36\n",
      "Epoch 36 of 120 took 0.080s\n",
      "  training loss (in-iteration):\t\t3.295429\n",
      "  validation loss:\t\t4.32\n",
      "Epoch 37 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t3.270468\n",
      "  validation loss:\t\t4.27\n",
      "Epoch 38 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t3.227515\n",
      "  validation loss:\t\t4.25\n",
      "Epoch 39 of 120 took 0.073s\n",
      "  training loss (in-iteration):\t\t3.205902\n",
      "  validation loss:\t\t4.20\n",
      "Epoch 40 of 120 took 0.092s\n",
      "  training loss (in-iteration):\t\t3.167837\n",
      "  validation loss:\t\t4.14\n",
      "24876.97596\n",
      "Epoch 41 of 120 took 0.086s\n",
      "  training loss (in-iteration):\t\t3.211826\n",
      "  validation loss:\t\t4.13\n",
      "Epoch 42 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t3.082625\n",
      "  validation loss:\t\t4.06\n",
      "Epoch 43 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t3.061463\n",
      "  validation loss:\t\t4.04\n",
      "Epoch 44 of 120 took 0.078s\n",
      "  training loss (in-iteration):\t\t3.034701\n",
      "  validation loss:\t\t4.01\n",
      "Epoch 45 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t3.015138\n",
      "  validation loss:\t\t3.98\n",
      "Epoch 46 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t2.978872\n",
      "  validation loss:\t\t3.99\n",
      "Epoch 47 of 120 took 0.079s\n",
      "  training loss (in-iteration):\t\t2.969146\n",
      "  validation loss:\t\t3.93\n",
      "Epoch 48 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t2.951648\n",
      "  validation loss:\t\t3.90\n",
      "Epoch 49 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t2.925021\n",
      "  validation loss:\t\t3.87\n",
      "Epoch 50 of 120 took 0.085s\n",
      "  training loss (in-iteration):\t\t2.894153\n",
      "  validation loss:\t\t3.83\n",
      "22803.2919141\n",
      "Epoch 51 of 120 took 0.103s\n",
      "  training loss (in-iteration):\t\t2.984963\n",
      "  validation loss:\t\t3.78\n",
      "Epoch 52 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t2.825598\n",
      "  validation loss:\t\t3.73\n",
      "Epoch 53 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t2.802093\n",
      "  validation loss:\t\t3.71\n",
      "Epoch 54 of 120 took 0.105s\n",
      "  training loss (in-iteration):\t\t2.779745\n",
      "  validation loss:\t\t3.71\n",
      "Epoch 55 of 120 took 0.095s\n",
      "  training loss (in-iteration):\t\t2.736663\n",
      "  validation loss:\t\t3.72\n",
      "Epoch 56 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t2.718690\n",
      "  validation loss:\t\t3.62\n",
      "Epoch 57 of 120 took 0.099s\n",
      "  training loss (in-iteration):\t\t2.721359\n",
      "  validation loss:\t\t3.63\n",
      "Epoch 58 of 120 took 0.076s\n",
      "  training loss (in-iteration):\t\t2.676660\n",
      "  validation loss:\t\t3.58\n",
      "Epoch 59 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t2.671537\n",
      "  validation loss:\t\t3.58\n",
      "Epoch 60 of 120 took 0.101s\n",
      "  training loss (in-iteration):\t\t2.625797\n",
      "  validation loss:\t\t3.56\n",
      "20641.5203883\n",
      "Epoch 61 of 120 took 0.114s\n",
      "  training loss (in-iteration):\t\t2.648759\n",
      "  validation loss:\t\t3.48\n",
      "Epoch 62 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t2.592174\n",
      "  validation loss:\t\t3.47\n",
      "Epoch 63 of 120 took 0.100s\n",
      "  training loss (in-iteration):\t\t2.568967\n",
      "  validation loss:\t\t3.46\n",
      "Epoch 64 of 120 took 0.121s\n",
      "  training loss (in-iteration):\t\t2.540574\n",
      "  validation loss:\t\t3.44\n",
      "Epoch 65 of 120 took 0.098s\n",
      "  training loss (in-iteration):\t\t2.511485\n",
      "  validation loss:\t\t3.42\n",
      "Epoch 66 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t2.500437\n",
      "  validation loss:\t\t3.41\n",
      "Epoch 67 of 120 took 0.113s\n",
      "  training loss (in-iteration):\t\t2.485821\n",
      "  validation loss:\t\t3.36\n",
      "Epoch 68 of 120 took 0.112s\n",
      "  training loss (in-iteration):\t\t2.480009\n",
      "  validation loss:\t\t3.33\n",
      "Epoch 69 of 120 took 0.113s\n",
      "  training loss (in-iteration):\t\t2.450850\n",
      "  validation loss:\t\t3.34\n",
      "Epoch 70 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t2.412587\n",
      "  validation loss:\t\t3.28\n",
      "18991.2498902\n",
      "Epoch 71 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t2.622378\n",
      "  validation loss:\t\t3.32\n",
      "Epoch 72 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t2.406518\n",
      "  validation loss:\t\t3.26\n",
      "Epoch 73 of 120 took 0.097s\n",
      "  training loss (in-iteration):\t\t2.349818\n",
      "  validation loss:\t\t3.23\n",
      "Epoch 74 of 120 took 0.114s\n",
      "  training loss (in-iteration):\t\t2.325832\n",
      "  validation loss:\t\t3.20\n",
      "Epoch 75 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.306341\n",
      "  validation loss:\t\t3.20\n",
      "Epoch 76 of 120 took 0.113s\n",
      "  training loss (in-iteration):\t\t2.296387\n",
      "  validation loss:\t\t3.17\n",
      "Epoch 77 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t2.286975\n",
      "  validation loss:\t\t3.15\n",
      "Epoch 78 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t2.241129\n",
      "  validation loss:\t\t3.14\n",
      "Epoch 79 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t2.240904\n",
      "  validation loss:\t\t3.11\n",
      "Epoch 80 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.213947\n",
      "  validation loss:\t\t3.05\n",
      "17461.4382987\n",
      "Epoch 81 of 120 took 0.124s\n",
      "  training loss (in-iteration):\t\t2.331489\n",
      "  validation loss:\t\t3.06\n",
      "Epoch 82 of 120 took 0.137s\n",
      "  training loss (in-iteration):\t\t2.164975\n",
      "  validation loss:\t\t3.02\n",
      "Epoch 83 of 120 took 0.122s\n",
      "  training loss (in-iteration):\t\t2.155226\n",
      "  validation loss:\t\t3.01\n",
      "Epoch 84 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.141797\n",
      "  validation loss:\t\t3.00\n",
      "Epoch 85 of 120 took 0.123s\n",
      "  training loss (in-iteration):\t\t2.122444\n",
      "  validation loss:\t\t2.97\n",
      "Epoch 86 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.108309\n",
      "  validation loss:\t\t2.95\n",
      "Epoch 87 of 120 took 0.124s\n",
      "  training loss (in-iteration):\t\t2.082301\n",
      "  validation loss:\t\t2.94\n",
      "Epoch 88 of 120 took 0.121s\n",
      "  training loss (in-iteration):\t\t2.063150\n",
      "  validation loss:\t\t2.91\n",
      "Epoch 89 of 120 took 0.120s\n",
      "  training loss (in-iteration):\t\t2.068124\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 90 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t2.048591\n",
      "  validation loss:\t\t2.87\n",
      "15924.0499754\n",
      "Epoch 91 of 120 took 0.120s\n",
      "  training loss (in-iteration):\t\t2.125723\n",
      "  validation loss:\t\t2.87\n",
      "Epoch 92 of 120 took 0.111s\n",
      "  training loss (in-iteration):\t\t2.005089\n",
      "  validation loss:\t\t2.88\n",
      "Epoch 93 of 120 took 0.113s\n",
      "  training loss (in-iteration):\t\t1.980856\n",
      "  validation loss:\t\t2.85\n",
      "Epoch 94 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t1.969297\n",
      "  validation loss:\t\t2.86\n",
      "Epoch 95 of 120 took 0.110s\n",
      "  training loss (in-iteration):\t\t1.942804\n",
      "  validation loss:\t\t2.80\n",
      "Epoch 96 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t1.942052\n",
      "  validation loss:\t\t2.76\n",
      "Epoch 97 of 120 took 0.112s\n",
      "  training loss (in-iteration):\t\t1.925351\n",
      "  validation loss:\t\t2.77\n",
      "Epoch 98 of 120 took 0.112s\n",
      "  training loss (in-iteration):\t\t1.923375\n",
      "  validation loss:\t\t2.73\n",
      "Epoch 99 of 120 took 0.108s\n",
      "  training loss (in-iteration):\t\t1.884333\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 100 of 120 took 0.109s\n",
      "  training loss (in-iteration):\t\t1.893445\n",
      "  validation loss:\t\t2.72\n",
      "14830.601093\n",
      "Epoch 101 of 120 took 0.121s\n",
      "  training loss (in-iteration):\t\t2.069345\n",
      "  validation loss:\t\t2.80\n",
      "Epoch 102 of 120 took 0.106s\n",
      "  training loss (in-iteration):\t\t1.871175\n",
      "  validation loss:\t\t2.70\n",
      "Epoch 103 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t1.824425\n",
      "  validation loss:\t\t2.69\n",
      "Epoch 104 of 120 took 0.120s\n",
      "  training loss (in-iteration):\t\t1.808797\n",
      "  validation loss:\t\t2.64\n",
      "Epoch 105 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t1.794639\n",
      "  validation loss:\t\t2.65\n",
      "Epoch 106 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t1.792464\n",
      "  validation loss:\t\t2.62\n",
      "Epoch 107 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t1.781281\n",
      "  validation loss:\t\t2.60\n",
      "Epoch 108 of 120 took 0.104s\n",
      "  training loss (in-iteration):\t\t1.773342\n",
      "  validation loss:\t\t2.59\n",
      "Epoch 109 of 120 took 0.112s\n",
      "  training loss (in-iteration):\t\t1.781742\n",
      "  validation loss:\t\t2.57\n",
      "Epoch 110 of 120 took 0.122s\n",
      "  training loss (in-iteration):\t\t1.758723\n",
      "  validation loss:\t\t2.58\n",
      "13624.191246\n",
      "Epoch 111 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t1.817765\n",
      "  validation loss:\t\t2.53\n",
      "Epoch 112 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t1.711983\n",
      "  validation loss:\t\t2.51\n",
      "Epoch 113 of 120 took 0.107s\n",
      "  training loss (in-iteration):\t\t1.699883\n",
      "  validation loss:\t\t2.50\n",
      "Epoch 114 of 120 took 0.118s\n",
      "  training loss (in-iteration):\t\t1.665843\n",
      "  validation loss:\t\t2.56\n",
      "Epoch 115 of 120 took 0.117s\n",
      "  training loss (in-iteration):\t\t1.670920\n",
      "  validation loss:\t\t2.49\n",
      "Epoch 116 of 120 took 0.115s\n",
      "  training loss (in-iteration):\t\t1.665526\n",
      "  validation loss:\t\t2.46\n",
      "Epoch 117 of 120 took 0.135s\n",
      "  training loss (in-iteration):\t\t1.642424\n",
      "  validation loss:\t\t2.49\n",
      "Epoch 118 of 120 took 0.112s\n",
      "  training loss (in-iteration):\t\t1.666363\n",
      "  validation loss:\t\t2.46\n",
      "Epoch 119 of 120 took 0.122s\n",
      "  training loss (in-iteration):\t\t1.633521\n",
      "  validation loss:\t\t2.41\n",
      "Epoch 120 of 120 took 0.116s\n",
      "  training loss (in-iteration):\t\t1.628992\n",
      "  validation loss:\t\t2.42\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a1c5bd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = eval.cross_val(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
