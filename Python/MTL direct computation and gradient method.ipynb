{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import csv\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scikit learn\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.cross_validation import KFold, cross_val_score, train_test_split\n",
    "\n",
    "import scipy as sp\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protein names equality check: True\n"
     ]
    }
   ],
   "source": [
    "from data_processing import *\n",
    "X, Y, feature_names, receptor_names, protein_names = read_data()\n",
    "X, feature_names = remove_constant_features(X, feature_names, eps=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "piv = np.load('features_local_cond.npy')\n",
    "piv_ind = np.array([f in piv for f in feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_k, Y_k = select_tasks(X, Y, receptor_ind=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_k = scale(X_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_k, Y_k, test_size=.5, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct matrix evaluation\n",
    "\n",
    "Let's consider\n",
    "\n",
    "$$\\min_{W} \\sum_{i=1}^n \\| W^T x_i - y_i \\|_2 + \\gamma \\sum_{j=1}^d \\| w^i \\|_2 , $$\n",
    "\n",
    "where $w^i$ is the $i$-th row of $W$.\n",
    "Note that here the residual $\\| W^T x_i - y_i \\|_2$ is not squared for further convenience.\n",
    "\n",
    "$$\\min_W \\| X W - Y \\|_{2, 1} + \\gamma \\| W \\|_{2, 1}$$\n",
    "\n",
    "We have obtained an **unconstrained optimization** problem.\n",
    "\n",
    "Let's reformulate it as a **constrained optimization**:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "& \\min_{W, E} & & \\| E \\|_{2,1} + \\| W \\|_{2,1}\\\\\n",
    "& \\text{S.t.} & & X W + \\gamma E = Y\n",
    "\\end{aligned}$$\n",
    "\n",
    "Or, taking $A = (X, \\gamma I)$ and $U = (W, E)^T$, we can write\n",
    "\n",
    "$$\\begin{aligned}\n",
    "& \\min_{U} & & \\| U \\|_{2,1}\\\\\n",
    "& \\text{S.t.} & & A U = Y\n",
    "\\end{aligned}$$\n",
    "\n",
    "Lagrangian \n",
    "\n",
    "$$L(U) = \\| U \\|_{2,1} - Tr(\\Lambda^T (AU - Y))$$\n",
    "\n",
    "$$\\dfrac{\\partial L(U)}{\\partial U} = 2DU - A^T\\Lambda = 0,$$\n",
    "\n",
    "where $D = diag(d_i)$, $d_i = \\dfrac{1}{2 \\| u^i \\|_2}$. Now multiplying by $A D^{-1}$ and using $A U = Y$:\n",
    "\n",
    "$$2 A U - A D^{-1} A^T \\Lambda = 0 \\Longrightarrow 2 Y - A D^{-1} A^T \\Lambda = 0 \\Longrightarrow\n",
    "\\Lambda = 2 (A D^{-1} A^T)^{-1} Y$$\n",
    "\n",
    "$$U = D^{-1} A^T (A D^{-1} A^T)^{-1} Y$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ind = np.all(Y != 999, axis=1)\n",
    "X = X[ind]\n",
    "Y = Y[ind]\n",
    "\n",
    "X = scale(X, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = X_train.shape[0]\n",
    "d = X_train.shape[1]\n",
    "m = n + d\n",
    "gamma = 0.5\n",
    "A = np.concatenate((X_train, gamma*np.identity(n)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "t = 0\n",
    "maxiter = 20\n",
    "epsilon = 1e-2\n",
    "\n",
    "diaginv = np.ones(m, dtype='double')\n",
    "olddiag = np.inf*diaginv\n",
    "\n",
    "while t < maxiter and np.linalg.norm(diaginv - olddiag) > epsilon:\n",
    "    Dinv = np.diag(diaginv)\n",
    "    U = Dinv.dot(A.T).dot(\n",
    "            np.linalg.inv(A.dot(Dinv).dot(A.T))).dot(Y_train)\n",
    "    olddiag = diaginv\n",
    "    diaginv = 2*np.linalg.norm(U, axis=1)\n",
    "    t += 1\n",
    "    \n",
    "time_direct = time() - start\n",
    "    \n",
    "W = U[:d, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y_prd = X_test.dot(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 iterations passed. Run took 68.30 seconds\n"
     ]
    }
   ],
   "source": [
    "print '%i iterations passed. Run took %.2f seconds' %(t, time_direct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC on test set for task 0 is 0.74\n",
      "AUC on test set for task 1 is 0.50\n",
      "AUC on test set for task 2 is 0.94\n",
      "AUC on test set for task 3 is 0.73\n",
      "AUC on test set for task 4 is 0.96\n"
     ]
    }
   ],
   "source": [
    "for i in range(Y_test.shape[1]):\n",
    "    print 'AUC on test set for task %i is %.2f' %(i, roc_auc_score(Y_test[:, i], Y_prd[:, i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient method for $l_{2,1}$ regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$F(W) =  \\| X W - Y \\|_{2, 1} + \\gamma \\| W \\|_{2, 1}$$\n",
    "\n",
    "$$\\min_W F(W)$$\n",
    "\n",
    "$$\\dfrac{\\partial F}{\\partial W} = X^T D_1 (XW - Y) + \\gamma D_2 W,$$\n",
    "\n",
    "where $D_1 = diag(d_1)$, $d_1^i = \\dfrac{1}{\\| X^i W - Y^i \\|_2}$, and $D_2 = diag(d_2)$, $d_2^i = \\dfrac{1}{\\| W^i \\|_2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MTLGradientMethods():\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y     \n",
    "        \n",
    "    def l21(self, A):\n",
    "        return np.linalg.norm(np.linalg.norm(A, axis=1, ord=2), ord=1)\n",
    "\n",
    "    def fun(self, W):\n",
    "        W_mat = W.reshape(self.d, self.T)\n",
    "        return self.l21(self.X.dot(W_mat) - self.Y) + self.gamma*self.l21(W_mat)\n",
    "\n",
    "    def gradient(self, W):\n",
    "        W_mat = W.reshape(self.d, self.T)\n",
    "        A = self.X.dot(W_mat) - self.Y\n",
    "        D1 = np.diag( 1.0 / np.linalg.norm(A, axis=1, ord=2) )\n",
    "        D2 = np.diag( 1.0 / np.linalg.norm(W_mat, axis=1, ord=2) )\n",
    "        return (self.X.T.dot(D1.dot(A)) + self.gamma*D2.dot(W_mat)).reshape(self.d*self.T)\n",
    "    \n",
    "    def solve(self, gamma = 2):\n",
    "        self.gamma = gamma\n",
    "        \n",
    "        # remove missing values\n",
    "        ind = np.all(self.Y != 999, axis=1)\n",
    "        self.X = self.X[ind]\n",
    "        self.Y = self.Y[ind]\n",
    "        \n",
    "        # remove features with small variance\n",
    "        eps = 1e-2\n",
    "        ind = np.var(self.X, axis = 0) > eps\n",
    "        self.X = self.X[:, ind]\n",
    "        \n",
    "        self.n = self.X.shape[0]\n",
    "        self.d = self.X.shape[1]\n",
    "        self.T = self.Y.shape[1]\n",
    "        \n",
    "        # scale matrix X\n",
    "        self.X = scale(self.X, axis = 0)\n",
    "        \n",
    "        # initial guess\n",
    "        W0 = np.ones(self.d*self.T)/self.n\n",
    "        \n",
    "        sol = minimize(self.fun, W0, jac=self.gradient, options={'maxiter': 10})\n",
    "        self.W = sol.x.reshape(self.d, self.T)\n",
    "        \n",
    "        return self.W\n",
    "    \n",
    "    def predict(self, X_new):\n",
    "        return X_new.dot(self.W)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myGrad = MTLGradientMethods(X_train, Y_train)\n",
    "W = myGrad.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for task 0 is 0.723\n",
      "AUC for task 1 is 0.824\n",
      "AUC for task 2 is 0.826\n"
     ]
    }
   ],
   "source": [
    "myGrad.W = np.ones((myGrad.d, myGrad.T))/(myGrad.n)\n",
    "#myGrad.W = np.zeros((myGrad.d, myGrad.T))\n",
    "#print myGrad.fun(np.ones((myGrad.d, myGrad.T))/(myGrad.n))\n",
    "#print myGrad.fun(myGrad.W)\n",
    "\n",
    "Y_pred = myGrad.predict(X_test)\n",
    "\n",
    "for i in range(3):\n",
    "    print 'AUC for task %i is %.3f' %(i, roc_auc_score(Y_test[:, i], Y_prd[:, i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
